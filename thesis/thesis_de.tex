\documentclass[twoside,a4paper,fleqn,12pt]{book}
\usepackage{fancyhdr,a4wide,graphicx}
\usepackage[paper=a4paper,left=20mm,right=20mm,top=25mm,bottom=25mm]{geometry}
\pagestyle{fancy}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
%\usepackage[]{amsfonts}
\usepackage{amsmath}
\usepackage[usenames,dvipsnames]{color}
\usepackage{colortbl}
%\usepackage{mathptmx}
\usepackage[bitstream-charter]{mathdesign}
\usepackage{charter}
\usepackage{helvet}
\usepackage{courier}
\usepackage{verbatim}
\usepackage{sectsty}
\usepackage{listings}
\usepackage{listingsutf8}
\usepackage{scalefnt}
\usepackage{setspace}
\usepackage{ngerman}
\usepackage{subfig}
\usepackage{longtable}

\definecolor{darkred}{rgb}{.5,0,0}
\definecolor{darkblue}{rgb}{0,0,.5}
\usepackage[plainpages=false,pdfpagelabels,colorlinks=true,urlcolor=darkblue,pagecolor=darkred,citecolor=darkred,linkcolor=darkred]{hyperref}
%\newcommand\url[1]{\texttt{#1}}

\lstset{basicstyle=\ttfamily\small,lineskip=-0.5em,language={},tabsize=8,inputencoding=utf8/latin1}

% define the title
\author{Frank Richter 68278\\frank.richter@gmail.com}
\title{\usefont{OT1}{phv}{b}{n}\selectfont Entwicklung eines Compilers für eine auf Cg basierende Sprache zur Programmierung von Graphikkarten \normalfont}
\date{\today}

\begin{document}

\sloppy

\newcommand\btxandlong{und}
\newcommand\btxandshort{u}
\newcommand\Btxinlong{In}
\newcommand\Btxinshort{I}
\newcommand\btxpageslong{Seiten}
\newcommand\btxetalshort{et al}
\newcommand\btxeditionlong{Auflage}
\bibliographystyle{mystyle}

% Zeilenabstand 1.5
\renewcommand{\baselinestretch}{1.50}\normalsize

% Helvetica für Section-Titel
\allsectionsfont{\usefont{OT1}{phv}{b}{n}\selectfont}

% Different font in captions
\newcommand{\captionstyle}{\small\centering}

\makeatletter  % Allow the use of @ in command names
\long\def\@makecaption#1#2{%
  \vskip\abovecaptionskip
  \sbox\@tempboxa{{\captionstyle #1: #2}}%
  \ifdim \wd\@tempboxa >\hsize
    {\captionstyle #1: #2\par}
  \else
    \hbox to\hsize{\hfil\box\@tempboxa\hfil}%
  \fi
  \vskip\belowcaptionskip}
\makeatother   % Cancel the effect of \makeatletter

% Fussnoten: alle Zeilen einrücken
\makeatletter
\newlength{\myFootnoteWidth}
\newlength{\myFootnoteLabel}
\setlength{\myFootnoteLabel}{1.2em}%  <-- can be changed to any valid value
\renewcommand{\@makefntext}[1]{%
  \setlength{\myFootnoteWidth}{\columnwidth}%
  \addtolength{\myFootnoteWidth}{-\myFootnoteLabel}%
  \noindent\makebox[\myFootnoteLabel][r]{\@makefnmark\ }%
  \parbox[t]{\myFootnoteWidth}{#1}%
}
\makeatother

% ---------- normal title ---------- %
\titlepage
\maketitle
\thispagestyle{empty}
\newpage
\thispagestyle{empty}
\mbox{}

% ---------- Fancyheader ---------- %
\fancyhead[L]{}
\fancyhead[R]{}
\fancyfoot[C]{\today}
\fancyfoot[R]{\footnotesize \thepage{}}
\renewcommand{\headrulewidth}{0pt}
%\setlength{\headheight}{24pt}

% generates the title


% ---------- table of contents ---------- %
\newpage
\pagenumbering{roman}
%\addcontentsline{toc}{section}{Inhaltsverzeichnis}
\pdfbookmark[1]{Inhaltsverzeichnis}{myPDFtocLabel}
\tableofcontents

\cleardoublepage
\pagenumbering{arabic}
\newcommand\todo[1]{\footnote{\textcolor{red}{TODO: #1}}}
\newcommand\fcite[1]{\footnote{\cite{#1}}}
\newcommand\fciteX[2]{\footnote{\cite{#1}, #2}}

\chapter{Einleitung}

\section{Zielstellung}

In der Echtzeit-3D-Graphik werden für 3D-Objekte überwiegend Dreiecksnetze\footnote{engl. ``triangle mesh'' und kürzer ``mesh''; siehe z.B. \cite{watt_de}}
verwendet. Dies spiegelt sich in dem Aufbau von 3D-Graphikprozessoren~("`GPU"') wie auch
den Programmierschnittstellen~(\cite{glspec4}, \cite{dx10}) wieder. Insbesondere bei der Programmierung der GPU müssen
separate Vertex- und Fragmentprogramme % Ref oder Erklärung was Vertex/Fragment
erstellt werden. Diese Aufteilung sowie die Definition der "`Schnittstelle"' zwischen den Verarbeitungseinheiten muss vom Programmierer manuell vorgenommen werden.

Ziel dieser Arbeit ist es, einen Compiler zu entwickeln, der die Aufteilung in Vertex- und Fragmentprogramme (und auch Schnittstellendefinition)
automatisch vornimmt,
ohne dass der Programmierer explizit angeben muss, auf welcher der Funktionseinheiten ein bestimmter Befehl ausgeführt wird.
%Die Programme sollen in der in Abschnitt~\ref{langspec} spezifizierten Sprache formuliert werden.
%Die Implementierung des Compilers wird in Abschnitt~\ref{implementation} beschrieben.

% Nochmal Abschnitt mit kurzer Beschreibung wichtiger Konzepte? (meshes, Vertices vs Fragmente, ...)

\section{Gliederung}

Zuerst wird eine Einführung in Grundlagen der 3D-Graphik vorgenommen. Diese sind nötig um die Absicht und Besonderheit des entwickelten Compilers zu verstehen.
Auch in den weiteren Kapiteln vorkommende, fachspezifische Begriffe werden dort erklärt. Insbesondere das für die Arbeit des Compilers essentielle Konzept
der Berechnugsfrequenzen wird dort einführend erläutert.

Im Kapitel "`Sprachspezifikation"' wird die Sprache spezifiziert, in der die Programme geschrieben werden sollen.
Es werden allgemeine Anforderungen an die Sprache gestellt sowie auf spezielle Aspekte der vorzunehmenden Auftrennung von Programmen eingegangen.
Unter Berücksichtigung dieser Anforderungen und der speziellen Aspekte wird die Sprachsyntax sowie eine Auswahl vordefinierter Funktionen spezifiert.

Im darauf folgenden Kapitel wird schliesslich auf die Implementierung des Compilers selbst eingegangen. Insbesondere werden die verwendete Zwischencoderepräsentation
für die Weitergabe des Programmen zwischen den verschiedenen Arbeitsschritten des Compilers sowie das eigentliche "`Ziel"' dieser Arbeit,
die Komponente zur Auftrennung eines Programms, beschrieben.

\chapter{Einführung 3D-Grafik}

Als "`3D-Grafik"' wird die Berechnung zweidimensionaler Bilder aus dreidimensionalen Daten (die sog. "`\emph{Szene}"')
 bezeichnet.
Anwendung findet sie in vielen Bereichen: Visualisierung abstrakter mathematischer Formeln, Darstellung
von geologischen Profilen, digitales Erstellen von Konstruktionszeichnungen, Spezialeffekte in Filmen und
Rundgänge durch künstliche Szenarien in Computerspielen. 

\section{Vorberechnete 3D-Grafik und Echtzeit-3D-Grafik}

Die Berechnung von 3D-Grafiken wird als \emph{Rendering} bezeichnet. Bei den Anwendungen für das Rendering
von 3D-Grafiken ist eine wichtige Untergruppe die der \emph{Echtzeitgrafik}, die sich durch besondere Anforderungen
an die Berechnungszeit abgrenzt.

\emph{"`Vorberechnete"'} 3D-Grafiken kommen zur Anwendung, wenn die gleiche Grafik mehrmals reproduziert werden
soll. Dabei nimmt man lange Renderingzeiten (Minuten bis Stunden) in Kauf, die von einer Verwendung von hohen
Bildauflösungen und komplexen Berechnungen herrühren. Diese Berechnungen werden von naturgetreuen Modellierungen 
natürlicher Phänomene verursacht; damit erlauben diese Berechnungen aber auch fast realitätsnahe Bilder. Beispiele 
für vorberechnete Grafiken sind computergenerierte Spezialeffekte in Filmen bzw. komplette Kinofilme aus dem Computer: 
ein Film soll bei jeder Betrachtung in gleicher Art reproduziert werden, muss offensichtlich also nur einmal berechnet
werden. Dadurch relativiert sich der erhöhte Aufwand zur Bildberechnung.

Dagegen fordert \emph{Echtzeitgrafik} Bildberechnungen, die nur Bruchteile einer Sekunde benötigen, um
dynamische Daten mit geringen bis keinen wahrnehmbaren Verzögerungen in einer 3D-Grafik 
darzustellen.

Beispiele hierfür sind Konstruktionszeichnungen und Computerspiele. Diese stehen auch für verschiedene Anforderungen,
die trotzdem unter "`Echtzeitdarstellung"' fallen: Konstruktionszeichnungen müssen meist mit sehr großen Datenmengen 
agieren, aber trotzdem die Verzögerungen geringstmöglich halten, wobei geringfügig wahrnehmbare Pausen toleriert
werden. Bildraten ab 15 Bildern/Sekunde werden als "`interaktiv"' bezeichnet. % TODO Ref?
Computerspiele hingegen haben strengere Anforderungen: um die Illusion von Bewegung zu erzeugen ist es hier nötig,
 mindestens 25 Bilder in einer Sekunde\footnote{Es wird in der Regel die höchstmögliche Anzahl von Bildern pro Sekunde 
angestrebt um alle Bewegungen möglichst flüssig darzustellen.} darzustellen. Überzeugende Bewegungsdarstellung und
geringe Latenzen bei Aktionen des Spielers sind von höchster Wichtigkeit; dafür werden aber, im Vergleich zur
Verwendung vorberechneter 3D-Grafiken, reduzierte Details in Kauf genommen.

\section{Renderingmethoden}

Die zu rendernden zweidimensionalen Bilder werden in fast allen Fällen als Rastergrafiken gespeichert\footnote{Es gibt
auch Renderer, die Vektorgrafiken erzeugen können.}: für jedes Pixel der Rastergrafik muss aus den gegebenen dreidimensionalen
Daten ein Farbwert berechnet werden. Die beiden hauptsächlich verwendeten Methoden sind Raytracing und Rasterung.

Beim \emph{Raytracing} wird für jeden Bildpunkt ausgehend ein Strahl in die dreidimensionale Szene nachverfolgt. Trifft
der Strahl auf ein Objekt, wird die Farbe des von der Oberfläche des Schnittpunktes reflektierten Lichts als die Farbe
des Bildpixels übernommen. Die reflektierte Farbe wird entweder durch eine Annäherung oder durch rekursives
Nachverfolgen von weiteren Strahlen bestimmt. Vorteile des Raytracings sind die einfache Unterstützung von Schatten und Nachbildung von Effekten wie spiegelnder
Oberflächen und Lichtbrechung an Oberflächenübergängen. Nachteil ist der Rechenaufwand; abhängig von gewünschter Bildauflösung und
Szenenkomplexität kann die Anzahl der zu berechnenden Strahlen im Millionenbereich und höher liegen.
Dabei muss für jeden Strahl wiederum eine Vielzahl von Berechnungen ausgeführt werden, um zu bestimmen, welches Objekt wo
geschnitten wird.

Beim \emph{Rastern} werden die Daten hingegen auf die Bildpixel projiziert und Farbwerte für diese Pixel berechnet.
Während dies weniger rechenintensiv als Raytracing ist können jedoch Effekte wie Spiegelungen und Schatten nicht so
einfach berechnet werden, sondern werden meist approximiert.

Die Geschwindigkeit und Einfachheit des Rasterns ist jedoch vorteilhaft für die Echtzeitgrafik und ist dort die praktisch
ausschließlich verwendete Variante. % TODO Intel-Raytracer
Vor allem ist spezielle Hardware verfügbar welche die Rasterung stark beschleunigt. % TODO siehe Aufbau Hardware
Raytracing findet vor allem bei der Vorberechnung von Grafiken statt. Allerdings wird dort zunächst auch Rasterung eingesetzt,
gemischt mit Raytracing wenn benötigt (z.B. reflektierende Oberflächen). % TODO Ref?

\section{Grundlegende Strukturen}

\subsection{Modelle}

Dreidimensionale Objekte ("`\emph{Modelle}"') einer Szene können auf verschiedene Arten repräsentiert werden~(\cite{watt_de}, S. 45-47). 

Bei der \emph{impliziten Darstellung} werden Objekte durch eine Formel beschrieben. So beschreibt z.B. $x^2 + y^2 + z^2 = r^2$
alle Oberflächenpunkte einer Kugel mit Radius $r$ am Koordinatenursprung. Diese Darstellung wird vor allem zusammen
mit Raytracing verwendet, da sich damit die Schnittpunkte von Strahlen und Objekten einfach berechnen lassen. Allerdings
können kompliziertere Objekte nicht mehr praktikabel implizit dargestellt werden.

Das dreidimensionale Äquivalent von Rastergrafiken sind \emph{Voxelgrafiken}\footnote{Voxel: ``volumetric pixel''}. 
Analog zu Bildern sind dies dreidimensionale
Raster, an dessen Rasterpunkte Farbwerte o.ä. gespeichert werden. 
%Im Vergleich zu anderen Darstellungen, die nur --
%einen menschlichen Betrachter alleinig interessierenden -- Oberflächen abbilden, können auch komplexere
%innere Strukturen einfach abgebildet werden.
Damit können auch komplexere innere Strukturen einfach abgebildet werden -- andere Darstellungen bilden bloß
Oberflächen ab, da meist allein diese einen menschlichen Betrachter interessieren.
Der Nachteil von Voxelgrafiken ist jedoch der hohe Speicheraufwand für Voxeldaten. Diese werden
vor allem im medizinischen Bereich verwendet, da z.B. Geräte wie CT-Scanner ihre Daten, welche mit
höchstmöglicher Genauigkeit archiviert werden müssen, als Voxelgrafiken ausgeben.

\emph{Patches} sind, einfach gesagt, gekrümmte Vierecke. Solche Oberflächen lassen sich durch mathematische Formeln
beschreiben; Eigenschaften wie die Krümmung einer Oberfläche lassen sich durch Manipulation von Parametern der
Formeln abändern. Jeder Punkt auf der Oberfläche lässt sich exakt berechnen. Allerdings ist das Rendering von Patches
sehr aufwending.

Die einfachste Form der Darstellung ist die des \emph{Dreiecksnetzes} (engl. ``triangle mesh'' und kürzer ``mesh'').
 Diese bestehen aus einer Menge von Eckpunkten,
als \emph{Vertices} bezeichnet, sowie einer Menge von Dreiecken, wobei deren Ecken aus der Menge der Vertices stammen.
Einem Vertex ist mindestens eine Position im Raum, meist aber auch weitere Daten, die für die Oberflächendarstellung und
\mbox{-schattierung} verwendet werden,  zugeordnet~(\cite{watt_de}, S. 50).
Analog sind auch Dreiecken neben Referenzen zu den Eckvertices weitere Daten wie z.B. eine Oberflächenfarbe zugeordnet.

Um ein passgenaues Abschließen der Dreiecke zu sichern teilen sich in der Regel Ecken mehrerer Dreiecke ein
Vertex\footnote{Selten haben zwei Ecken in \emph{einem} Dreieck das selbe Vertex -- dies führt zu "`degenerierten"' Dreiecken}. 
Der Vorteil von Dreiecksnetzen ist deren Einfachheit. Insbesondere das Rastern von Dreiecken kann mit wenig Aufwand
implementiert werden. Auch können Oberflächen beliebig genau angenähert werden. Diese Eigenschaften sind aber auch
nachteilig: einige Oberflächen \emph{müssen} angenähert werden. So z.B. kann eine Kugel nicht perfekt durch ein Dreiecksnetz
abgebildet werden. 

% Bild Drahtgitter
\begin{figure}[h]
  \centering
  \includegraphics[width=10cm]{drahtgitter}
  \caption{Ein 3D-Würfel mit schattierten Seiten, als Drahtgittermodell und eine Aufteilung in Dreiecke. Die Vertices
  sind die Eckpunkte des Würfels.}
  \label{fig:wirecube}
\end{figure}

Hervorzuheben ist, dass auf die Berechnung von 3D-Grafiken spezialisierte Hardware 
ausschließlich mit Dreiecksdaten arbeiten -- die Hardware kann eigentlich nichts anderes zeichnen. Wegen der Einfachheit der Darstellung
können aber sehr viele Dreiecke in einer Sekunde gezeichnet werden. Gekrümmte Oberflächen (z.B. Kugeln, Patches) können unter Verwendung von Dreiecken visualisiert werden,
in dem die Oberfläche mit einer hohen Anzahl von Dreiecken angenähert wird.

%Auch zum Umrechnen von Voxel-Daten existieren Algorithmen, um daraus Dreiecksdaten zu erzeugen. % TODO Ref Marching cubes, Slides
Auch Voxel-Daten müssen zur Darstellung auf 3D-Hardware durch Dreiecksdaten angenähert werden,
entweder als Dreiecksnetz einer Oberfläche (``marching cubes''-Algorithmus,~\cite{watt_de} Abschn. 13.3.1)
oder durch Benutzung von Schnittflächen~(\cite{watt_de} Abschn. 13.6).

% TODO Skizze Rendering-Pipeline?

\subsection{Räume, Transformationen und Kamera}

In praktischen Anwendungen wird selten ein einziges Modell statisch dargestellt. In der Regel müssen mehrere Modelle
gleichzeitig dargestellt werden (z.B. ein aus mehreren Baugruppen zusammengesetztes Teil), wobei die Modelle
in bestimmter Weise zueinander positioniert dargestellt werden müssen. Weiterhin soll ein "`Bewegen"' um und in den 3D-Modellen
 möglich sein, also die Betrachtung von beliebigen Punkten aus. Dieser "`Blickpunkt"' des Betrachters ist die \emph{Kamera}.

Zu diesem Zweck werden verschiedene \emph{virtuelle Räume} definiert~(\cite{watt_de}, S. 166ff).
 So gibt es für jedes Modell ein \emph{Objektkoordinatensystem}\footnote{engl. ``object space''},
in dem sich alle Koordinaten des Modells befinden. 
Die Positionierung verschiedener Modelle zueinander wird im \emph{Weltkoordinatensystem}\footnote{engl. ``world space''} vorgenommen. 
Dazu wird jedem Modell eine \emph{Transformation} zugewiesen, welche Koordinaten aus dem Objekt- in das
Weltkoordinatensystem überführt. 

Eine Transformation wendet Verschiebungen, Skalierungen und Rotationen an. Als Repräsentation von Transformationen
verwendet man Matrizen, genauer $4 \times 4$-Matrizen: die dreidimensionalen Koordinaten des Modells werden
in homogene Koordinaten überführt, % Ref Watt (DE)
jede Koordinate wird dann mit der Transformationsmatrix multipliziert. Die Verwendung von homogenen Koordinaten
erlaubt das Darstellen von Verschiebungen in der Matrix. Mehrere Transformationen können angewendet werden, indem 
die entsprechenden Matrizen der Teiltransformationen in der gewünschten Reihenfolge zu der Gesamtmatrix konkateniert werden~(\cite{watt_de}, Kap. 1).

Die Übersetzung eines Dreiecksnetz-Modells in das Weltkoordinatensystem erfordert nur die Anwendung der Transformationsmatrix
auf die Koordinaten aller Vertices.

% TODO Hier Skizze 
Die Position des Betrachters wird durch das \emph{Kamerakoordinatensystem}\footnote{engl. ``eye space'' oder ``camera space''}
 bestimmt. Dies ist so definiert, dass der "`Blickpunkt"' am Koordinatenursprung des Systems liegt
und die "`Blickrichtung"' einer gegebenen Achse entspricht. 
Durch eine weitere Transformation werden Koordinaten im Weltkoordinatensystem in das Kamerakoordinatensystem
überführt um damit eine Positionierung des Betrachters an einer beliebigen Position in der Szene und den Blick in eine beliebige Richtung zu erlauben.
Die zugrundeliegenden Prinzipien sind die selben wie bei der Transformation aus dem Objektkoordinatensystem.

Der Blickpunkt ist ein Punkt in einem \emph{dreidimensionalem} Raum, eine Szene wird jedoch auf einem
\emph{zweidimensionalem} Bild dargestellt -- es besitzt also eine Ausdehnung in Breite
und Höhe, aber nicht Tiefe. Zu diesem Zweck wird eine \emph{Bildebene} in geringem Abstand zum Betrachter gesetzt,
welche als "`Projektionsfläche"' der Szene dient.

Weiterhin müssen Modelle \emph{perspektivisch verzerrt} werden. Bei den vorangegangenen Transformationen werden die Koordinaten
als homogene Koordinaten interpretiert. Homogene Koordinaten besitzen eine vierte Komponente $w$, die bei der Anwendung
der vorangegangenen Transformationen $1$ ist~(\cite{watt_de}, Kap. 1).
Für die perspektivische Verzerrung wird auf die Koordinaten im Kamerakoordinatensystem eine \emph{Projektionsmatrix} angewendet,
die als Besonderheit die $w$-Koordinate auf den Wert der $z$-Koordinate -- den Abstand von der Bildebene -- setzt.
Werden nun die transformierten Koordinaten durch die $w$-Komponente dividiert so ist dies effektiv die perspektivische Verzerrung.
Die Projektionsmatrix kann frei gewählt werden -- z.B. kann sie, durch Setzen der $w$-Koordinate auf $1$, auch orthographische
Projektionen darstellen.

\subsection{Texturen}

Zur Simulation von detaillierten Oberflächen werden \emph{Texturen} verwendet. Im Regelfall sind dies zweidimensionale
Bilder. Einem jeden Dreieck eines Modells ist ein (ebenfalls dreieckiger) Ausschnitt auf einer Textur zugeordnet. 
Die Zuordnung findet über \emph{Texturkoordinaten} statt, d.h. jedem Vertex ist ein weiteres Zahlenpaar zugeordnet,
welches einen Punkt auf der Textur angibt.
Beim Rendering wird nun der durch diese Koordinaten beschriebene Texturausschnitt auf die Oberfläche des Dreiecks 
"`gespannt"': für jedes gerenderte Pixel des Dreiecks wird die Position des zugehörigen Texturepixels (``texel'')
berechnet. Der Farbwert der Textur an dieser Position wird ausgelesen und dient als Farbwert des gerenderten Pixels~(\cite{watt_de}, S. 160).

\subsection{Shading}

Bei der visuellen Wahrnehmung spielt die Interaktion von wahrgenommen Oberflächen mit Lichtquellen eine wichtige
Rolle. Die Helligkeit einer Oberfläche variiert mit Abstand und Lage bezüglich einer Lichtquelle. 
Aus Helligkeitsunterschieden können auf Objekteigenschaften wie Drehung, Größe und Form sowie auf Oberflächeneigenschaften
wie deren Struktur geschlossen werden. Bei der Computergrafik ist die Berechnung der Beleuchtung einer Oberfläche
entsprechend wichtig: soll die Realität nachgeahmt werden, so sind Beleuchtungsberechnungen gewünscht, die möglichst
nah die Ergebnisse der in der Realität stattfindenden physikalischen Vorgänge nachbilden. Bei Anwendungen wie die
Konstruktion eines Bauteils werden dagegen Berechnungen verwendet, die nicht physikalisch korrekt sind, aber dafür
die dreidimensionale Form einfach erkennen lassen.

In der bisherigen Beschreibung der Darstellung von Oberflächen wurde die Berechnung der Beleuchtung einer
Oberfläche ausgelassen. Diese Berechnung wird \emph{Shading} (übersetzt "`Schattierung"') genannt~(\cite{watt_de}, S. 146, 198).
% Begr. Shading: , Schattierung: Watt (DE) 146, 198 -> Ergebnis ist "Intensität"
Beim Shading wird eine \emph{Lichtintensität}, d.h. die Intensität des reflektierten Lichts, für Punkte auf der
Oberfläche berechnet.

Um das reflektierte Licht zu berechnen wird mindestens der Oberflächenpunkt im Raum sowie die Lage der Oberfläche
-- dargestellt durch eine \emph{Normale} der Oberfläche an dem gegebenen Punkt -- benötigt.

% TODO Bilder
Es gibt verschiedene Strategien zur Berechnung von Lichtintensitäten. Die einfachste ist die Berechnung der Lichtintensität
eines Punktes des Dreiecks und die Verwendung dieses Wertes für das komplette Dreieck. Dieser Ansatz, ``flat shading'',
ist zwar schnell, hat aber eine sehr "`facettierte"' und kaum realistische Objektdarstellung zur Folge.
% TODO Ref auf Methoden

Wird die Intensität für jedes Vertex berechnet und dann über das Dreieck linear interpoliert ("`Gouraud-Shading"') so ist
das Ergebnis bereits weniger facettiert, allerdings mit Mehraufwand für Intensitätsberechnung und Interpolation verbunden.
Trotzdem haben Objekte bei Verwendung dieser Methode ein charakteristisches Aussehen, besonders die Kanten von Dreiecken lassen sich leicht erkennen.

Die aufwändigste Methode ist das Berechnen der Intensität für jedes dargestellte Pixel ("`Phong Shading"'), wobei
nur per Vertex verfügbare Werte über das Dreieck linear interpoliert werden (analog zur eigentlichen Intensität beim
Gouraud-Shading). Der Aufwand wird aber damit belohnt, dass keine Facetten und wenig Kanten sichtbar sind.
% @@@ Kanten sichtbar an Umriss

\section{Aufbau Hardware}

\subsection{Ablauf Echtzeit-Rendering}

\begin{figure}[h]
  \centering
  \includegraphics{3d_pipeline}
  \caption{Schematische Darstellung der 3D-Grafik-Pipeline}
  \label{fig:3d_pipeline}
\end{figure}

Die Ausgabe der Grafik soll in der Regel auf einem Computermonitor erfolgen - also als Rastergrafik auf einer zweidimensionalen Fläche.
Demgegenüber besitzen 3D-Modelle per Definition Koordinaten in einem dreidimensionalen Raum, deren Komponenten potentiell
aus der Menge der reellen Zahlen stammen. Es muss also eine Herunterrechnung, oder Projektion, vorgenommen werden. 

Diese Projektion wird nach der Vertexverarbeitung durchgeführt. Da auf alle Vertices die gleichen
Berechnungen angewendet werden, werden diese zur Geschwindigkeitssteigerung in Hardware in der Regel parallel 
auf mehreren Recheneinheiten ausgeführt. 
Des weiteren rechnen die benutzten Recheneinheiten im Allgemeinen mit Vektoren.
Die Vertexverarbeitung berechnet mehrere Werte pro Vertex. Minimal muss die Vertex-Koordinate in das Kamerakoordinatensystem
abgebildet werden. In der Regel werden aber weitere Werte berechnet ("`Vertexattribute"'), die als Eingabe der späteren Fragmentverarbeitung dienen.

Auf der neuesten Generation von Grafikkarten (GeForce 8) % etwas zu GraKa-Generationen sagen
ist ein weiterer Verarbeitungsschritt verfügbar, die "`Geometrieverarbeitung"'\footnote{engl. geometry shader}. 
Diese hat die Besonderheit, neue Dreiecke
mit beliebigen Koordinaten erzeugen zu können. Betrachtet man die Verarbeitungsschritte eines Modells auf der
Grafikkarte ohne Geometrieeinheit, so bemerkt man, dass diese "`statisch"' bezüglich der Vertices sind, da nur existierende
Werte manipuliert werden können. Gleiches gilt für Dreiecksdaten. Das \emph{Erzeugen} von Vertices kann auf diesen Grafikkarten
also nur durch die CPU erfolgen, woraufhin die Daten zur GPU übertragen werden.

 Steht aber der Schritt der Geometrieverarbeitung zur Verfügung, kann die GPU selbst Vertices und Dreiecke erzeugen
und auch entfernen. Dieser Schritt erlaubt die Implementierung von Algorithmen auf der Grafikkarte, die viel 
Flexibilität bei der Verarbeitung von Modelldaten, speziell der Dreiecksdaten, erfordern.

Nach der Vertex- bzw. Geometrieverarbeitung stehen die Koordinaten in das \emph{Kamerakoordinatensystem}\footnote{Betrachter befindet sich am
Ursprung} transformiert zur Verfügung. Diese werden nun auf das Monitor-2D-Rasterbild mit Hilfe einer einfachen linearen Projektion
abgebildet. Damit erhält man die Eckpunkte der Dreiecke im Koordinatensystem des Monitors mit denen die Dreiecke selbst
gezeichnet werden. Dies geschieht durch Rasterung der Dreiecke. Um die Farbe eines berechneten 
\emph{Fragments}\footnote{Ein Fragment ist ein Teil eines Pixels des Rasterbildes. Ein Pixel kann aus mehreren Fragmenten bestehen wenn 
Algorithmen zur Kantenglättung benutzt werden. Zum Verständnis reicht es jedoch aus, anzunehmen, dass ein Fragment genau einem Pixel entspricht.} zu 
bestimmen werden eine Reihe weiterer Rechnungen vorgenommen. Die Eingaben der Fragmentverarbeitung werden
durch perspektivisch korrekte lineare Interpolation aus den Vertexattributen der Drei\-ecks\-eck\-punk\-te  
berechnet. In den meisten Fällen wird in der Fragmentverarbeitung eine Textur ausgelesen
und mit den Vertexattributen durch Operationen kombiniert (z.B. Multiplikation, um eine beleuchtete Oberfläche zu simulieren).
Wie bei den Vertex-Berechnungen werden auch bei den Fragment-Berechnungen die gleichen Berechnungen auf eine Vielzahl
von Fragmenten zur gleichen Zeit angewendet. Auch die Fragment-Berechnungen erfolgen parallel auf mehreren Vektorrecheneinheiten.

\begin{figure}[h]
  \centering
  \includegraphics[scale=0.8]{triraster1}
  \qquad
  \includegraphics[scale=0.8]{triraster2}
  \qquad
  \includegraphics[scale=0.8]{triraster3}
  \caption{Rasterung eines Dreiecks: 1. Nach Transformation in das Koordinatensystem des Monitors.
  2. Vom Dreieck überlagerte Fragmente. 3. Ein Vertexattribut "`Grauwert"', über die Fragmente interpoliert.}
  \label{fig:triraster}
\end{figure}


%Alle Verarbeitungseinheiten sind auf aktueller Graphikhardware programmierbar.
\section{Berechnungsfrequenzen}
\label{berechnungsfrequenz_locker}

Für das Rendering eines 3D-Modells werden verschiedenartige Daten benötigt. So zuerst das Modell selbst, als Dreiecksnetz. Dazu
eine Reihe von Transformationen zur Abbildung zwischen Koordinatensystemen -- Objekt zu Welt, Welt zu Kamera und schliesslich
eine Projektion von Koordinaten im Kameraraum auf Bildschirmpixel. Typischerweise kommen noch weitere, vom Shading verwendete Daten --
wie eine Oberflächennormale, per Vertex definiert, und eine Textur -- hinzu.

Zu Beobachten ist, dass diese verschiedenen Daten in ihrer "`Veränderlichkeit"' variieren:
\begin{itemize}
\item Die verwendeten Transformationen gelten für das ganze 3D-Modell, verändern sich also \emph{per Mesh}.
\item Vertexdaten, wie Position im Objektkoordinatensystem oder Oberflächennormale, sind \emph{per Vertex}
unterschiedlich. Vor allem berechnete Vertexattribute, die Fragmentverarbeitung verwendet werden, werden
bloss per Vertex berechnet -- die eigentliche Eingabe der Fragmentverarbeitung wird aus den per-Vertex-Werten
interpoliert.
\item Texturdaten werden in der Fragmentverarbeitung ausgelesen, ein so bestimmter Wert ändert sich \emph{per Fragment}.
\end{itemize}

Aus diesen Beobachtungen leitet sich das Konzept der \emph{Berechnungsfrequenz}\footnote{Zuerst beschrieben in \cite{stanford_rtsl}.} ab.
Die Berechnungsfrequenz eines Wertes sagt aus, wie oft dieser berechnet werden müsste bzw. in welchem Verarbeitungsschritt
dies passiert. Je "`höher"' die Frequenz, desto häufiger muss ein Wert potentiell berechnet werden:
\begin{itemize}
\item Die theoretisch niedrigste Frequenz besitzen Verknüpfungen statischer Konstanten -- solche Ergebnisse müssen nur ein einziges Mal berechnet werden.
\item Die für 3D-Grafik nächsthöhere, relevante Frequenz ist die "`Meshfrequenz"': Transformationen werden in der Regel per Mesh spezifiziert,
eine Verknüpfung von zwei Transformationen muss nur einmal für ein Modell berechnet werden; auf die gesamte Ausführung einer Anwendung
müssen aber solche Transformation aber praktisch öfter als ein einziges Mal berechnet werden.
\item Als nächste Frequenz folgt die "`Vertexfrequenz"' für Werte, die von Vertexdaten abhängen. Augenscheinliches Beispiel sind Abbildungen
wie vom Objektkoordinatensystem in das Kamerakoordinatensystem. Da ein Modell in der Praxis mehr als ein Vertex besitzt,
ist ersichtlich, das Berechnungen in Vertexfrequenz öfter ausgeführt werden als solche mit Meshfrequenz.
\item Die höchstmögliche Frequenz ist die der "`Fragmentfrequenz"' für Werte, die per Fragment berechnet werden müssen.
Dies sind zum Beispiel aus Vertexdaten berechnete Werte, die sich nicht sinnvoll interpolieren lassen, oder Werte aus Texturen,
deren Zweck es ja ist, mehr Details zu ermöglichen, als es Vertexdaten allein zulassen würden.
Ein gerastertes Dreieck überspannt in der Regel mehrere Fragmente; aus diesem Grund werden per Fragment auszuführende Operationen
öfters berechnet als per Vertex.
\end{itemize}

Eine höhere Berechnungsfrequenz korrespondiert prinzipiell mit einer weiter hinten liegenden Verarbeitungsstufe in der Renderingpipeline.
Statische und Meshfrequenz sind praktisch sogar noch vor der Verarbeitung auf der GPU angesiedelt. Berechnungen in Vertexfrequenz (oder "`per Vertex"')
entsprechen Berechnungen auf der Vertexeinheit, analog werden Berechnungen in Fragmentfrequenz (oder "`per Fragment) auf der Fragmenteinheit ausgeführt.

Abbildung~\ref{fig:simple_cg} zeigt ein Programm-Paar für eine einfache Shadingberechnung in Cg. Die verschiedenen auftretenden Berechnungsfrequenzen
sind dabei farbig markiert. 

Die Nützlichkeit von Berechnungsfrequenzen besteht in der Verwendbarkeit als Werkzeug zur Optimierung des Renderings von 3D-Modellen.
Bei der Echtzeitgrafik ist ein grundsätzliches Bestreben, zum Zwecke schnellerem Renderings Operationen so selten wie möglich auszuführen.
Wird eine Operation, für die eine Berechnung per Vertex ausreichend wäre, auf der Fragmenteinheit ausgeführt, so bedeutet dies
eine Verschwendung von Rechenleistung. Bestimmt man nun für eine Beschreibung, wie ein Modell in den verschiedenen Renderingschritten zu
verarbeiten ist, die Frequenz jeder Operation, mit der diese ausgeführt werden muss, so können die Operationen optimal auf die
Verarbeitungseinheiten verteilt werden, ohne dass Rechenleistung verschwendet wird.

Programme in der hier beschriebenen Shadingsprache sind genau solche Beschreibungen der Verarbeitungsschritte; der implementierte Compiler
bestimmt für jede Operation eines Programms die nötige Berechnungsfrequenz und spaltet das Eingabeprogramm entsprechend auf.

\newcommand\freqPerMesh[1]{\framebox{#1}}
\newcommand\freqPerVert[1]{\colorbox{SpringGreen}{\textcolor{Black}{#1}}}
\newcommand\freqPerFrag[1]{\colorbox{BlueViolet}{\textcolor{White}{#1}}}
\begin{figure}[hp]
  \input{simple_cg}
  \caption{Ein Programm-Paar in Cg.}
  \centering
  \small Operationen und Werte sind von der Berechnungsfrequenz abhängig markiert (\freqPerMesh{Mesh}, \freqPerVert{Vertex}, \freqPerFrag{Fragment})
  \label{fig:simple_cg}
\end{figure}

\section{Zusammenfassung}

Bei der Echtzeit-3D-Graphik werden von der Graphikhardware als Dreiecksnetze vorliegende 3D-Modelle dargestellt.
Diese Modelle bestehen aus \emph{``Vertices''}, die die Eckpunkte von Dreiecken bilden. Bei der Darstellung eines
Modelles wird zuerst die \emph{Vertexverarbeitung} vorgenommen; dabei werden die Raumkoordinaten der Vertices transformiert
und weitere Berechnungen auf den Vertices zugeordneten Daten vorgenommen ("`Vertexattribute"').
Als nächsten Schritt der Darstellung werden Dreiecke bei der \emph{Rasterung} auf Fragmente (im Wesentlichen Pixel) des Ausgabegerätes abgebildet.
Bei dieser \emph{Fragmentverarbeitung} dienen als Eingaben die Ausgaben der Vertexverarbeitung, allerdings \emph{interpoliert}.
Es werden weitere Berechnung vorgenommen, um Details hinzuzufügen, für die eine Berechnung per Vertex zu "`grob"' wäre,
wie das "`aufziehen"' von \emph{Texturen} (Bilddaten) auf das 3D-Modell.

Die Verarbeitungsschritte "`Vertexverarbeitung"' und "`Fragmentverarbeitung"' sind beide programmierbar, die Ausgabe des Compilers
soll ein Programm-Paar aus Vertex- und Fragmentprogramm sein.


\chapter{Sprachspezifikation}
\label{langspec}

\input{langspec}

\chapter{Implementierung}
\label{implementation}

In diesem Kapitel wird auf die Implementierung des Compilers selbst eingegangen. 
Neben Scanner und Parser werden vor allem die verwendete Zwischencoderepräsentation
für die Weitergabe des Programmen zwischen den verschiedenen Arbeitsschritten des Compilers 
sowie die Komponente zur Auftrennung eines Programms -- das eigentliche "`Ziel"' dieser Arbeit -- beschrieben.

\section{Compiler-Aufbau}
\begin{figure}[h]
   \centering
  \includegraphics{compiler_structure}
  \caption{Schematischer Aufbau des Compilers}
  \label{fig:structure}
\end{figure}

Der Aufbau entspricht grösstenteils der Compiler-Standardarchitektur (Abbildung~\ref{fig:structure}): das \emph{Front-End} generiert nach Syntax- und Semantikanalyse
eine Repräsentation des Programms in einem \emph{Zwischencode}. Auf dieser Zwischencoderepräsentation werden im "`Middle-End"' % Ref wo das gesagt wird, oder besseres Wort
Optimierungen vorgenommen. Im letzten Schritt wird im \emph{Back-End} aus der optimierten Zwischencoderepräsentation der tatsächliche Zielcode generiert.

Besonderheit dieses Compilers ist der Schritt \emph{Auftrennung VP/FP}. Hier wird für jeden Befehl der Zwischencoderepräsentation untersucht, mit
welcher Berechnungsfrequenz~(siehe \ref{berechnungsfrequenz_locker} und \ref{Berechnungsfrequenz})
\footnote{Für "`Meshfrequenz"' wird kein Programm generiert, sie spielt aber eine Rolle bei der Aufspaltung. Generell ist das Konzept der Aufspaltung auch auf weitere Frequenzen erweiterbar.}
jeder Befehl des Programms ausgeführt werden muss - mit anderen Worten,
es wird untersucht, welche Befehle auf der Vertex-Einheit oder der Fragment-Einheit ausgeführt werden müssen. Mit diesen Informationen kann
das Programm entsprechend in ein Vertex- und ein Fragment-Programm aufgeteilt werden. Da zur Laufzeit auch ein "`Übergeben"' von Ausgaben
des Vertexprogramms an Eingaben des Fragmentprogramms stattfindet wird auch eine den Vertex-Ausgaben zu Fragment-Eingaben
abbildende "`Schnittstelle"' generiert.

Die Programme werden vom Aufspalter in Zwischencode ausgegeben und können noch einmal optimiert werden. % Irgendein besonderer Vorteil?
Abschließend werden ein Fragment- und ein Vertexprogramm im gewünschten Zielcode ausgegeben\footnote{Diese Implementierung benutzt den
gleichen Generator für beide Programme, prinzipiell könnten diese jedoch mit verschiedenen Generatoren ausgegeben werden.}.

\section{Implementierungsdetails}

Als \emph{Programmiersprache}, in der die hier beschriebene Implementierung verfasst ist, wurde C++ gewählt.
Gründe dafür sind:
\begin{itemize}
\item Die Flexibilität der Sprache und deren reichhaltige Standardbibliothek,
\item hohe Portabilität (C++-Compiler sind für praktisch jede Plattform verfügbar),
\item eine reichhaltige Palette an von Dritten hergestellter Bibliotheken,
\item die einfache Verwendbarkeit in anderen Programmiersprachen (direkt oder über eine C-kompatible Schnittstelle).%,
%\item nicht zuletzt die Gewandheit des Autors dieser Arbeit in C++.
\end{itemize}
 
Um eine Wiederverwendung des Compilers zu vereinfachen wurde dieser im Wesentlichen als eine \emph{Bibliothek} realisiert;
eine "`Kommandozeilenversion"' des Compilers setzt auch auf diese Bibliothek auf.
 
Zur Sicherstellung der fortwährend korrekten Funktionsweise aller Module des Compilers wurden entwicklungsbegleitend 
jeweils \emph{Tests} der Module geschrieben (Black-Box und White-Box); Ausführen der Tests war regelmässiger Teil des Entwicklungsprozesses.
 
\section{Scanner}

Der \emph{Scanner} wandelt die als Byte-Strom vorliegende Eingabe in eine Folge von "`Tokens"'.
Ein Token ist eine der in Abschnitt~\ref{Lexikalische Einheiten} aufgezählten lexikalischen Einheiten, ein bekanntes Symbol (Operatoren etc.) oder Schlüsselwort. 
Leerzeichen (``Whitespace'') und Kommentare werden bereits vom Scanner ignoriert (d.h. für diese werden keine Tokens produziert).

Der Scanner folgt einer typischen Implementierung wie sie z.B. in \cite{wirth_compiler} beschrieben ist. Auf einige beachtenswerte Aspekte
wird im folgenden eingegangen.

\paragraph{Eingabe.} Da die Spezifikation von Unicode als Eingabe ausgeht, arbeitet der Scanner entsprechend auf der Basis von Unicode-kodierten Zeichen.
Der Byte-Strom der Eingabe wird also in einem Schritt noch vor dem Scanner in einen "`Unicode-Strom"' umkodiert\footnote{Verwendet wird dazu die Bibliothek ICU,
\url{http://site.icu-project.org/}}.

\paragraph{Schlüsselwörter.} Erkennt der Scanner einen Bezeichner, wird auch geprüft, ob es sich um ein Schlüsselwort handelt. Ist dies der Fall
wird im Token eine dem Schlüsselwort eindeutig zugeordnete ID gespeichert.

%Die erste Ausnahme
Eine Ausnahme allerdings bilden die Schlüsselwörter für Vektor- und Matrixtypen (Abschnitte~\ref{Vektortypen}, \ref{Matrixtypen}). Diese entsprechen
jeweils dem Muster $\mathit{typ}\mathrm{N}$ bzw. $\mathit{typ}\mathrm{N}\mathit{x}\mathrm{M}$ (mit $N \in 1 \dots 4, M \in 1 \dots 4$).
Da eine eigene ID für jeden Vektor- oder Matrix insgesamt 20 weitere IDs pro Basis-Typ nach sich ziehen würde -- wobei später noch jeder ID wiederum
die ursprünglichen Werte für $N$ und $M$ nochmals zugeordnet
werden müssten -- wird im generierten Token vermerkt, ob es sich um einen Vektor- oder Matrixtyp handelt.
Dazu überprüft der Scanner, ob ein Bezeichner den angegebenen Muster für Vektor- bzw. Matrixschlüsselwörtern entspricht.
Weiterhin werden bereits $N$ bzw. $M$ aus den Bezeichnern extrahiert und ebenfalls vermerkt.

\begin{figure}[h]
   \centering
  \lstinputlisting[language=C++]{snips/LexerToken.txt}
  \caption{Daten eines vom Scanner ausgegebenen Tokens}
  \label{fig:LexerToken}
\end{figure}

% Die zweite Ausnahme bilden Attributnamen~(\ref{Attribute}) inklusive Swizzles~(\ref{Vektorattribute}). Diese sind teilweise recht allgemein, und
% es erscheint wünschenswert, Bezeichner zuzulassen, die Attributnamen entsprechen -- z.B. ``length'', das auch ein Arrayattribut ist, und einbuchstabige
% Bezeichner wie ``x'', ``y'' etc., welche auch Vektorattribute (Swizzles) sind. Syntaktisch gibt es keine Mehrdeutigkeiten zwischen Attributen und
% anderen Bezeichnern -- ein Attribut kann \emph{nur} rechts eines \op{.} auftauchen, ein anderer Bezeichner dort nie.


Weiterhin schreibt die Spezifikation vor, dass zwei Bezeicher als identisch betrachtet werden, wenn sie kanonisch äquivalent im Sinne von Unicode sind.
Zu diesem Zweck werden alle Bezeichner vom Scanner nach einer von Unicode vorgegebenen Form normalisiert~(\cite{unicode}, Annex \#15).

\section{Parser}

Der \emph{Parser} untersucht den vom Scanner gelieferten Strom von Tokens auf syntaktische Strukturen.
Es wird überprüft, ob der Token-Strom gültig im Sinne der in der Sprachspezifikation gegebenen Sprache ist --
sonst liegt ein \emph{Syntaxfehler} vor.

Während der Überprüfung werden auch syntaktische Elemente -- grundsätzlich Terminale wie Bezeichner oder numerische Werte -- extrahiert.
Diese werden bei der \emph{semantischen} Verarbeitung benötigt.

%- Lookahead: unendl.
%- Grammatik: kontextfrei, rechtsrekursiv

%\subsection{Eigenschaften der Grammatik}

%Die Grammatik ist kontextfrei. Die Regeln sind rechtsrekursiv.

\subsection{Aufbau des Parsers}

\newcommand\rulelink[1]{\glq\texttt{\detokenize{#1}}\grq~(\ref{#1})}

Der Parser ist nach der Methode des rekursiven Abstiegs (beschrieben in \cite{wirth_compiler}) handprogrammiert.
Der Aufbau spiegelt im Wesentlichen die Struktur der Regeln wieder -- viele haben ein direktes Gegenstück in einer Methode des Parsers.

\paragraph{Umgang mit Mehrdeutigkeiten:}
An einigen Stellen der Grammatik gibt es Mehrdeutigkeiten.
Werden beim Parsen eines \rulelink{programm_statements} die Tokens \glq\texttt{typ BEZEICHNER}\grq~(\ref{typ}, \ref{BEZEICHNER})  erkannt,
so kann es sich entweder um die Regel \rulelink{funktion_definition} oder um \rulelink{dekl_var} handeln.
Andere Fälle von Mehrdeutigkeiten sind \rulelink{dekl_var} oder \rulelink{kommando} in \rulelink{block},
\rulelink{funktion_aufruf} oder \rulelink{BEZEICHNER} in \rulelink{asdr_basis}.

Solche Mehrdeutigkeiten lassen sich entweder in der Implementierung des Parsers oder durch Abändern der Grammatik lösen.

Bei der Parser-Lösung werden einfach weitere Tokens betrachtet. Im Falle eines  \rulelink{programm_statements}
wird auch das nächste Token nach \glq\texttt{typ}\grq{} und \glq\texttt{BEZEICHNER}\grq{} überprüft:
handelt es sich um \glq\texttt{(}\grq, ist die anzuwendende Regel \rulelink{funktion_definition};
handelt es sich um \glq\texttt{=}\grq, \glq\texttt{,}\grq{} oder \glq\texttt{;}\grq{} ist die anzuwendende Regel \rulelink{dekl_var};
andere Tokens sind ein Syntaxfehler. Eine Pseudo-Code-Version der Implementierung ist in Abbildung~\ref{fig:ParseProgramStatements}
aufgelistet.

In den Implementierungen der Regeln \rulelink{block} und \rulelink{asdr_basis} wurde analog verfahren.

Bei der Lösung von Mehrdeutigkeiten durch Abändern der Grammatik muss eine Regel erstellt werden,
die mit der mehrdeutigen Token-Sequenz beginnt. Dahinter werden als Alternativen neue Regeln angefügt,
die aus den "`Resttokens"' der ursprünglich mehrdeutigen Regeln bestehen müssen. % Hier ne Ref wäre vllt gut

Allerdings wird damit die Lesbarkeit der Grammatik eingeschränkt; nur für die Regel \rulelink{ausdruck} wurde dieser Ansatz verfolgt.
Für die anderen Regeln wurde das "`Vorausschauen"' von Tokens gewählt, da es in diesen Fällen einfach zu implementieren war
und die Grammatik besser lesbar bleibt.

\begin{figure}[!h]
   \centering
  \lstinputlisting[language=Java]{snips/ParseProgramStatements_pseudo.txt}
  \caption{Beispiel einer Parsing-Methode mit Auflösung von Mehrdeutigkeiten}
  \label{fig:ParseProgramStatements}
\end{figure}

\paragraph{Semantische Verarbeitung:}
% Die semantische Verarbeitung wird an ein Interface vom Typ \verb+SemanticHandler+ übergeben.
% Dieses Interface übernimmt die verschiedenen Aspekte der semantischen Verarbeitung, von der Verwaltung der
% Symboltabelle bis zu einer geeigneten internen Repräsentation von Ausdrücken.
Die semantische Verarbeitung wird von einer weiteren Komponente -- hier ``semantic handler'' genannt -- vorgenommen. 
Dieses Komponente übernimmt die verschiedenen Aspekte der semantischen Verarbeitung, von der Verwaltung der
Symboltabelle bis zu einer geeigneten internen Repräsentation von Ausdrücken. Die in der Komponente gespeicherten Informationen sind
in einem Rückkanal dem Parser zugänglich; so werden diese zum Beispiel benutzt um festzustellen, ob ein Bezeichner ein
Typ-Alias oder eine Funktion identifiziert.
Die Ausgabe des ``semantic handlers'' ist eine Zwischencoderepräsentation des Programms.

% \verb+SemanticHandler+ besitzt Methoden, um syntaktische Elemente -- wie Bezeichner und numerische Literale -- in Objekte 
% einzukapseln. Diese Objekte wiederum werden bei der Verarbeitung anderer syntaktischer Elemente
% zurück an das Interface übergeben. % Wenn Code-Schnipsel dann hier verweisen

% Beispiel: Bei einem Ausdruck \verb+a * 2+ werden von \verb+SemanticHandler+ zunächst Repräsentationen für
% \verb+a+ und \verb+2+ erfragt. Zurückgegeben werden Repräsentationen von "`Ausdrücken"'. Diese wiederum
% dienen als Argumente, um eine Repräsentation einer Multiplikation zu erhalten. Diese letzte Repräsentation kann
% dann überall dort verwendet werden, wo Ausdrücke erwartet werden: Zuweisungen, Funktionsparameter etc.

% Vom der \verb+SemanticHandler+-Implementierung zum Parser gibt es auch einen "`Rückkanal"'. Dies ist nötig, da bei einigen
% Konstrukten bekannt sein muss, ob ein Bezeichner eine Variable, eine Funktion oder einen Typ identifiziert:
% Das Ausdruck \verb+foo (1)+ ist, je nachdem ob \verb+foo+ eine Funktion, ein Typ-Alias oder eine Variable bezeichnet,
% entsprechend ein ein Funktionsaufruf, der Aufruf eines Typ-Konstruktors, oder ein ungültiger Ausdruck.

Verglichen mit dem "`klassischen"' Ansatz der semantischen Verarbeitung -- Parser erzeugt Abstract Syntax Tree (AST) als ersten Schritt,
Semantische Analyse erzeugt Zwischencoderepräsentation im zweiten Schritt -- finden sich kleine Teile der semantischen
Analyse im Parser; die Erstellung eines ASTs wird übergangen, der ``semantic handler'' nimmt mit den vom
Parser übergebenen Informationen die restliche semantische Analyse vor und erzeugt sofort eine Zwischencoderepräsentation (beschrieben in Abschnitt~\ref{zcr}).

Die Erstellung eines AST wurde übergangen, da diese als unnötig angesehen wurde: eine direkte Ausgabe der Zwischencoderepräsentation(ZCR)
wurde als einfacher umzusetzen und für die weiteren Arbeitsschritte im Compiler als ausreichend angesehen. 
Insbesondere Optimierungen sind in der gewählten ZCR einfacher vorzunehmen als auf
einem AST. Auch werden in der ZCR wichtige semantische Informationen, wie Typen von Werten, Funktionssignaturen etc. gespeichert,
es tritt also kein Informationsverlust im Vergleich zu einem AST auf.

Weiterhin wurde die Implementierung so gestaltet, dass die Komponent des ``semantic handler'' relativ einfach austauschbar ist.
Sollte also notwendig werden, dass der Compiler einen AST des Programms erstellt, so wäre es prinzipiell möglich,
einen ``semantic handler'' zu schreiben der genau dies tut.

% Die Idee hinter dem \verb+SemanticHandler+ ist eine möglichst vollständige Trennung zwischen syntaktischer
% und semantischer Verarbeitung. Eine minimale Implementierung könnte intern eine
% AST-Repräsentation generieren (allerdings benötigt der Parser trotzdem auch einige semantische Informationen über
% Bezeichner).

% \begin{figure}[h]
%    \centering
%   \lstinputlisting[language=Java]{snips/ParseIf_pseudo.txt}
%   \caption{Zusammenspiel Parser und \texttt{SemanticHandler}: Parsen einer Verzweigung}
%   \label{fig:ParseIf}
% \end{figure}

\paragraph{Fehlerbehandlung:}
In der Implementierung wird die Fehlerbehandlung bei der syntaktischen wie auch semantischen Verarbeitung wird über \emph{Ausnahmen}
realisiert. Die Parser-Komponente selbst fängt dabei Ausnahmen ab, um zu gewährleisten, dass möglichst viel eines
Programms verarbeitet wird, um möglichst viele potentielle Fehler aufzudecken (wie in \cite{wirth_compiler} empfohlen):
tritt z.B. eine Ausnahme während der Verarbeitung eines Block-Kommandos auf, setzt der Parser die
Verarbeitung nach dem nächsten Semikolon -- also mit dem nächsten Kommando -- fort (sofern kein Ende
des Blockes festgestellt wird).
Die abgefangen Ausnahmen werden jedoch nicht verworfen, sondern an ein Objekt zur Fehlerbehandlung
übergeben um eine Nachricht für den Benutzer darzustellen.

% \paragraph{Implementierung \texttt{SemanticHandler}:}
% In der vorgenommen Implementierung von \verb+SemanticHandler+ wird gleich eine Umsetzung in die Zwischencoderepräsentation vorgenommen
% (Beschreibung siehe Unten). Die Generierung eines ASTs als Zwischenschritt wurde als unnötig angesehen.
% Die Zwischencoderepräsentation erhält auch wichtige semantische Eigenschaften (wie Typinformationen) und
% die Verarbeitungsschritte "`Auftrennung"' und "`Optimierung"' lassen sich auf der Zwischencoderepräsentation besser vornehmen.

% Zuordnung Variable <-> akt. Register in Symboltabelle

\section{Zwischencoderepräsentation}
\label{zcr}

\input{ir_commands}

% Abstrakte(s) Beispiel(e): Quellcode + resultierende Zw.rep.

\subsection{Vorlagen der Zwischencoderepräsentation}

Als Vorlagen für die hier vorgestellte Zwischencoderepräsentation dienten das ``LLVM Instruction Set''~(\cite{LLVM:CGO04}),
SafeTSA~(\cite{SafeTSA}) und ``SIMPLE'' des McCAT Compiler-Projektes~(\cite{SIMPLE}).

% "Inspirationen": LLVM, Amme's SSA, GIMPLE/SIMPLE

%Das \emph{LLVM Instruction Set} (hier kurz ``LLVM'') 
\paragraph{LLVM}: LLVM ist ein \emph{Framework} für Compiler. Insbesondere will es ermöglichen, Optimierungen
eines Programms über dessen ganzen "`Lebenszyklus"' (inklusive Link- und Laufzeit) zu ermöglichen.

Das \emph{LLVM Instruction Set} ist der ausgegebene "`Objektcode"'. Das Programm wird -- ähnlich Maschinen-
oder Bytecode -- als eine Folge von einfachen Instruktionen auf Registern repräsentiert. 
Allerdings gibt es eine unbeschränkte Anzahl von typisierten Registern. Typumwandlungen sind immer explizit.
Die Instruktionen sind in SSA-Form.

% LLVM:
% - nicht gedacht als allg. Compiler-IR
% - keine Typsicherheit (nicht mehr als Maschinencode)
% - 
% - LLVM provides an inﬁnite set of typed virtual
% registers which can hold values of primitive types (Boolean,
% integer, ﬂoating point, and pointer). The virtual registers
% are in Static Single Assignment (SSA) form [15]. LLVM
% is a load/store architecture: programs transfer values be-
% tween registers and memory solely via load and store op-
% erations using typed pointers. The LLVM memory model is
% described in Section 2.3.
% - Opcodes: 3-Adress-Form
% - Ich->Mehr Opcodes als LLVM (unäre Op., Vektor-Op.)
% - Expliziter Kontrollflussgraph
% - abgeleitete Typen: Zeiger, Arrays, Structs, Funktionen
% - Typumwandlungen: explizit

% expliziter Kontrollfluss == keine GOTOs, sondern "Verweise" auf Blöcke/nächsten Schritt

\paragraph{SafeTSA:} Eine Art Objektcode, hauptsächlich zur Benutzung
als "`mobiler"' Code, d.h. zur Übertragung von Programmcode über Netzwerke wie das Internet.
Das Design von SafeTSA ist inhärent sicher. Bösartige Manipulationen von Programmen, die zu
problematischem Verhalten wie die Benutzung von undefinierten Werten oder Aliasing von Werten
eines anderen Typs führen, sind nicht möglich bzw. durch eine einfache Verifizierung feststellbar.

Die Instruktionen basieren auf der SSA-Form. Entsprechend gibt es eine beliebige Zahl von Registern.
Register sind in mehrere Sätze organisiert, ein Satz pro Typ. Instruktionen können nur auf einen
spezifischen Registersatz zugreifen. Verschiedene Instruktionsblöcke besitzen eigene Registersätze.

% SafeTSA:
% - erweiterte SSA
% - Zugriff auf Werte über Abstand in Dominatorbaum
% - Typtrennung: mehrere Registersätze; implizite Auswahl des Registersatzes
% - typisierter Konstantenpool
% - Registersätze per Basisblock
% - 

\paragraph{SIMPLE:} Als "`echte"' Compiler-Zwischencoderepräsentation für einen C-Compiler entwickelt
stellt sie Programme auf sehr hoher Ebene dar. Ausdrücke sind nicht in der SSA-Form, allerdings
"`vereinfacht"' auf zwei Operanden und einfache Strukturzugriffe. Symboltabelle und Typinformationen
sind erhalten. Typumwandlung, und andere in C implizite Verhalten, müssen explizit ausgedrückt werden.

% SIMPLE:
% - expliziter Kontrollfluss/zusammengesetzte Flusskontrollstatements
% - Typinformationen
% - klare Semantik (keine impliziten Verhalten wie autom. casts)
% - einfache Referenzen
% - einfache Statements

\paragraph{Zusammenfassung:}
Die gewählte Zwischencoderepräsentation ist größtenteils ein "`Querschnitt"' aus den obigen Repräsentationen
%(allerdings auch mit Aspekten aus keiner Vorlage, wie die Behandlung von Arrays).
(allerdings auch mit eigenständig entwickelten Aspekten, wie die Behandlung von Arrays).
Die meisten Eigenschaften
teilt die Zwischencoderepräsentation mit dem LLVM Instruction Set; chronologisch wurde dieses jedoch als letzte
Repräsentation betrachtet. Aus SafeTSA und SIMPLE stammen deshalb grundsätzliche Aspekte der Zwischencoderepräsentation 
-- einfache Statements, SSA-Form, separate Registersätze.

Anzumerken ist, dass die Shadingsprache keine zufälligen Speicherzugriffe oder Zeiger/Referenzen erlaubt.
Im Umfang ist sie teilweise beschränkt -- es gibt keine Strukturtypen --, besitzt aber als "`Eigenheit"' Vektortypen.
LLVM, SafeTSA und SIMPLE wurden für "`Maschinen"' entwickelt, die die Verwendung von Zeigern erlauben. Entsprechend
stellen sie Lösungen für Probleme, wie die Aliasing\footnote{Zugriff auf ein Datum über mehrere verschiedene Zeiger}-Analyse oder typsichere Speicherzugriffe, bereit, die mit
der hier spezifizierten Shadingsprache nicht vorkommen. Insofern sind diese Repräsentationen hier nicht
mit ihren vollständigen Fähigkeiten beschrieben.

\subsection{Aufbau}

Bei der Gestaltung der \emph{Zwischencoderepräsentation} sollten folgende Rahmenbedingungen erfüllt werden:
\begin{itemize}
\item \emph{Eignung als Zwischenrepräsentation zwischen verschiedenen Arbeitsschritten des Compilers}.
Um die Komplexität des Compilers und den damit verbundenen Implementierungsaufwand klein zu halten
sollte \emph{ein} Format zur Zwischenrepräsentation für den Compiler-internen Austausch verwendet werden.
(Andere Compiler verwenden verschiedene Formate zwischen Verarbeitungsschritten, siehe z.B.~\cite{SIMPLE}.)
\item Dies schliesst auch \emph{Eignung für Optimierungen} ein. Es sollten also genug Information enthalten sein,
um verschiedene Optimierungsalgorithmen umzusetzen. Idealerweise sollte die Zwischencoderepräsentation
diese Umsetzung von Optimierungen möglichst unterstützen und vereinfachen.
% \item Eignung als Ausgabe für Auftrenner?
\item Auch der \emph{Aufbau} sollte möglichst \emph{einfach} sein, damit Programme in der Zwischencoderepräsentation 
unkompliziert traversiert und manipuliert werden können.
\end{itemize}

Die Optimierbarkeit wird unterstützt, in dem der Zwischencoderepräsentation die \emph{``Single Static Assignment''-Form} (SSA, siehe~\cite{ssa1} und \cite{ssa2})
für Ausdrücke zugrunde liegt. Der gewünschte einfache Aufbau äußert sich darin, dass Befehle eines Programmes
in einer einfachen Reihung gespeichert werden -- ohne Sprungmarken oder ähnliches. Verzweigungen und Schleifen werden
durch "`komplexe"' Befehle realisiert (die intern wiederum Reihungen von Befehlen enthalten).

Das "`Grundelement"' der Zwischencoderepräsentation ist eine "`Sequenzen"'. Eine Sequenz besteht aus "`Operationen"',
die auf "`Registern"' arbeiten. Register sind \emph{typisiert}, es gibt getrennte Registersätze, ein Satz für jeden verwendeten Typ. 
Der Aufbau einer Sequenz ist in Abbildung~\ref{fig:ir_sequence} schematisch dargestellt.

Die in Operationen gespeicherte Registeridentifikation verweist auf den zugehörigen Registersatz, Typinformationen bleiben also erhalten.
% Satz teil von Register-ID
%Jedes Register besitzt ausserdem einen Namen; dieser wird aber nur verwendet, um generierten Code lesbarer zu machen.

\begin{figure}[h]
   \centering
  \includegraphics{ir_sequence}
  \caption{Teile einer Sequenz}
  \label{fig:ir_sequence}
\end{figure}

Der wesentliche, von der SSA-Form entliehene, Aspekt ist, dass ein Register nur von \emph{einer} Operation der Sequenz beschrieben werden darf
(im Weiteren "`Register-Zuweisungs-Bedingung"' genannt).

Im Gegensatz zu einer "`reinen"' SSA-Form gibt es jedoch keine $\phi$-Operation. Stattdessen werden $\phi$-Operation bereits "`aufgelöst"'
gespeichert: soll z.B. bei einer Verzweigung eine Variable in einem Zweig verändert werden, so werden in beiden Zweigen Zuweisungen zum
entsprechenden Register generiert. Ein Zweig enthält die Zuweisung des neuen Wertes, der andere die Zuweisung des alten Wertes.

Anzumerken ist, dass dieses Auflösen nicht die oben gegebenen "`Register-Zuweisungs-Bedingung"' verletzt, da Verzweigungen und Schleifen
jeweils als \emph{eine} Operation in der Sequenz, in der sie verwendet werden, gelten.

Die Sichtbarkeit von Registern ist auf die Sequenz, in der sie deklariert wurden, beschränkt.
%Insbesondere können auf diese nicht implizit
%aus verschachtelten Blöcke (wie sie auch bei Bedingungen oder Schleifen vorkommen) zugegriffen werden. 
Insbesondere gibt es Sequenzoperationen, die andere Sequenzen einschachteln (Verzweigungen, Schleifen, Sequenzschachtelung).
Aus solch eingeschachtelten Blöcken kann \emph{nicht} implizit auf die Register aus dem umgebenden Block
zugegriffen werden.

Stattdessen werden zu eingeschachtelten Blöcken eine Zuordnung zwischen Registern aus dem umgebenden Block
("`extern"') und
Registern des eingeschachtelten Blockes ("`lokal"') gespeichert.
Wie genau die Abbildung von Werten von "`externen"' an "`lokale"' Register statfindet ist ein Implementierungsdetail, dass dem Generator obliegt;
das Verhalten muss bloss einem "`umleiten"' von Lese- oder Schreibzugriffen von den angegebenen lokalen auf die zugeordneten externen
Registern entsprechen.
%Wie genau die Übergabe von Werten von "`externen"' an "`lokale"' Register statfindet ist ein Implementierungsdetail, dass dem Generator obliegt;
%das Verhalten muss jedoch semantisch äquivalent zu einem Kopieren der externen Eingaberegister in lokale Register Anfang des Blockes
%und analog am Ende zu einem zurückkopieren von lokalen Registern in die externen Ausgaberegister sein.

Abbildung~\ref{fig:ir_seq_block_nest} zeigt eine Sequenz, in der die zweite Operation eine Sequenzschachtelung ist.
Der Sequenzoperation sind neben einem Verweis auf die auszuführende Sequenz auch Registerzuordnungen von
Registern der äusseren (einschachtelnden) zu Registern der inneren (eingeschachtelten) Sequenz.

\begin{figure}[h]
   \centering
  \includegraphics{ir_seq_block_nest}
  \caption{Schema einer Sequenzschachtelung}
  \label{fig:ir_seq_block_nest}
\end{figure}

\paragraph{Funktionen:}
Eine Funktion der Zwischencoderepräsentation besteht aus einem eindeutigem Bezeichner, einer Liste von Eingabeparametern,
einer Liste von Ausgabeparametern und einer Sequenz mit den eigentlichen Funktionsoperationen. Abbildung~\ref{fig:ir_function}
ist eine schematische Abbildung einer Funktion.

%Jede Überladung einer Funktion wird in der Zwischencoderepräsentation durch einen eindeutigen Bezeichner identifiziert.
%Dieser wird aus dem ursprünglichen Bezeichner sowie einer aus den Parametertypen generierten "`Signatur"' konstruiert.
Bei überladenen Funktionen muss die auszuführende Variante der Funktion in der Zwischencoderepräsentation
explizit angegeben werden.
Aus diesem Grund wird in der Zwischencoderepräsentation jede Überladung einer Funktion durch einen eindeutigen Bezeichner identifiziert.

Parameter werden mit einem Mechanismus, der der Behandlung "`externer"' Register in einem eingeschachteltem
Block ähnelt, übergeben. Die Parameterlisten enthalten zu jedem Eingabeparameter ein lokales Register, in dem die
Sequenz den Wert des Parameters "`erwartet"'. Analog wird jedem Ausgabeparameter ein Register zugeordnet,
in dem bei Verlassen der Funktion der zurückzugebende Wert liegt.
(Die genaue Umsetzung dieses Verhaltens ist ein Implementierungsdetail, dass dem Generator obliegt.)

Ein Parameter, der gleichzeitig Ein- wie auch Ausgabeparameter ist, wird "`verdoppelt"', d.h. es wird daraus
ein nur-Eingabe- sowie auch ein nur-Ausgabe-Parameter generiert. Bei Funktionsaufrufen werden den beiden
Parametern auch entsprechend verschiedene Register zugeordnet.

\begin{figure}[h]
   \centering
  \includegraphics{ir_function}
  \caption{Schema einer Funktionsbeschreibung}
  {\small für eine Funktion deklariert mit \texttt{float lerp (float a, float b, float factor)}.}
  \label{fig:ir_function}
\end{figure}

\paragraph{Globale Variablen:}
Echte globale Variablen sind nicht vorgesehen. Sie werden nachgebildet, in dem in einer Funktion gelesene globale Variablen
auf spezielle, "`versteckte"' Eingabeparameter abgebildet werden. Geschriebene globale Variablen werden
auf spezielle Ausgabeparameter abgebildet. Nur in der Eintrittsfunktion werden globalen Variablen tatsächlich
"`eigene"' Register zugewiesen. Im Prinzip sind "`globale"' Variablen bloss "`versteckte"' lokale Variablen in
der Eintrittsfunktion.

Damit müssen globale Variablen nicht besonders von Optimierungsschritten u.ä. berücksichtigt werden.
Insbesondere müssen keine "`Seiteneffekte"' von Funktionen ermittelt werden: manipuliert eine Funktion eine "`globale"' Variable,
so erhält sie in der Zwischencoderepräsentation bloss einen weiteren Ausgabeparameter.
Betrachtet man den Aufruf dieser Funktion so wird nur eine weitere Variable beschrieben.

Optimierungsschritte wie Constant Propagation oder Dead Code Elimination. aber auch der Auftrennungs-Schritt werden vereinfacht,
da nur "`lokale"' Variablen berücksichtigt werden müssen; gleichzeitig werden als global deklarierte Variablen
von solchen Verarbeitungsschritten korrekt behandelt.

%Stattdessen werden zu eingeschachtelten Blöcken gespeichert, welche Register von dem Block gelesen oder
%beschrieben werden sollen

%Soll ein Register in einem eingeschachteltem Block gelesen oder beschrieben werden, 

\paragraph{Behandlung von Arrays:}
Arrays werden als "`ein"' Wert behandelt. D.h. eine Zuweisungsoperation kopiert immer ein ganzes Array.
Das Lesen einzelner Elemente geschieht mit Hilfe der Operation "`Extraktion eines Arrayelements"' ($\mathtt{getelem}$).

Zum Schreiben eines Elements gibt es die Operation "`Änderung eines Arrayelements"' ($\mathtt{setelem}$):
%diese kopiert alle Elemente eines Arrays in das Zielarray \emph{außer} das Element eines gegebenen Indexes;
%im Zielarray wird dort der zu schreibende Wert abgelegt.
diese kopiert alle Elemente, bis auf das zu ändernde Element, eines Arrays in das Zielarray;
dort wird am gegebenen Index der zu schreibende Wert abgelegt.
Dieser Ansatz wurde gewählt, weil er sehr gut in das "`SSA-Prinzip"' passt.
Bei der direkten Umsetzung eines Zugriffs auf Array-Elemente (Ausdrücke wie eine Zuweisung "`$a[i] = x$"') ist es schwierig, sicherzustellen, dass
jedes Element von $a$ wie verlangt nur einmal beschrieben wird (insbesondere bei Schleifen); es
müsste für jedes Array-Element individuell "`verfolgt' werden, ob es beschrieben wurde.
Ein solches Verfolgen wird weiterhin schwieriger, sobald die Array-Größe nicht bekannt ist
-- die spezifizierte Sprache sieht dies vor. Das betrachten eines Arrays als "`einen"' Wert macht es hingegen einfach,
die Bedingung "`nur eine Zuweisung"' einzuhalten und zu überprüfen.
% Andere Alternativen? Wie in LLVM, SafeTSA? Wer hat sich noch über Arrays Gedanken gemacht?

Für manche Optimierungen ist es trotzdem von Vorteil, die einzelnen Elemente eines Arrays zu verfolgen -- sind diese
z.B. Konstanten können die Werte an einer Konstantenfaltung teilnehmen. Solche Möglichkeiten der Optimierungen
bleiben bestehen: sind Größe und Elementwerte eines Arrays bekannt, kann ein Optimierer diese wie individuelle
Register durch die Arrayoperationen hindurch verfolgen, oder sogar ein Array auf individuelle Register "`aufteilen"'.

\subsection{Sequenz-Operationen}

Dieser Abschnitt zählt alle möglichen Operationen in einer Sequenz auf. Eine Operation greift für die Eingabe auf kein, ein oder mehrere
\emph{Quellregister} zu. Hat die Operation ein Ergebnis, wird dieses in ein \emph{Zielregister} geschrieben. 

%Unter vielen Operationen ist das Verhalten in Pseudo-Code angegeben. Dabei steht $d$ für das Zielregister einer Operation.
%Die Quellregister werden durch $s$, $t$, \dots bezeichnet. 

\subsubsection{Einfache Operationen}

\paragraph{Zuweisungsoperation:} Kopiert Inhalt eines Registers in ein anderes.
%\\\hspace*{1cm}$d \gets s$

\paragraph{Konstantenoperation:} Diese weist dem Zielregister eine Bool'sche, Integer- (vorzeichenlos oder vorzeichenbehaftet) oder
Fließkommakonstante zu.
%\\\hspace*{1cm}$d \gets \mathrm{Konstante}$

\paragraph{Typumwandlungsoperation:} Liest das Eingaberegister, wandelt dessen Wert in den Ziel-Typ und schreibt den umgewandelten Wert in das Zielregister.
Kann zwischen Integer- (vorzeichenlos oder vorzeichenbehaftet) und Fließkommawerten umwandeln.
%\\\hspace*{1cm}$d \gets s\ \mathrm{als}\ \mathrm{"`Ziel-Typ``}$

% Eventuell Tabelle (Operation|Verknüpfung|Eing-Typ|Ausg-Typ) statt Prosa?
\paragraph{Arithmetische Operation:} Die Inhalte zweier Eingaberegister 
werden durch eine arithmetische Operation verknüpft und das Ergebnis in das Zielregister geschrieben.
Die Eingaberegister und das Zielregister müssen vom gleichen Typ sein -- Integer- (vorzeichenlos oder vorzeichenbehaftet) und Fließkommawerte.
%\\\hspace*{1cm}$d \gets s + t$
%\\\hspace*{1cm}$d \gets s - t$
%\\\hspace*{1cm}$d \gets s * t$
%\\\hspace*{1cm}$d \gets s / t$

\paragraph{Vergleichsoperation:} Die Inhalte zweier Eingaberegister 
werden miteinander verglichen (gleich, ungleich, größer, größer gleich, kleiner oder kleiner gleich) und das Ergebnis in das Zielregister geschrieben.
Die Eingaberegister müssen vom gleichen Typ sein -- Integer- (vorzeichenlos oder vorzeichenbehaftet) und Fließkommawerte.
Das Zielregister muss vom Typ Boolean sein.
%\\\hspace*{1cm}$d \gets s = t$
%\\\hspace*{1cm}$d \gets s < t$
%\\\hspace*{1cm}$\phantom{d \gets}\vdots$

\paragraph{Logische Operation:} Die Inhalte zweier Eingaberegister werden durch logisch UND oder logisch ODER verknüpft und das Ergebnis in das Zielregister geschrieben.
Die Eingaberegister und das Zielregister müssen vom Typ Boolean sein.
%\\\hspace*{1cm}$d \gets s \land t$
%\\\hspace*{1cm}$d \gets s \lor t$

\paragraph{Unäre Operation:} Unäre Operationen sind Negation, Logisches NICHT und bitweise Invertierung.
Negation negiert den Wert des Eingaberegisters und schreibt das Ergebnis in das Zielregister.
Die Eingabe- und das Zielregister müssen vom gleichen Typ sein -- Integer- (vorzeichenlos oder vorzeichenbehaftet) und Fließkommawerte.\\
Logisches NICHT invertiert den Wert des Eingaberegisters und schreibt das Ergebnis in das Zielregister.
Die Eingabe- und das Zielregister müssen vom gleichen Typ Boolean sein.\\
Bitweise Invertiertung wird auf das Eingaberegister angewendet und schreibt das Ergebnis in das Zielregister.
Die Eingabe- und das Zielregister müssen von einem Integer-Typ (vorzeichenlos oder vorzeichenbehaftet) sein.
%\\\hspace*{1cm}$d \gets \neg s$
%\\\hspace*{1cm}$d \gets -s$
%\\\hspace*{1cm}$\phantom{d \gets}\vdots$

\subsubsection{Vektor- und Matrix-Operationen}

\paragraph{Vektor-Erstellung:} Nimmt als Eingabe ein bis vier Register, je nach der Komponentenanzahl des Zielregisters. Die Eingaberegister müssen alle
den Basistyp des Zielregisters besitzen. Sie werden der Reihe nach den Vektorkomponenten im Zielregister zugeordnet.
%\\\hspace*{1cm}$d \gets (s)$
%\\\hspace*{1cm}$d \gets (s, t)$
%\\\hspace*{1cm}$\phantom{d \gets}\vdots$

\paragraph{Extraktion einer Vektorkomponente:} Nimmt neben einem Eingaberegister auch eine Integer-Konstante $N$ im Bereich $0 \dots 3$ entgegen.
Das Eingaberegister muss von einem Vektortyp sein. Das Zielregister muss vom Basistyp des Vektors sein.
Aus dem Eingabevektor wird die Komponente Nummer $N$ extrahiert und in das Zielregister geschrieben.
%\\\hspace*{1cm}$d \gets s_N$

\paragraph{Matrix-Erstellung:} Nimmt als Eingabe ein bis sechzehn Register, je nach den Dimensionen des Zielregisters. Die Eingaberegister müssen alle
den Basistyp des Zielregisters besitzen. Sie werden der Reihe nach den Elementen im Zielregister zugeordnet: zuerst das Element der ersten Spalte in der ersten Zeile,
als nächstes das Element der zweiten Spalte in der ersten Zeile, usw.
%\\\hspace*{1cm}$d \gets \left(s\right)$
%\\\hspace*{1cm}$d \gets \left(\begin{array}{cc}s&t\\u&v\end{array}\right)$
%\\\hspace*{1cm}$\phantom{d \gets}\vdots$

\subsubsection{Array-Operationen}

\paragraph{Array-Erstellung:} Nimmt als Eingabe eine Variable Anzahl von Registern, die Anzahl der Eingaberegister bestimmt die Länge des Arrays.
Die Eingaberegister müssen alle den Basistyp des Zielregisters besitzen. Sie werden der Reihe nach den Array-Elementen im Zielregister zugeordnet.
%\\\hspace*{1cm}$d \gets (s, t, \dots)$

\paragraph{Extraktion eines Arrayelements:} Verwendet zwei Eingaberegister: ein Arrayregister sowie als Index ein Register mit einem vorzeichenlosen Integer.
Aus dem Array wird das Element mit dem gegebenen Index extrahiert und in das Zielregister geschrieben.
Das Zielregister muss den Basistyp des Array-Registers besitzen.
%\\\hspace*{1cm}$d \gets s[t]$

\paragraph{Änderung eines Arrayelements:} Verwendet drei Eingaberegister: neben einem Arrayregister und dem Indexregister (vorzeichenloser Integer)
weiterhin ein Register mit vom Basistyps des Arrays (der "`neue Wert"').
Aus dem Eingabearray werden alle Elemente \emph{außer} das Element des gegebenen Indexes in das Zielarray kopiert;
dort wird stattdessen der "`neue Wert"' abgelegt. Das Zielregister muss den Typ des Arrayregisters besitzen.
%\\\hspace*{1cm}$d \gets (x | x = s[i]\ \mathrm{f"ur\ alle}\ i \neq t, u\ \mathrm{sonst})$

In Pseudocode ausgedrückt:
\begin{lstlisting}
// Eingaben: Array, Index, NeuerWert
// Ausgabe: Zielarray
for element = 0 to Array.length-1
{
  if (element == Index)
    ZielArray[element] = NeuerWert;
  else
    ZielArray[element] = Array[element];
}
\end{lstlisting}

\paragraph{Arraylänge:} Nimmt im Eingaberegister ein Array entgegen. Schreibt in das Zielregister, welches vom Typ "`vorzeichenloser Integer"' sein muss,
die Anzahl der Elemente des Arrays.
%\\\hspace*{1cm}$d \gets |s|$

\subsubsection{Komplexe Operationen}

\paragraph{Sequenzschachtelung:} Eine Operation, die auf eine weitere, eingeschachtelte Sequenz verweist, welche beim Ausführen der Operation abgearbeitet wird.
Neben dem Verweis auf eine Sequenz werden auch Listen von "`importierten"' und "`exportierten"' Namen zu der Operation gespeichert.
Jedem Namen ist weiterhin ein Register in der eingeschachtelten Sequenz zugeordnet.

Für den Zugriff auf Register der "`umgebenden"' Sequenz wird von dieser 
beim Einfügen der Operation eine Zuordnung von "`importierten"' und "`exportierten"' Namen der
eingeschachtelten Sequenz zu Registern der umgebenden Sequenz vorgenommen. 
%Diese Zuordnung wird benutzt, um vor der Abarbeitung der eingeschachtelten Sequenz Registerwerte von der umgebenden in die eingeschachtelte Sequenz zu kopieren.
%Nach der Abarbeitung erfolgt ein Kopieren in die umgekehrte Richtung.

Eine Sequenzschachtelung gilt als \emph{eine} Operation in der umgebenden Sequenz. Solange die Zuordnung von "`exportierten"' Namen der
eingeschaltelten Sequenz zu Registern der umgebenden Sequenz korrekt ist (es wird kein Register verwendet, das bereits beschrieben wurde), bleibt die Register-Zuweisungs-Bedingung erfüllt.

\paragraph{Verzweigung:} Eine auf der Sequenzschachtelung basierende Operation. Eingaben sind zwei Sequenzen (eine ``if''- und eine ``else''-Sequenz) sowie ein Register vom
Typ Boolean mit dem Wert der Bedingung. Ist dieser "`wahr"', wird die ``if''-Sequenz ausgeführt, sonst die ``else''-Sequenzen. Es müssen immer beide Sequenzen
gegeben werden, Sequenzen können aber leer sein.
%Soll ein Register in einer Verzweigung beschrieben werden, so muss dies immer in \emph{beiden} Blöcken geschehen, da ansonsten je nach Ausführungspfad ein
%Register undefinierte Wert

%Ein Register kann in beiden Blöcken beschrieben werden (z.B. wenn im Quellcode eine Variable von einer Bedingung abhängig unterschiedliche Werte zugewiesen wurden).
%Eine Verzweigung gilt als \emph{eine} Operation in der umgebenden Sequenz. D.h. auch wenn ein Register in beiden Blöcken beschrieben wird, wird es,
%von der umgebenden Sequenz aus gesehen, bloß von einer Operation beschrieben (eben der Verzweigung). Damit bleibt die Register-Zuweisungs-Bedingung erfüllt.
Ein beschriebenes "`exportiertes"' Register muss in beiden Untersequenzen beschrieben werden. (Problematisch ist der Fall, wenn in einer Verzweigung
in nur einer Sequenz ein Register beschrieben wird. Bei Ausführung des "`anderen"' Pfades entweder zur Laufzeit das Register einen undefinierten Wert besitzen, oder
es müsste anderweitig überschrieben werden, was die Register-Zuweisungs-Bedingung verletzt. In der "`anderen"' Sequenz muss eine Zuweisung vom alten
Wert vorgenommen werden.)

Da eine Verzweigung als \emph{eine} Operation in der umgebenden Sequenz gilt, wird ein Register, auch wenn es in beiden Blöcken beschrieben wird, 
von der umgebenden Sequenz aus gesehen bloß von einer Operation beschrieben (eben der Verzweigung). Damit bleibt die Register-Zuweisungs-Bedingung erfüllt.

%\\\hspace*{1cm}$\mathrm{if}\ s\ \mathrm{then}\ \mathit{Block}\ \mathrm{else}\ \mathit{Block}$

%Um die SSA-Bedingungen zu erfüllen, aber

Abbildung~\ref{fig:ir_seq_branch} zeigt Schematisch eine Verzweigungsoperation in einer Sequenz.
Zuerst wird der Bedingungswert \texttt{Z} berechnet. Die Verzweigungsoperation selbst enthält dazu noch
Verweise auf die ``if''- und ``else''-Sequenzen, zu denen es jeweils Zuordnungen von "`importierten"' und "`exportierten"' 
Namen der umgebenden Sequenz zu Registern der verwiesenen Sequenz gibt.

\begin{figure}[h]
   \centering
  \includegraphics{ir_seq_branch}
  \caption{Schema einer Verzweigungsoperation.}
  \small\includegraphics[height=10pt]{ir_seq_torquoise_arrow} symbolisiert die Registerzuordnungen aus Abb.~\ref{fig:ir_seq_block_nest}.
  \label{fig:ir_seq_branch}
\end{figure}

\paragraph{While-Schleife:} Eine auf der Sequenzschachtelung basierende Operation. Eingaben sind eine Sequenz sowie zwei Register vom
Typ Boolean, jeweils mit einem Wert der Bedingung: das erste Register enthält die Bedingung \emph{vor} der ersten Ausführung der Sequenz,
das zweite Register die Bedingung \emph{nach} einer Ausführung der Sequenz.

Werte, die sich von Schleifendurchlauf zu Schleifendurchlauf ändern, werden ähnlich behandelt: es muss jedem solchen Wert ein lokales
Register im Schleifenkörper zugeordnet werden. Die Schleifenoperation selber erhält eine Abbildung von einem Paar "`externer"' Register
(Wert vor der ersten Ausführung sowie Wert nach einer Ausführung) zu den lokalen Registern als weitere Eingabe.
Durch diese Verwendung von Paaren von Eingaben ist es möglich, Werte in einem Schleifendurchlauf zu beschreiben
und im nächsten Durchlauf wieder als Eingabe für eine Operation zu verwenden. (Angenommen sei ein Quellcode wie 
\texttt{int i = 0; while (...) \{ i = i + 1; \}}. Ohne Registerpaare müsste bei \texttt{i = i + 1} entweder Eingabe-\texttt{i}
wie auch Ergebnis-\texttt{i} auf das gleiche Register umgesetzt werden, welches entsprend mehrfach zugewiesen wird, oder aber verschiedene Register, wobei
Eingabe-\texttt{i} immer den anfänglichen Wert \texttt{0} besitzen würde. Registerpaare erlauben es, das im ersten Durchlauf
der anfängliche Wert \texttt{0} für Eingabe-\texttt{i} verwendet wird, in anschliessenden Durchläufen aber der Wert des Ergebnis-\texttt{i}
des letzten Durchlaufs.)

%Durch die Verwendung eines
%Paares von Eingaben wird die Verwendung der $\phi$-Funktion vermieden.

Ein Register kann also in mehreren Schleifendurchläufen beschrieben werden.
Da aber rine Schleife gilt als \emph{eine} Operation in der umgebenden Sequenz gilt, wird auch ein mehrmals beschriebenes Register,
von der umgebenden Sequenz aus gesehen, bloß von einer Operation beschrieben (eben der Schleife).
Damit bleibt die Register-Zuweisungs-Bedingung erfüllt.

Es gibt keine spezielle Operation für \texttt{for}-Schleifen, diese werden auf \texttt{while}-Schleifen abgebildet.
%\\\hspace*{1cm}$\mathrm{while}\ s\ \mathrm{do}\ \mathit{Block}$

\subsubsection{Funktions-Operationen}

\paragraph{Funktionsaufruf:} Diese Operation nimmt einen Funktionsbezeichner, eine Liste Eingabe-Register, eine Liste Ausgabe-Register
und eventuell ein Zielregister für den Rückgabewert entgegen. Die Eingaberegister werden der Position nach auf die Funktionsparameter abgebildet.

Der "`Bezeichner"' ist eine prinzipiell beliebig wählbare Zeichenkette, die die Funktion bezeichnet. Dem Code-Generator muss
vorher eine Funktionsbeschreibung übergeben worden sein, die durch den Bezeichner identifiziert werden kann.
%\\\hspace*{1cm}$d \gets \mathrm{Funktion}\ (s, \dots)$
%\\\hspace*{1cm}$\mathrm{Funktion}\ (s, \dots)$

\paragraph{Funktionsrücksprung:} Damit wird die Funktion verlassen. Hat die Funktion einen Rückgabewert, so wird als Parameter ein Register
erwartet, welches den Rückgabewert der Funktion enthält.
%\\\hspace*{1cm}$\mathrm{return}\ s$
%\\\hspace*{1cm}$\mathrm{return}$

\paragraph{Vordefinierte Funktion:} Diese Operation sammelt den Zugriff auf vordefinierte Funktionen (siehe~\ref{builtins})
und arbeitet analog zu Funktionsaufrufen. Es wird eine Konstante, welche die Funktion identifiziert, eine Liste Eingabe-Register 
und ein Zielregister für den Rückgabewert entgegengenommen. Die Eingaberegister werden wieder der Position nach auf die Funktionsparameter abgebildet.
%\\\hspace*{1cm}$d \gets \mathrm{pow}(s, t)$
%\\\hspace*{1cm}$d \gets s \cdot t$
%\\\hspace*{1cm}$\phantom{d \gets}\vdots$

%$\phi$-Funktion: diese konkrete Zwischencoderepräsentation eines compilierten Programmes enthält nicht die bei SSAs wesentliche $\phi$-Funktion.

\subsection{Textdarstellung}

Die folgende Tabelle listet auf, wie die verschiedenen Sequenzoperationen in den Beispielen als Text dargestellt werden.
Bei den Parametern steht $d$ für das Zielregister einer Operation, $s$, $t$ bezeichnen die Quellregister.

\begin{longtable}{ l l p{4cm} }
Zuweisung & \begin{array}[t]{ll}\sOassign{d}{s}\\\sOassign{d}{\mathrm{Konstante}}\end{array}\\
\hline
Typumwandlung & \begin{array}[t]{ll}\sOcast{float}{d}{s}\\\sOcast{int}{d}{s}\\\sOcast{uint}{d}{s}\end{array}\\
\hline
Arithmetische Operationen & \begin{array}[t]{ll}\sOadd{d}{s}{t}\\\sOsub{d}{s}{t}\\\sOmul{d}{s}{t}\\\sOdiv{d}{s}{t}\\\sOmod{d}{s}{t}\end{array}\\
\hline
Vergleichsoperation & \begin{array}[t]{ll}\sOcmpeq{d}{s}{t}\\\sOcmpne{d}{s}{t}\\\sOcmplt{d}{s}{t}\\\sOcmple{d}{s}{t}\\\sOcmpgt{d}{s}{t}\\\sOcmpge{d}{s}{t}\end{array}\\
\hline
Logische Operation & \begin{array}[t]{ll}\sOand{d}{s}{t}\\\sOor{d}{s}{t}\end{array}\\
\hline
Unäre Operation & \begin{array}[t]{ll}\sOinv{d}{s}\\\sOneg{d}{s}\\\sOnot{d}{s}\end{array}\\
\hline
Vektor-Erstellung & \begin{array}[t]{ll}\sOmakevec{d}{\dots}\end{array} & Zahl der Quellregister variiert\\
Extraktion einer Vektorkomponente & \begin{array}[t]{ll}\sOvecextract{d}{s}{\mathrm{n}}\end{array} & $n$ ist konstante Komponentennummer\\
\hline
Matrix-Erstellung & \begin{array}[t]{ll}\sOmakematrix{d}{\dots}\end{array} & Zahl der Quellregister variiert\\
\hline
Array-Erstellung & \begin{array}[t]{ll}\sOmakearray{d}{\dots}\end{array} & Zahl der Quellregister variiert\\
Extraktion eines Arrayelements & \begin{array}[t]{ll}\sOgetelem{d}{s}{i}\end{array} & $i$: zu extrahierender Index\\
Änderung eines Arrayelements & \begin{array}[t]{ll}\sOsetelem{d}{s}{i}{t}\end{array} & $t$: neuer Elementwert\\
Arraylänge & \begin{array}[t]{ll}\sOarraylen{d}{s}\end{array}\\
\hline
Sequenzschachtelung & \begin{array}[t]{ll}\sOnestseq{Sequenz}\end{array}\\
\hline
Verzweigung & \begin{array}[t]{ll}\sObranch{c}{if-Sequenz}{else-Sequenz}\end{array} & $c$: Bedingungsregister\\
\hline
While-Schleife & \begin{array}[t]{ll}\sOwhile{c_0}{c_n}{Sequenz}\end{array} & $c_0, c_n$: Bedingungsregister erster Durchlauf/weitere Durchläufe\\
\hline
Funktionsaufruf & \begin{array}[t]{ll}\sOcall{\mathrm{Funktion}}{\dots}\\\sOcallret{d}{\mathrm{Funktion}}{\dots}\end{array} & Zahl der Quell- und Zielregister variiert\\
\hline
Funktionsrücksprung & \begin{array}[t]{ll}\sOreturnvoid\\\sOreturn{s}\end{array}\\
\hline
%Vordefinierte Funktion
Skalarprodukt & \begin{array}[t]{ll}\sObuiltindot{d}{s}{t}\end{array}\\
Vektorprodukt & \begin{array}[t]{ll}\sObuiltincross{d}{s}{t}\end{array}\\
Matrixmultiplikation & \begin{array}[t]{ll}\sObuiltinmul{d}{s}{t}\end{array}\\
Normalisierung & \begin{array}[t]{ll}\sObuiltinnormalize{d}{s}\end{array}\\
Euklidische Länge & \begin{array}[t]{ll}\sObuiltinlength{d}{s}\end{array}\\
Minimum & \begin{array}[t]{ll}\sObuiltinmin{d}{s}{t}\end{array}\\
Maximum & \begin{array}[t]{ll}\sObuiltinmax{d}{s}{t}\end{array}\\
Potenz & \begin{array}[t]{ll}\sObuiltinpow{d}{s}{t}\end{array}\\
Textur auslesen & \begin{array}[t]{ll}\sObuiltintexOneD{d}{s}{t}\\\sObuiltintexTwoD{d}{s}{t}\\\sObuiltintexThreeD{d}{s}{t}\\\sObuiltintexCUBE{d}{s}{t}\\\end{array}\\
\end{longtable}

\subsection{Beispiel}

Abbildung~\ref{fig:ir_sample_src} zeigt ein einfaches Programm in der Sprache, Abbildung~\ref{fig:ir_sample_gen} die generierte Zwischencoderepräsentation.

\begin{figure}[h]
   \centering
  \lstinputlisting{s1source/sample_minimal.s1}
  \caption{Quelltext eines Programms.}
  \label{fig:ir_sample_src}
\end{figure}
\begin{figure}[h]
   \centering
  \input{s1latex/sample_minimal.tex}
  \caption{Zu~\ref{fig:ir_sample_src} generierte Zwischencoderepräsentation.}
  \label{fig:ir_sample_gen}
\end{figure}

\section{Auftrennung}
\label{Auftrennung}

% High-Level Arbeitsweise
Der "`\emph{Splitter}"' trennt ein als Zwischencoderepräsentation vorliegendes Programm in ein \emph{Vertex-} und \emph{Fragmentprogramm} auf.
Die Entscheidung wird für individuelle Sequenzoperationen getroffen. Jeder Operation lässt sich eine \emph{Berechnungsfrequenz}
\footnote{Siehe Abschnitte \ref{berechnungsfrequenz_locker} und \ref{Berechnungsfrequenz}},
in der diese Operation ausgeführt wird, zugeordnet werden: mit \emph{Vertexfrequenz}, oder per Vertex, berechnete Operationen werden dem Vertexprogramm zugeordnet.
Analog werden mit \emph{Fragmentfrequenz}, oder per Fragment, berechnete Operationen dem Fragmentprogramm. Die Bestimmung der Berechnungsfrequenz hängt von der Operation selbst
und von den Frequenzen, mit denen die Operanden berechnet wurden, ab. 

\paragraph{Operanden:} Eine Operation muss mindestens in derjenigen Frequenz ausgeführt werden, welche die höchste ist, in der einer der Operatoren
vorliegt. So muss z.B. eine Verknüpfung von zwei Werten per Fragment ausgeführt werden, wenn einer der Operatoren per Fragment berechnet wurde.
% DIes ist darin begründet, dass Werte nur vom Vertex- zum Fragmentprogramm, aber nicht zurück, übertragen werden können. ... \ref{}

\paragraph{Operation:} Eine Berechnung kann per Vertex ausgeführt werden, wenn beide Eingaben per Vertex vorliegen, und
sofern die Operation das Kriterium der \emph{Interpolierbarkeit} (Abschnitt~\ref{Interpolierbarkeit}) erfüllt.

\subsection{Berechnungsfrequenzen}
\label{splitter_Berechnungsfrequenzen}
% Welche Frequenzen?

Für die Aufspaltung relevante Frequenzen sind die Mesh-, % TODO Vergl. Nomenklatur mit Erklärung Freq.; "Freq." besser nicht überladen mit "Verarbeitungsschritt"
% "Uniform" blöd
Vertex- und Fragmentfrequenz.

Per-Mesh-Eingaben sind Eingaben, die sich nicht während aufeinanderfolgenden Ausführungen eines Programmes
ändern, und können daher als \emph{konstant} angesehen werden. Deren Werte stammen aus der umgebenden Anwendung.

Per-Vertex-Eingaben sind den verschiedenen Vertices zugeordnete Eingaben . % TODO Verw. auf Vertexdaten
Auch diese sind Anwendungsdaten.

Per-Fragment-Eingaben sind die interpolierten Ausgaben des Vertexprogramms (siehe Abschnitt~\ref{schnittstelle} unten). 
Insbesondere besitzt Graphikhardware keinen Mechanismus, der der Anwendung erlauben würden, direkt per-Fragment-Eingaben
vorzugeben.

"`Echte"' Konstanten werden vom Splitter auch als "`per Mesh"' betrachtet.

Für jedes Register wird verfolgt, für welche Frequenzen es vorliegt, im Wesentlichen also in welchem Teilprogramm es berechnet wird.
Dabei kann ein Register in mehreren Frequenzen verfügbar sein, wenn es im Vertex-Programm berechnet wurde, aber später als
an das Fragmentprogramm zu Übertragen markiert wird (Abschnitt~\ref{schnittstelle}).

Der Splitter kategorisiert auch Operationen und Werte als "`per Mesh"', generiert jedoch \emph{kein} separates Programm.
Stattdessen werden per-Mesh-Operationen sowohl vom Vertex- als auch vom Fragmentprogramm ausgeführt. Zwei Annahmen
liegen diesem Zugrunde: zuerst, dass nur relativ einfache Operationen mit uniformen Werten allein vorgenommen werden, es also kein
Nachteil durch eine mehrfache Ausführung in Vertex- und Fragmentprogramm entsteht. Darüber hinaus können auch durch, so die zweite Annahme,
weitere Optimierungsschritte wie Dead Code Elimination einige Operationen auf uniformen Werten entfernt werden.

% Eingaben: Uniform oder per Vertex; Fragmentfreq. nur Eingaben von VP

\subsection{Schnittstelle Vertex-/Fragmentprogramm}
\label{schnittstelle}

Da ein Teil der Operationen des ursprünglichen Programms dem Vertexprogramm zugeordnet wird, ein anderer Teil aber dem
Fragmentprogramm, müssen Ergebnisse des einen Programms zum anderen übertragen werden.
Dabei ist zu beachten, dass nur Werte vom Vertex- zum Fragmentprogramm übertragen werden können; % @@@ Eher nicht hier
eine Übertragung in die andere Richtung ist nicht möglich.

Stellt der Splitter die Notwendigkeit des Übertragens für einen Wert fest, wird das Register, welches den Wert enthält, aufgezeichnet.
Diese Liste der zu übertragenden Werte ("`Schnittstelle"' in Abbildung~\ref{fig:structure}) wird später dem Codegenerator übergeben.
Dieser kümmert sich um die "`technischen"' Details wie die Zuordnung von für die Übertragung notwendigen Ressourcen und % @@@ Ress. -> Interpolatoren. Verw
entsprechende Abbildung in der Zieldarstellung.

\subsection{Interpolierbarkeit}
\label{Interpolierbarkeit}
% Kriterium: Interpolation

Programme der Shadingsprache sind grundsätzlich so formuliert, als würden Operationen per Fragment ausgeführt (siehe Abschnitt~\ref{formulierte_frequenz}).
Die vom Splitter zu lösende Problem ist die Bestimmung von Operationen, die per Vertex ausgeführt werden können.
Das Hauptkriterium diese Entscheidung ist die \emph{Interpolierbarkeit} einer Operation.

\newcommand\lerp{\mathrm{lerp}}
Vom Vertexprogramm ausgegebene Werte werden, bevor sie wieder dem Fragmentprogramm als Eingabe dienen, \emph{linear interpoliert}: % TODO: Verw. auf Erklärung/Interpolatoren
Eine lineare Interpolation -- "`$\lerp$"' -- zwischen zwei Werten $a$ und $b$ mit Faktor $f$ ($0 \le f \le 1$) wird durch $\lerp(a, b, f) = a \cdot (1-f) + b \cdot f$ berechnet.
Soll ein Wert $x$ vom Vertex- and das Fragmentprogramm übergeben werden, so gibt das Vertexprogramm per Vertex verschiedene Werte aus - $x_1, x_2$ usw.
Das Fragmentprogramm erhält als Eingabe das Ergebnis einer implizierten, bei der Rasterung berechneten Interpolation $\lerp(x_1, x_2, f)$ (wobei $f$ von der Graphikhardware berechnet wird
und per Fragment variiert)\footnote{Tatsächlich muss bei der Rasterung von Dreiecken zwischen drei Werten interpoliert werden. Dieser Abschnitt betrachtet konkret
bloss Interpolation zwischen zwei Werten, die Ergebnisse gelten aber auch bei Interpolation zwischen drei Werten.}.

Eine per Fragment ausgeführte Rechenoperation $g(x)$, mit einem aus Ausgaben des Vertexprogramms interpoliertem $x$ -- also $x = \lerp(x_1, x_2, f)$ --
kann auch per Fragment ausgeführt werden, wenn eine Interpolation des Ergebnisses der per Vertex berechneten Rechenoperation zum gleichen Endergebnis führt:
es muss $g(\lerp(x_1, x_2, f)) = \lerp (g(x_1), g(x_2), f)$ gelten. Augenscheinlich muss $g$ eine lineare Funktion sein.

Für binäre Rechenoperationen lautet die Bedingung $\lerp (g (x_1, y_1), g (x_2, y_2), f) = g (\lerp (x_1, x_2, f), \lerp (y_1, y_2, f))$.
Rechenoperationen mit mehr Operanden müssen nicht betrachtet werden, da die Shadingsprache höchstens
binäre Rechenoperationen vorsieht bzw. "`komplexere"' Rechenoperationen auf binäre Operationen heruntergebrochen werden
können (siehe auch~\ref{split_builtins}). % Zweistelliges Äquivalent für "lineare Funktion"?

Da Rechenoperationen auf Vektoren komponentweise ausgeführt werden,  ist die "`Interpolierbarkeit"' ohne weiteres auch auf Vektoroperationen anwendbar.

Die geforderte Linearität von $g(x)$ führt dazu, dass bloss Operationen auf \texttt{float}-Werten problemlos interpolierbar sind:
bei der Interpolation von Integer-Werten können nicht-Integer-Werte als Zwischenergebnisse entstehen,
die (zwangsweise) gerundet\footnote{Oder Nachkommastelle abgeschnitten usw.} werden müssen. Diese Rundung
ist aber keine stetige Funktion und deshalb nicht interpolierbar.

Zu Beachten ist, dass Interpolierbarkeit nur Relevanz hat, wenn entschieden wird, ob eine Operation, bei der mindestens ein Operand
nur per Vertex (oder höher) vorliegt, auch per Vertex ausgeführt werden kann.
Operationen allein auf Konstanten oder (praktisch konstanten) per-Mesh-Eingaben sind immer auch per Vertex ausführbar - das Ergebnis
einer solchen Operation kann nicht zwischen den Berechnungen für verschieden Vertices variieren. Insbesondere können damit
auch Operation auf Integer-Werten, oder Operationen, die nachfolgend als "`nicht interpolierbar"' klassifiziert werden,
per Vertex ausgeführt werden.

% Konkreter: Ausgabe VP: x_1, x_2, ...
% Eingabe FP: lerp (x_1, x_2, f) - implizit

%Allerdings kann eine Operation auf Vertex-Frequenz "`abgesenkt"' werden, wenn eine lineare Interpolation
%des Ergebnisses der Operation äquivalent zu der Operation mit linear interpoliertem Operanden ist
%($\lerp (g (x_1, y_1), g (x_2, y_2), f) = g (\lerp (x_1, x_2, f), \lerp (y_1, y_2, f))$).
% Andere Operandenzahlen betrachten
% Beispiel?

% Stichwort: Linearkombination?

\paragraph{Arithmetische Operationen:} Die Summe oder Differenz von zwei linearen Funktionen
ist wieder eine lineare Funktion, Addition und Subtraktion sind also uneingeschränkt interpolierbar.
% @@@ Beweisen? Zumindest erläutern.

Multiplikation und Division sind interpolierbar, wenn mindestens ein Operand höchstens per Mesh gegeben ist.
Sind beide Operanden per Vertex gegeben, so ist eine Multiplikation oder Division keine lineare,
sondern eine \emph{quadratische} Funktion. Da per Mesh gegebene Operanden sind praktisch als
konstant betrachtet werden können ist die Multiplikation oder Division mit einem per Mesh gegebenen
Operanden eine lineare Funktion und interpolierbar.

Modulo ist nicht interpolierbar da es keine stetige Funktion ist.

\paragraph{Logische Ausdrücke, Vergleichsoperationen:} Diese sind nicht interpolierbar da keine stetigen Funktionen.

\paragraph{Unäre Ausdrücke:} Negation ist offentsichtlich interpolierbar.

Logisches NICHT ist, wie die anderen logischen Ausdrücke, nicht interpolierbar.

Bitweises invertieren ist nur für Integer-Werte sinnvoll und damit nicht interpolierbar.

\paragraph{Eingebaute Funktionen:} \label{split_builtins}
Skalarprodukt, Vektorprodukt und Matrixmultiplikation lassen sich alle mit arithmetischen Basisoperationen darstellen;
vor allem eine Multiplikation ist in allen drei "`enthalten"'. Damit ergeben sich die gleichen Beschränkungen:
diese Operationen sind nur interpolierbar, wenn mindesten ein Operand per Mesh gegeben ist.

Potenzierung ist im Allgemeinen keine stetige Funktion und damit nicht interpolierbar.

Die Berechnung von "`Normalisierung"' und "`Euklidische Länge"' erfordert das Ziehen einer Wurzel bzw. Potenzieren mit $\frac{1}{2}$.
Damit sind diese Funktionen auch nicht interpolierbar.

Minimum und Maximum sind im Allgemeinen keine stetigen Funktion und damit nicht interpolierbar.

Die Texturfunktionen sind prinzipbedingt nicht interpolierbar.

\paragraph{Sequenzschachtelung:} Eine Sequenzschachtelungsoperation wird prinzipiell zu allen generierten Teilprogrammen hinzugefügt,
allerdings mit unterschiedlichen Sequenzen. Diese sind selbst das Ergebnis einer Aufspaltung der ursprünglichen Sequenz.

\paragraph{Verzweigung:} Eine Verzweigung besteht konzeptionell aus zwei eingeschalten Sequenzen (für die jeweiligen Verzweigungsblöcke)
und ein bool'scher Bedingungswert, nach dem verzweigt wird.

Die beiden eingeschachtelten Verzweigungssequenzen werden selbst aufgespalten.

Der bool'scher Bedingungswert kann entweder per Mesh oder per Fragment vorliegen: per Mesh, wenn er eine per-Mesh-Eingabe ist bzw. allein aus
per-Mesh-Eingaben berechnet wurde. Per Fragment, wenn er aus Werten anderer Frequenzen berechnet wurde. Per Vertex ist nicht
möglich da auf Grund der Nicht-Interpolierbarkeit von Vergleichs- und Logikoperationen diese immer per Fragment berechnet werden.

Selbst wenn der Bedingungswert nur per Fragment vorliegt, kann die Verzweigungsoperation nicht allein per Fragment ausgeführt werden:
die Aufspaltung der Verzweigungsblöcke kann auch in per Vertex auszuführende Sequenzen resultieren. Diese müssen als "`normale"'
eingeschachtelte Sequenzen, d.h. keine Verzweigung, zum Vertexprogramm hinzugefügt werden. Im Vertexprogramm werden also immer
die Vertexteile beider Verzweigungsblöcke ausgeführt. Zwischenergebnisse müssen an das Fragmentprogramm übertragen und dort ausgewählt werden.

Von den Verzweigungsblöcken beschriebene Register sind immer nur in der selben Frequenz wie der Bedingungswert verfügbar:
Selbst wenn beide Verzweigungen bloss per-Vertex-Operationen ausführen, sind durch die Auswahl nach einer per-Fragment-Bedingung
die berechneten Wert nur per Fragment verfügbar.

\paragraph{Schleife:} Eine Schleifenoperation besteht aus einer eingeschachtelten Sequenz (dem Schleifenrumpf) sowie
ein bool'scher Bedingungswert, der Schleifenbedingung.

Wie bei der Verzweigung kann der bool'scher Bedingungswert nur entweder per Mesh oder per Fragment vorliegen.

Ein Ausführen von Teilen des Rumpfes per Vertex wäre problematisch: es müsste bekannt sein, wieviele Werte vom Vertex-Teil
zum Fragment-Teil übertragen werden sollen. Diese Anzahl hängt von der Anzahl der Schleifendurchläufe ab -
diese kann aber Im Allgemeinen zur Kompilierzeit nicht bestimmt werden. Schleifenoperationen können also nur komplett
per Mesh oder per Fragment ausgeführt werden.

\paragraph{Funktionsaufruf:} Der Rumpf einer Funktion ist eine Sequenz, kann also prinzipiell in einen per-Vertex- und einen per-Fragment-Teil aufgespalten werden.
Das Hauptproblem besteht dabei darin, dass die Frequenzen der Funktionsparameter je nach Aufruf variieren können.

Dies wurde gelöst, in dem für eine Funktion bei der Aufspaltung mehrere Varianten generiert werden: bei einem Funktionsaufruf
wird die Funktion aufgespalten, mit den jeweiligen Verfügbarkeiten der übergebenen aktuellen Parameter. Wird die gleiche Funktion
nochmals aufgerufen, aber mit einer anderen "`Signatur"' von Verfügbarkeiten, so wird die Funktion in neue Varianten aufgespalten usw.

Die Verfügbarkeiten von Ausgabeparametern hängen von den Verfügbarkeiten der Eingabeparameter ab, können aber nach dem Aufspalten
einer Variation bestimmt werden.

Das Übertragen von Werten vom per-Vertex- zum per-Fragment-Teil einer Funktionsvariation geschieht über generierte Ausgabe- bzw.
Eingabeparameter; die eigentliche Übertragung geschieht schlussendlich in der Eintrittsfunktion.

Rekursionen müssen besonders behandelt werden: um die korrekten Verfügbarkeiten der Ausgabeparameter zu bestimmen
muss eine Funktion zunächst aufgespalten werden. Im Falle einer Rekursion wird möglicherweise aber genau die angetroffene
Variante gerade selbst aufgespalten -- die Verfügbarkeiten sind also noch nicht bekannt, der Versuch einer Aufspaltung der
angetroffenen Variante würde über kurz oder lang zum exakt selben Problem führen.

Die Auflösung ist, dass rekursive Funktionen besonders behandelt werden: im Wesentlichen wird, bei einem festgestelltem
rekursiven Aufruf, konservativ angenommen, die Ausgabeparameter sind nur per Fragment verfügbar. Damit kann der Rumpf
einer rekursiven Funktion aufgespalten werden.

% Behandlung von: arithm. Ausdr., Logik, Vergl, Unäre Ausdr., Verzweigungen, Schleifen, Funktionen

% Array-Operationen: evtl. nur per Fragment? (bei dyn. Arrays)

% 'Trivial': Zuweisung, Konstante, Typumwandlung, Vektor-Erstellung/-Extraktion, [Array-Erstellung/-Extraktion/-Änderung/-Länge,?]
% 

\paragraph{Array-Operationen:} Array-Operationen sind nur interpolierbar, wenn die Länge des Arrays \emph{statisch konstant}
(und nicht per Mesh) bekannt ist und bei der Array-Extraktion bzw. -Änderung der verwendete Index höchstens per Mesh
verfügbar ist.

\paragraph{Andere Operationen:} Zuweisungen, Konstantenoperationen, Typumwandlung, die Erstellung eines Vektors sowie
die Extraktion einer Komponente können trivialerweise mit derjenigen Frequenz berechnet werden, die der höchsten Frequenz
aller Eingaben entspricht.

% Beispiele
\begin{figure}[hp]
  \input{simple_s1}
  \caption{Ein Programm in der Shading-Sprache.}
  \centering
  \small Operationen und Werte sind von der Berechnungsfrequenz abhängig markiert (\freqPerMesh{Mesh}, \freqPerVert{Vertex}, \freqPerFrag{Fragment})
  \label{fig:simple_s1}
\end{figure}

\begin{figure}[!ht]
  \centering
  \input{simple_s1_split}
  \caption{Programm aus \ref{fig:simple_s1} nach der Aufspaltung.}
  %\small Operationen und Werte sind von der Berechnungsfrequenz abhängig markiert (\freqPerMesh{Mesh}, \freqPerVert{Vertex}, \freqPerFrag{Fragment})
  \label{fig:simple_s1_split}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=4cm]{simple_s1_mesh}\quad
  \includegraphics[width=4cm]{simple_s1_vert}\quad
  \includegraphics[width=4cm]{simple_s1_frag}
  \caption{Programm aus \ref{fig:simple_s1}}
  \small 1. nur per-Mesh-Anteil der Fragment-Farbe\\
  2. mit zusätzlich per-Vertex-Anteil\\
  3. vollständige Fragment-Farbe\\
  \label{fig:simple_s1_images}
\end{figure}

\newpage
\section{Code-Generator}

Der \emph{Code-Generator} übersetzt ein in der Zwischencoderepräsentation vorliegendes Programm in eine \emph{Zieldarstellung}.
Diese "`Darstellung"' kann wieder eine Hochsprache sein, prinzipiell kann ein Code-Generator aber auch Assembler-Quelltext oder eine
Binärcodierung ausgeben.

\subsection{Eingaben und Aufgaben}

Der \emph{Code-Generator} erhält als Eingabe eine Liste von Funktionsbeschreibungen.
Eine Funktionsbeschreibung besteht aus dem eindeutigen Bezeichner, einer Liste von Parametern (getrennt nach Ein- und Ausgabeparametern)
und einer Sequenz mit den eigentlichen Operationen. Eine Funktion aus der Liste ist als "`Eintrittsfunktion"' markiert.

\begin{figure}[h]
   \centering
  \includegraphics{ir_program}
  \caption{Zusammensetzung eines Programms in der Zwischencoderepräsentation}
  \label{fig:ir_program}
\end{figure}

Die Aufgaben des Code-Generators bestehen aus:
\begin{itemize}
\item Nötige Umformungen für die Zieldarstellung -- z.B. Schleifen ausrollen oder ``inlining'' von Funktionen.
\item Übertragung der Funktionsbeschreibungen in eine entsprechende Deklaration in der Zieldarstellung.
\item Übersetzung der Sequenzoperationen in die Zieldarstellung. 
\item Dabei Ressourcenallokation, wenn nötig (z.B. begrenzte Registerzahl in der Zieldarstellung).
\item Generierung von "`Schnittstellen-Anweisungen"' wie z.B. bei der Übergabe von Parametern an Funktionen
oder die Behandlung von Werten "`vor dem ersten Durchlauf, nach dem ersten Durchlauf"' wie sie bei Schleifen
auftreten.
\end{itemize}

\subsection{Generator für Cg}

In der vorliegenden Implementierung wurde als Zieldarstellung die Sprache Cg~(\cite{cgpaper}, \cite{cg_home}) gewählt.

Cg als Hochsprache kennt selbst Konstrukte wie Funktionen und Schleifen. Umformungen durch den Codegenerator
sind also nicht nötig.

Jede Funktion wird also direkt auf eine Cg-Funktion abgebildet.

Jedem Register der Zwischencoderepräsentation wird eine Variable zugeordnet -- eine Re\-gis\-ter\-al\-lo\-ka\-tion ist unnötig, diese wird später vom Cg-Compiler selbst vorgenommen.
"`Einfache"' Sequenzoperation (arithmetische Operationen u.ä.) lassen sich trivialerweise auf ein einzelnes Statement in Cg übertragen. 
Weiterhin werden die meisten eingebauten Funktionen und Attribute direkt von Cg unterstützt (Ausnahme ist das Matrix-Attribut \texttt{inverted}).

Kompliziertere Operationen -- Verzweigungen, Schleifen, Funktionsaufrufe -- resultieren in mehreren Statements, obwohl es sich bei dem
zusätzlichen "`Aufwand"' meist nur um Zuweisungen zwischen Variablen handelt, wie z.B. die Auswahl des Bedingungsregisters basierend zwischen
den Wert vor und nach dem ersten Schleifendurchlauf.

Die spezifizierte Sprache unterstützt Zeichenketten aus Unicode-Buchstaben und -Ziffern als Bezeichner;
Cg nur eine Untermenge von ASCII. Für die Ausgabe als Cg-Code werden Zeichen ausserhalb von ASCII in eine Darstellung in der von Cg akzeptieren
Zeichenmenge umgewandelt\footnote{Als Kodierung wurde Punycode~(\cite{rfc3492}) gewählt da dies die aus ASCII bestehenden Teile eines Bezeichners
gut lesbar lässt.}.

% Original-Schnipsel und Generator-Output

\section{Zusammenfassung}

Grundsätzlich folgt der Aufbau des Compilers der Standardarchitektur dafür; die Abweichnung ist der Verarbeitungsschritt der "`Auftrennung"' in mehrere
Programme.

Die Auftrennung nutzt dabei Eigenschaften von Graphikhardware aus, deren Aufbau auf den Ablauf des Echtzeit-3D-Renderings abgestimmt ist.
Speziell werden Operationen in der Vertex- statt Fragmentverarbeitung ausgeführt sofern das Ergebnis zur ursprünglichen Operation mathematisch äquivalent ist,
nachdem die von der Graphikhardware vorgenommen Interpolation von Ausgaben der Vertexverarbeitung angewendet wurde.

Auch hervorzuheben ist die verwendete Zwischencoderepräsentation, die als Übergabeformat zwischen allen Verarbeitungsschritten von der
semantischen Analyse bis zur Codegenerierung dient. Weiterhin ist sie darauf ausgerichtet, die Implementierung von Optimierungsschritten
möglichst zu vereinfachen.

\chapter{Ausblick}

% AST: nützlich, wenn FEs für anderen Sprachen, oder komplexer (Strukturen)
% Manuelles spezifizieren von per-Vertex Ops // keyword 'interpolate'

Die übersetzte Sprache ist eine zwar vergleichsweise einfache, aber trotzdem praktisch nutzbare
Shadingsprache, die es erlaubt, Shadingprogramme zu schreiben, ohne den Hardwareaufbau aus verschiedenen Funktionseinheiten
berücksichtigen zu müssen.

Der in Abschnitt~\ref{Auftrennung} beschriebene Auftrenner arbeitet konservativ in dem Sinne dass eine Operation nur in das Ausgabe-Vertex-Programm
"`verschoben"' wird wenn das Ergebnis mathematisch äquivalent zu einer Berechnung im Ausgabe-Fragment-Programm wäre.
Praktisch sollen aber manchmal bewusst Operationen durch eine per-Vertex-Berechnung approximiert werden (aus Geschwindigkeitsgründen
bei komplexen oder oftmals verwendeten Programmen). Die Sprache sollte deswegen noch um ein Schlüsselwort o.ä. erweitert werden
welches ein manuelles Bestimmen der Berechnungseinheit für eine Operation erlaubt.

Eine weitere Erweiterung, um das Erstellen von komplexeren Programmen zu vereinfachen, wäre das Hinzufügen von Verbundtypen zur Sprache.

Denkbar ist es auch, den Compiler so zu erweitern, dass Programme aus "`üblichen"' Shadingsprachen mit getrennten Vertex- und Fragmentprogrammen
-- wie Cg -- akzeptiert werden. Die Ausgabe des Compilers wären ein funktional äquivalente Vertex- und Fragment-Programme,
allerdings potentiell mit einer besseren Verteilung von Operationen auf Verarbeitungseinheiten.

Bei der Implementierung besteht praktisch das grösste Verbesserungspotential im Aufspalter. Die Behandlung von Funktionen ist relativ
kompliziert. Rekursiven Funktionen, aber auch Schleifen, werden nur im Fragment-Programm ausgeführt - dies stellt zwar ein korrektes
Ergebnis sicher, ist aber nicht in allen Fällen die optimale Lösung.

Der Compiler selbst nimmt in der vorliegenden Implementierung noch keine Optimierungsschritte vor. In Anbetracht der bewussten Ausrichtung
der Zwischencoderepräsentation auf möglichst einfache Optimierungen sowie die bei der Implementierung gemachten Annahmen (z.B. im Aufspalter) über das
Vorhandensein von Optimierungsschritten wäre es der nächste sinnvolle Schritte, diese Optimierungsschritte tatsächlich umzusetzen.

\cleardoublepage
\appendix
\bibliography{thesis_de}
\addcontentsline{toc}{section}{Literatur}

\end{document}
