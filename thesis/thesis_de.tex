\documentclass[twoside,a4paper,fleqn,12pt]{book}
\usepackage{fancyhdr,a4wide,graphicx}
\usepackage[paper=a4paper,left=30mm,right=20mm,top=30mm,bottom=25mm]{geometry}
\pagestyle{fancy}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
%\usepackage[]{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[usenames,dvipsnames]{color}
\usepackage{colortbl}
%\usepackage{mathptmx}
\usepackage[bitstream-charter]{mathdesign}
\usepackage{charter}
\usepackage{helvet}
\usepackage{courier}
\usepackage{verbatim}
\usepackage{sectsty}
\usepackage{listings}
\usepackage{listingsutf8}
\usepackage{scalefnt}
\usepackage{setspace}
\usepackage{ngerman}
\usepackage{subfig}
\usepackage{longtable}

% Anm.: vor hyperref um Glossar-Ref nicht "klickbar" zu machen
\usepackage[toc]{glossaries}
\renewcommand{\glossaryname}{Glossar}

\definecolor{darkred}{rgb}{.5,0,0}
\definecolor{darkblue}{rgb}{0,0,.5}
% Screen
%\usepackage[plainpages=false,pdfpagelabels,colorlinks=true,urlcolor=darkblue,pagecolor=darkred,citecolor=darkred,linkcolor=darkred]{hyperref}
% Print
\usepackage[plainpages=false,pdfpagelabels,colorlinks=true,urlcolor=black,pagecolor=black,citecolor=black,linkcolor=black]{hyperref}
%\newcommand\url[1]{\texttt{#1}}

\lstset{basicstyle=\ttfamily\small,lineskip=-0.5em,language={},tabsize=8,inputencoding=utf8/latin1,numberstyle=\tiny}

% define the title
\title{\usefont{OT1}{phv}{b}{n}\selectfont Entwicklung eines Compilers für eine auf Cg basierende Sprache zur Programmierung von Grafikkarten \normalfont}
% What a hack!
\author{{\Large \textbf{Diplomarbeit}}\\
\vspace{1em}\\
{\large \textsc{Friedrich-Schiller-Universität Jena}}\\
{\large Fakultät für Mathematik und Informatik}\\
\vspace{1em}\\
eingereicht von Frank Richter\thanks{Matrikel 68278, Kontakt: frank.richter@gmail.com}\\
Betreuer: Prof. Dr. habil. Wolfram Amme}
\date{\vspace{1em}\today}

\makeglossaries

\newtheorem{defn}{Definition}

\begin{document}

\sloppy

\newcommand\btxandlong{und}
\newcommand\btxandshort{u}
\newcommand\Btxinlong{In}
\newcommand\Btxinshort{I}
\newcommand\btxpageslong{Seiten}
\newcommand\btxetalshort{et al}
\newcommand\btxeditionlong{Auflage}
\bibliographystyle{mystyle}

% Zeilenabstand
\newcommand\defltbaselinestretch[0]{\renewcommand{\baselinestretch}{1.42}}
\defltbaselinestretch\normalsize

% Helvetica für Section-Titel
\allsectionsfont{\usefont{OT1}{phv}{b}{n}\selectfont}

% Different font in captions
\newcommand{\captionstyle}{\small\centering}

\makeatletter  % Allow the use of @ in command names
\long\def\@makecaption#1#2{%
  \vskip\abovecaptionskip
  \sbox\@tempboxa{{\captionstyle #1: #2}}%
  \ifdim \wd\@tempboxa >\hsize
    {\captionstyle #1: #2\par}
  \else
    \hbox to\hsize{\hfil\box\@tempboxa\hfil}%
  \fi
  \vskip\belowcaptionskip}
\makeatother   % Cancel the effect of \makeatletter

% Fussnoten: alle Zeilen einrücken
\makeatletter
\newlength{\myFootnoteWidth}
\newlength{\myFootnoteLabel}
\setlength{\myFootnoteLabel}{1.2em}%  <-- can be changed to any valid value
\renewcommand{\@makefntext}[1]{%
  \setlength{\myFootnoteWidth}{\columnwidth}%
  \addtolength{\myFootnoteWidth}{-\myFootnoteLabel}%
  \noindent\makebox[\myFootnoteLabel][r]{\@makefnmark\ }%
  \parbox[t]{\myFootnoteWidth}{#1}%
}
\makeatother

% ---------- normal title ---------- %
\titlepage
\maketitle
% \begin{titlepage}
% \begin{center}
% \setlength{\baselineskip}{2em}
% {\huge \usefont{OT1}{phv}{b}{n}\selectfont Entwicklung eines Compilers für eine auf Cg basierende Sprache zur Programmierung von Grafikkarten \normalfont}
% \vfill\today
% \end{center}
% \end{titlepage}

\thispagestyle{empty}
\newpage
\thispagestyle{empty}
\mbox{}

% ---------- Fancyheader ---------- %
\fancypagestyle{plain}{ %
\fancyhf{} % remove everything
\fancyhead[LE,RO]{\footnotesize \thepage{}}
\renewcommand{\headrulewidth}{0pt} % remove lines as well
\renewcommand{\footrulewidth}{0pt}}

\fancyhead[CLR]{}
\fancyhead[LE,RO]{\footnotesize \thepage{}}
\fancyhead[CE]{\footnotesize \leftmark}
\fancyhead[CO]{\footnotesize \rightmark}
\fancyfoot[C]{}
\renewcommand{\headrulewidth}{0pt}
%\setlength{\headheight}{24pt}
%\setlength{\parskip}{0pt plus 1pt}

% generates the title

\thispagestyle{empty}
\newpage
\chapter*{Zusammenfassung}

In dieser Arbeit wurde eine Sprache zur Programmierung von Grafikprozessoren sowie ein diese Sprache übersetzender
Compiler entwickelt.

Schwerpunkt ist die Besonderheit des Compiler, mehrerer Ausgabeprogramme aus einem Eingabeprogramm zu erzeugen.
Die verschiedenen Ausgabeprogramme zielen dabei auf verschiedene Funktionseinheiten
eines Grafikprozessors ab. Die Aufspaltung in die Ausgabeprogramme wird so vorgenommen, das im
Zusammenspiel der verschiedenen Programme auf den verschiedenen Funktionseinheiten die Semantik
des Eingabeprogramms umgesetzt wird. Für die Aufspaltung selbst wurden Kriterien entworfen, die
den speziellen Aufbau und Datenfluss auf Grafikprozessoren berücksichtigen und ausnutzen.

Die entwickelte Programmiersprache ist eine Hochsprache, die in wesentlichen Zügen auf der
Sprache Cg basiert, im Vergleich aber signifikant vereinfacht wurde und in der syntaktisch bewusste einige
eigene Wege eingeschlagen wurden.

\thispagestyle{empty}
\newpage
\mbox{}
\thispagestyle{empty}
\newpage
% ---------- table of contents ---------- %
\pagenumbering{roman}
%\addcontentsline{toc}{section}{Inhaltsverzeichnis}
\pdfbookmark[1]{Inhaltsverzeichnis}{myPDFtocLabel}
\tableofcontents

\cleardoublepage
\pagenumbering{arabic}
\newcommand\todo[1]{\footnote{\textcolor{red}{TODO: #1}}}
\newcommand\fcite[1]{\footnote{\cite{#1}}}
\newcommand\fciteX[2]{\footnote{\cite{#1}, #2}}

\newcommand\emphalt[1]{\textbf{#1}}

\newcommand\freqPerMesh[1]{\framebox{#1}}
\newcommand\freqPerVert[1]{\colorbox{SpringGreen}{\textcolor{Black}{#1}}}
\newcommand\freqPerFrag[1]{\colorbox{BlueViolet}{\textcolor{White}{#1}}}

% Number subsubsections
\setcounter{secnumdepth}{3}

\chapter{Einleitung}

\section{Zielstellung}

\newglossaryentry{GPU}{name={GPU},description={``Graphics Processing Unit'', auf Darstellung von 3D-Grafik spezialisierte Prozessoren}}
Ziel dieser Arbeit ist es, eine Sprache und einen Compiler zum Zweck der Programmierung von
3D-Grafikprozessoren~(``\gls{GPU}'', ``Graphics Processing Unit'') zu entwickeln.
GPUs sind aus verschiedenen Funktionseinheiten aufgebaut;
Sprache und Compiler sollen die GPU-Programmierung vereinfachen, in dem die Aufteilung eines Programms in mehrere Teilprogramme
für verschiedene Funktionseinheiten automatisch vorgenommen wird.

Weiterhin soll die entwickelte Sprache die Programmierung von GPUs syntaktisch unterstützen, wie es auch
bei es auch bei existierend Sprachen zu diesem Zweck üblich ist: durch Vektortypen, Unterstützung von Verknüpfungen
u.ä. von ganzen Vektoren sowie vordefinierte Funktionen für typische Vektoroperationen.


Der entwickelte Compiler soll einer modularen Standardarchitektur folgen: ein "`Front-End"' soll Eingaben übernehmen
und das Programm in eine interne Darstellung überführen, auf welcher ein "`Kern"' weitere Arbeitsschritte vornimmt;
abschliessend soll ein "`Back-End"' das Programm in eine Zieldarstellung ausgeben. Die vorgenommenen "`Arbeitsschritte"'
sollen nicht nur der typische Optimierungsschritt sein, sondern in diesem speziellen Compiler auch die "`Aufspaltung"'
des Programms in die Teile für die verschiedenen GPU-Funktionseinheiten vornehmen.

Für die interne Darstellung des zu übersetzenden Programms soll eine Zwischencoderepräsentation entworfen werden,
auf der die nötigen Arbeitsschritte -- also "`Aufspaltung"' und Optimierungen -- vorgenommen werden können
und aus der die Ausgabe in die Zieldarstellung generiert werden kann.

% In der Echtzeit-3D-Grafik werden 3D-Objekte überwiegend aus Dreiecken aufgebaut, welche für die Darstellung
% auf einem Bildschirm gerastert werden.

% Diese groben Arbeitsschritte spiegeln sich in dem Aufbau von 3D-Grafikprozessoren~(``\gls{GPU}'', ``Graphics Processing Unit''),
% deren Programmierschnittstellen~(\cite{glspec4}, \cite{dx10}), und, da GPUs programmierbar sind,
% auch in den auf den Grafikprozessoren laufenden Programmen wieder.

% GPU-Programme  kommen sowohl während der Verarbeitung von Dreiecken (bzw. deren Eckpunkten -- "`Vertexverarbeitung"') 
% und der Berechnung der Rasterbildpunkte ("`Fragmentverarbeitung"') zum Einsatz.
% Allerdings muss der Programmier die Aufteilung von Berechnungen gemäss dieser Verarbeitungsschritte sowie die Definition der "`Schnittstelle"'
% zwischen den beteiligten Verarbeitungseinheiten manuell vornehmen.

% Ziel dieser Arbeit ist es, einen Compiler zu entwickeln, der die Aufteilung in Programme für die Vertex- und Fragmentverarbeitung
% (und die entsprechended Schnittstellendefinition) automatisch vornimmt,
% ohne dass der Programmierer explizit angeben muss, auf welcher der Funktionseinheiten ein bestimmter Befehl ausgeführt wird.
% Berücksichtigt werden müssen, dass Vertex- und Fragmentprogramme verschiedene Eingaben annehmen.
% Auch muss bei der Auftrennung das Verhaltens der "`Schnittstelle"' zwischen den Verarbeitungseinheiten --
% diese Schnittstelle nimmt selbst Interpolationen vor -- beachtet werden.

%Die Programme sollen in der in Abschnitt~\ref{langspec} spezifizierten Sprache formuliert werden.
%Die Implementierung des Compilers wird in Abschnitt~\ref{implementation} beschrieben.

% Nochmal Abschnitt mit kurzer Beschreibung wichtiger Konzepte? (meshes, Vertices vs Fragmente, ...)

\section{Gliederung}

Zuerst wird eine Einführung in Grundlagen der 3D-Grafik vorgenommen. Diese sind nötig um die Absicht und Besonderheit des entwickelten Compilers zu verstehen.
Auch in den weiteren Kapiteln vorkommende, fachspezifische Begriffe werden dort erklärt.
%Insbesondere das für die Arbeit des Compilers essentielle Konzept der Berechnungsfrequenzen wird dort einführend erläutert.

Im Kapitel "`Sprachspezifikation"' wird die Sprache spezifiziert, in der die Programme geschrieben werden sollen.
Es werden allgemeine Anforderungen an die Sprache gestellt sowie auf spezielle Aspekte der vorzunehmenden Auftrennung von Programmen eingegangen.
Unter Berücksichtigung dieser Anforderungen und der speziellen Aspekte wird die Sprachsyntax sowie eine Auswahl vordefinierter Funktionen spezifiert.

Im darauf folgenden Kapitel wird schliesslich auf die Implementierung des Compilers selbst eingegangen. Insbesondere werden die verwendete Zwischencoderepräsentation
für die Weitergabe des Programmen zwischen den verschiedenen Arbeitsschritten des Compilers sowie das eigentliche "`Ziel"' dieser Arbeit,
die Komponente zur Auftrennung eines Programms, beschrieben. Auch der umgesetzte Generator für die Programm-Ausgabe sowie vorgenommene Optimierungen
werden erläutert.

Abschliessend, im Kapitel "`Evaluation"', wird die Leistung des Compilers anhand praxisnaher Beispielprogramme evaluiert.

% Abschluss?

\chapter{Einführung 3D-Grafik}

Dieses Kapitel beschreibt den Ablauf der Berechnung einer 3D-Grafik in Echtzeit.
Das Augenmerk liegt vor allem darauf, Grundlagen der Grafikkartenprogrammierung -- und damit verbundenen
Besonderheiten der verwendeten Sprache -- zu erklären, Zweck des entwickelten Compilers, dessen "`Zielhardware"' Grafikkarten sind,
zu verdeutlichen, und Gründe für dessen Funktionsweise zu liefern.

Diese Einführung erfasst nur einen kleinen Ausschnitt des Themengebietes "`3D-Grafik"' und seiner Unterkategorie
"`Echtzeit-3D-Grafik"'. Selbst die ausgewählten Sachverhalte werden nur vereinfacht dargestellt.
Eine umfassende Einführung sowie viele weitere Aspekte des Themenkomplexes "`3D-Grafik"' bietet zum Beispiel~\cite{watt_de}.

\section{Echtzeit-3D-Grafik}

Um "`Echtzeit-3D-Grafik"' handelt es sich, wenn eine 3D-Grafik mit dynamischen Komponenten (Animation, Änderung der Betrachterposition)
dargestellt werden soll, typischerweise verbunden mit einer Manipulation durch einen menschlichen Benutzer
(der z.B. die Betrachterposition kontrolliert). Unter anderem Szenarien von "`virtuellen Realitäten"' fallen darunter (z.B. Computerspiele).
Das "`Echtzeit"' im Namen bedeutet, dass die dargestellte Grafik mit möglichst geringer, idealerweise nicht wahrnehmbarer
Verzögerung dargestellt wird. Das vom Kino bekannte Prinzip, dass mit einem schnellen Bildwechsel aus statischen Bildern die Illusion von Bewegung
erzeugt werden kann, findet genau so auch der Echtzeit-3D-Grafik Anwendung: Computerspiele stellen typischerweise 30 oder 60 Bilder
pro Sekunde dar um Animationen überzeugend zu präsentieren. Dabei wird jedes dieser Bilder neu berechnet --
eine der Herausforderungen der Echtzeit-3D-Grafik ist also, für komplexe Szenarien Bilder in wenigen
Millisekunden zu berechnen.

\section{3D-Objekte und Szenen}
\label{objects}

\newglossaryentry{Dreiecksnetz}{name={Dreiecksnetz},description={3D-Modell, Menge von Eckpunkten (Vertices) und Dreiecken}}
\newglossaryentry{Vertex}{name={Vertex},plural={Vertices},description={Eckpunkt eines Dreiecksnetzes. Mehrzahl: Vertices}}
In einer Echtzeit-3D-Grafik darzustellende Objekte ("`Modelle"') werden als \emph{\gls{Dreiecksnetz}} gespeichert.
Dieses besteht aus einer Menge \emph{Eckpunkte} (``\gls{Vertex}'' bzw. ``Vertices'')
sowie von diesen aufgespannte \emph{Dreiecke}.

\begin{defn}
Ein \emph{3D-Modell} wird als \emphalt{Dreiecksnetz} gespeichert.
Zu diesen Dreiecken wird eine Menge von \emph{Eckpunkten} gespeichert.
\end{defn}

\begin{defn}
Ein \emphalt{Vertex} ist ein Eckpunkt eines Dreiecksnetzes.
\end{defn}

\newglossaryentry{Vertexattribut}{name={Vertexattribut},plural={Vertexattribute},description={Beschreibt weitere Daten, die jedem Vertex eines 3D-Modells zugeordnet sind. %
Attributtypen sind Vektoren mit ein bis vier Komponenten}}
Zu jedem Eckpunkt ist dessen \emph{Position}, eine Koordinate im dreidimensionalen Raum, gespeichert.
Praktisch sind zu jedem Eckpunkt auch noch weitere Daten gespeichert ("`\glspl{Vertexattribut}"'),
die bei der Berechnung der Oberflächenerscheinung des Objekts eine Rolle spielen.
Typischerweise verwendete Vertexattribute sind eine Oberflächennormale (als Vektor mit drei Komponenten)
sowie Koordinaten für ein Oberflächen-"`Muster"'\footnote{siehe Abschnitt~\ref{surface_and_shading}} (als Vektor mit zwei Komponenten).
(Man kann sich vorstellen, dass ein Verbundtyp die Vertexattribute definiert; die Menge der Vertices eines Modells wäre
eine Reihung von Werten dieses Typs, und ein Element enthält entsprechend die Attributwerte für ein Vertex.)

\begin{figure}[h]
  \centering
  \includegraphics[width=10cm]{mesh_wireframe_thick}
  \caption{"`Drahtgitter"'-Darstellung eines 3D-Objektes. Die einzelnen Eckpunkte und Dreiecke sind gut erkennbar.}
  \label{fig:wireframe_teapot}
\end{figure}

\newglossaryentry{Vertexattributwert}{name={Vertexattributwert},plural={Vertexattributwerte},description={Werte von Vertexattributen. Jedem Vertex ist für jedes Attribut ein Wert zugeordnet}}
\glsadd{Vertexattributwert} 
\begin{defn}
\emphalt{Vertexattribute} beschreiben die zu einem Vertex gespeicherten Daten. Es ist immer mindestens
ein Attribut "`Raumkoordinate"' vorhanden, es können aber eine beliebige Anzahl von Attributen verwendet werden.
Attributtypen sind Vektoren mit ein bis vier Komponenten.

%Die Anzahl der Attribute ist also beliebig, aber für jedes Vertex in einem 3D-Modell gleich.
In einem 3D-Modell besitzt jedes Vertex die gleichen Attribute, aber verschiedene Attribut\emph{werte}.
\end{defn}

Selten wird ein alleinstehendes 3D-Objekt dargestellt -- stattdessen wird praktisch immer mit aus mehreren Objekten
bestehenden 3D-"`\emph{Szenen}"' gearbeitet. In solchen Szenen ist es auch nicht unüblich, das selbe Objekt mehrfach,
aber an unterschiedlichen Position \mbox{und/oder} mit unterschiedlichen Drehungen darzustellen (z.B. eine Küchen-Szene mit identischem
Geschirr an verschiedenen Stellen). 3D-Objekte müssen also positioniert usw. werden. Dazu dienen \emph{Transformationen}
(Abbildungen). Ein 3D-Objektes wird mit einer Transformation transformiert, indem diese auf die Raumkoordinate jedes Vertices
des Modells angewendet wird.
%(In der 3D-Grafik sind verschiedene "`Räume"' definiert, und man arbeitet mit Abbildungen zwischen diesen Räumen,)

\newglossaryentry{Transformation}{name={Transformation},plural={Transformationen},description={%
Auf Raumkoordinaten von 3D-Modellen angewendete Abbildungen. Ermöglichen Verschiebungen, Rotation, Skalierung von Modellen}}
\begin{defn}
\emphalt{\glspl{Transformation}} sind Abbildungen von Raumkoordinaten auf Raumkoordinaten und dienen dazu,
3D-Objekte zu verschieben, zu rotieren oder zu skalieren.

Eine Transformation wird auf ein Objekt angewendet, indem auf die Raumkoordinaten aller Vertices dieselbe Transformation angewendet wird.
\end{defn}


Eine der bestimmenden Gründe, warum Echtzeit-3D-Grafik eingesetzt wird, ist die Möglichkeit eines "`freien Bewegens"' durch
eine Szene (z.B. könnte die beispielhafte Küche Teil einer "`virtuellen Hausbesichtigung"' sein).
Mit anderen Worten, der Blickpunkt und die Blickrichtung des Betrachters, oder auch \emph{Kamera}, soll veränderbar sein.
Auch dies wird unter Verwendung einer Transformation realisiert.

Transformationen bilden weiterhin die Grundlage der für Echtzeit-3D-Szenen typischen Dynamik von Szenen; Objekte werden animiert,
in dem die für die Positionierung verwendete Transformation über die Zeit verändert wird.

Schliesslich wird eine 3D-Szene in der Regel auf einem zweidimensionalen Ausgabegerät -- typischerweise einem Computermonitor --
dargestellt. Es muss also eine Herrunterrechnung auf die zweidimensionale Fläche, eine \emph{Projektion}, vorgenommen werden;
dabei muss, für korrekten räumlichen Eindruck, die \emph{perspektivische Verzerrung} berücksichtigt werden.
Auch diese Projektion und Verzerrung werden grundsätzlich durch Transformationen realisiert\footnote{Mit Besonderheiten bei der perspektivischen Verzerrung}.
Als letzten Schritt müssen die -- jetzt auf einer zweidimensionalen Fläche vorliegenden -- Dreiecke der Objekte
in Monitor-Pixel "`umgewandelt"', also \emph{gerastert}, werden. Für jedes dieser Pixel wird schliesslich die Farbe bestimmt,
mit der es auf dem Monitor dargestellt wird\footnote{Streng genommen werden diese Berechnungen nicht für Pixel sonder für \emph{Fragmente} vorgenommen --
ein Pixel kann mehrere Fragmente "`überdecken"', z.B. zum Zwecke der Kantenglättung. Zur Anschaulichkeit und Verständlichkeit ist es jedoch
ausreichend, über "`Pixel"' zu reden.}.

\section{Darstellung und Beleuchtung von Oberflächen}
\label{surface_and_shading}

Beleuchtung und Schattenwurf von 3D-Objekten geben einem menschlichen Betrachter wichtige Hinweise zur Form
einzelner Objekte sowie zur Positionierung von Objekten zueinander. Aus Lichtreflektionen der Oberfläche -- Art, Farbe und Zusammenspiel
mit Strukturen und Mustern -- lassen sich Materialeigenschaften und damit das dargestellte Material ableiten.

\newglossaryentry{Shading}{name={Shading},description={Berechnung der Farbe eines beleuchteten Punktes auf einer 3D-Oberfläche}}
Beleuchtungs- und Oberflächenberechnungen (``\emph{\gls{Shading}}'') sind bei der Darstellung von 3D-Objekten also äusserst wichtig.
Allerdings können diese auch Zeitaufwendig sein, insbesondere da in der Echtzeit-3D-Grafik die Szenen in der Regel
immer auch eine dynamische Komponente haben. Insbesondere Beleuchtungsberechnungen hängen von der Kameraposition
und/oder der Objektposition ab und müssen, wenn die Kamera oder Objekte sich bewegen, für jedes darzustellende Bild
neu berechnet werden. Aus der Anforderung der Echtzeit-3D-Grafik, für eine überzeugende Bewegungsdarstellung
Bilder genügend schnell zu berechnen, ergibt sich auch für die Beleuchtungs- und Oberflächenberechnung, dass diese
möglichst schnell von statten gehen soll.

Grundsätzlich wird ein Farbwert pro Rasterpunkt benötigt. Dazu wird aus der Koordinate des Rasterpunktes die ursprüngliche Koordinate
im dreidimensionalen Raum berechnet. Für diesen Punkt in Raum können dann Oberflächeneigenschaften bestimmt werden
(z.B. Farbe) und zusammen mit Informationen über vorhandene Lichtquellen kann die vom Betracher wahrgenommene 
"`Lichtreflektion"' berechnet werden.

Eine Berechnung für jeden Rasterpunkt ist zwar genau, aber in manchen Fällen zu aufwändig. Eine Annäherung ist,
solche Beleuchtungs- und Oberflächenberechnungen nur für die Eckpunkte des Dreiecks zu berechnen und das Ergebnis
dieser Berechnung linear über die Pixel des Dreiecks zu \emph{interpolieren}.

\begin{figure}[h]
  \centering
  (a) \includegraphics[scale=0.8]{triraster1}
  \qquad
  (b) \includegraphics[scale=0.8]{triraster2}
  %\qquad
  %(c) \includegraphics[scale=0.8]{triraster3}
  \caption{Rasterung eines Dreiecks:}
  \small (a) Nach Transformation in das Koordinatensystem des Monitors.\\
  (b) Vom Dreieck überlagerte Pixel.
  %(c) Ein Eckpunktattribut "`Grauwert"', über die Pixel interpoliert.
  \label{fig:triraster}
\end{figure}

Für eine überzeugende Darstellung einer Oberfläche sind deren Details wichtig, z.B. feine Muster in der Oberflächenfarbe.
Es liegt nahe, jedem Eckpunkt eines Dreiecks eine Farbe zuzuweisen; aber oftmals sollen die darzustellenden Details kleiner als die Dreiecke, aus denen
ein Modell aufgebaut wurde, sein.
\newglossaryentry{Textur}{name={Textur},plural={Texturen},description={Bilddaten, bei der Pixelverarbeitung ausgelesen. Typischerweise auf Oberfläche von Modellen "`gespannt"'}}
Zu diesem Zweck werden zweidimensionale Bilder\footnote{"`\glspl{Textur}"'}
über die Oberfläche "`gelegt"'. Dazu wird eine Abbildung auf die 3D-Raumkoordinate auf angewendet um eine 2D-Bildkoordinate,
an der das Bild ausgelesen wird, zu erhalten. Z.B. kann ein "`Blatt Papier"' durch zwei Dreiecke dargestellt werden, aber die Verwendung
eines Oberflächenbildes erlaubt es Text usw. darzustellen, was weit detaillierter ist, als es eine einfache Färbung der Dreieckseckpunkte erlauben würde.

An diesem Beispiel erkennt man, dass man nicht immer alle Teile von Beleuchtungs- und Oberflächenberechnungen für jeden Eckpunkt berechnen und
dann linear interpolieren kann -- dementsprechen lassen sich diese Teile nur sinnvoll berechnen, wenn die Rechnung für jeden Pixel individuell vorgenommen wird.

Andererseits gibt es bei der Dreiecksdarstellung auch Arbeitsschritte, die nur für jeden Eckpunkt berechnet werden können -- die Transformation eines
Dreiecks vor der Rasterung zum Beispiel: eine Berechnung für jeden Pixel ist schlicht unmöglich, da das Dreieck noch gar nicht gerastert wurde.

In der Praxis werden praktisch immer "`Mischformen"' bei der Beleuchtungs- und Oberflächenberechnungen verwendet: einige Werte oder
Zwischenergebnisse werden für jeden Eckpunkt berechnet; diese werden dann, bevor sie als Eingabe für eine für ein Pixel auszuführende
Berechnung dienen, interpoliert.
%(sofern dies sinnvoll ist, oder zumindest einem Betrachter nicht auffällt)

\section{Verarbeitungsschritte auf 3D-Grafikprozessoren}
\label{hw_steps}

Moderne Grafikchips (genannt ``Graphics Processing Unit'', kurz ``GPU'') sind auf Echtzeit-Darstellung von 3D-Grafiken spezialisierte Hardware.
Deren logischer Aufbaum, schematisch Abbildung~\ref{fig:3d_pipeline} dargestellt, ist auf die Darstellung von Dreiecksnetzen ausgerichtet. 

\begin{figure}[h]
  \centering
  \includegraphics{3d_pipeline}
  \caption{Schematische Darstellung der 3D-Grafik-Pipeline}
  \label{fig:3d_pipeline}
\end{figure}

\newglossaryentry{Vertexberechnungen}{name={Vertexberechnungen},description={Arbeitsschritt der GPU. Berechnungen, die für jedes Vertex des dargestellten 3D-Modells vorgenommen werden}}
Der erste Schritt bei der Darstellung
eines 3D-Objekts die Ausführung der für jedes Vertex erforderlichen Berechnungen ("`\gls{Vertexberechnungen}"').
Dies sind immer mindestens die Anwendung der Transformationen für ein Objekt auf die individuellen Raumkoordinaten der Eckpunkte;
in der Regel werden auch, wie oben genannte, Teile der Beleuchtungs- und Oberflächenberechnung vorgenommen.

Die Ergebnisse der Vertexberechnungen sind eine Pixelkoordinate sowie weitere "`Zwischenergebnisse"' der Beleuchtungs- und Oberflächenberechnung.
Analog zu Vertexattributen liefert jede Vertexberechnung die gleiche Anzahl von Ergebnis"`variablen"', aber deren \emph{Werte} unterscheiden sich
von Vertex zu Vertex.

\newglossaryentry{Rasterung}{name={Rasterung},description={Arbeitsschritt der GPU. Bestimmt Monitorpixel, die von einem Dreieck überdeckt werden}}
\glsadd{Rasterung}
Die Pixelkoordinaten der Vertices eines Dreiecks werden von einer speziellen Funktionseinheit verwendet um das Dreieck zu rastern:
ausgegeben werden alle Pixel, die vom Dreieck überdeckt werden. 
%Auch die Interpolation der weiteren Ausgaben der Eckpunktberechnungen -- die "`Zwischenergebnisse"' -- wird von dieser Funktionseinheit vorgenommen.

Aus den Ausgaben der Vertexberechnungen -- die oben erwähnten "`Zwischenergebnisse"' -- werden die Eingaben für die Pixelberechnungen abgeleitet.
Dies geschieht durch \emph{lineare Interpolation} zwischen den Ergebniswerten der Vertexberechnung für die drei Vertices, aus denen das gerade gerasterte
Dreieck besteht. Interpoliert wird auf der Ebene von Ergebnis"`variablen"' -- die Werte der ersten Ergebnis"`variablen"' für jeden Eckpunkt wird bestimmt,
zwischen diesen drei Werten wird interpoliert; daraufhin werden die Werte der zweiten Ergebnis"`variablen"' für jeden Eckpunkt bestimmt
und diese interpoliert; usw. Die Gewichtungsfaktoren für die Interpolation bestimmen sich aus der Position des Pixels, für deren Berechnungen
die Eingaben interpoliert werden, auf dem gerasterten Dreieck. Die Faktoren werden von der Funktionseinheit zur Rasterung der Dreiecke mitberechnet.

Abbildung~\ref{fig:interp_simple} zeigt für einen einfachen Fall (horizontale Pixel-Reihe) die Gewichtungsfaktoren für die Ergebnis"`variablen"'
zweier Eckpunkte eines Dreiecks. Erkennbar ist, dass die Gewichtungsfaktoren des ersten Eckpunkts abnehmen je näher man
dem zweiten Eckpunkt kommt; umgekehrt steigern sich dessen Gewichtungsfaktoren in dessen Richtung.

\begin{figure}[h]
  \centering
  \includegraphics[scale=0.8]{interp_simple}
  \caption{Gewichtungsfaktoren für die Interpolation zwischen Attributwerten zweier Vertices.}
  \small Oberer Faktor wird auf Werte des linken, unterer auf Werte des rechten Vertices angewendet.\\
  Gewichtungsfaktor für drittes Vertex kann vernachlässigt werden (ist $0$ für alle gezeigten Pixel).
  \label{fig:interp_simple}
\end{figure}

Abbildung~\ref{fig:triraster_lerp} zeigt beispielhaft das Ergebnis einer Interpolation für ein Pixel im Dreieck aus Abbildung~\ref{fig:triraster}.
Im Bild (a) ist das Beispielpixel hervorgehoben. $v_1$, $v_2$ und $v_3$ sind die Eckpunkte des Dreiecks.
$f_1$, $f_2$ und $f_3$ sind die Gewichtungsfaktoren für die Ausgaben der Vertexberechnungen.
In Bild (b) wurden diese Faktoren auf eine Ergebnis"`variable"' Grauwert angewendet. Die Dreieckseckpunkte wurden mit den Werten
dieser Ergebnis"`variable"' beschriftet. Für das Beispielpixel wurde der interpolierte Grauwert angegeben.

\begin{figure}[h]
  (a) \includegraphics[scale=0.8]{triraster_lerp}
  \qquad
  (b) \includegraphics[scale=0.8]{triraster_values}
  \caption{(a) Gewichtungsfaktoren für die Interpolation der Ausgaben der Vertexberechnungen für ein Dreieck.}
  \small (b) Für jeden Eckpunkt vorliegenden Werte und Interpolationsergebnis für einen Grauwert.
  \label{fig:triraster_lerp}
\end{figure}

% Interpolation: linear; zwischen Werten der Dreieckseckpunkte; Gewichtungsfaktor(en) von Position des Pixels auf Dreieck abhängig
% + Bild

\newglossaryentry{Interpolation}{name={Interpolation},description={Arbeitsschritt der GPU. Interpoliert zwischen Ausgaben der Vertexberechnungen,
Interpolationsergebnisse dienen als Eingaben für Pixelberechnungen}}
\begin{defn}
Die Eingaben der Pixelberechnungen werden aus den Ausgaben der Vertexberechnungen durch \emphalt{lineare \gls{Interpolation}}
abgeleitet.

Interpoliert wird zwischen den Ausgaben der Vertexberechnungen für die Eckpunkte des gerasterten Dreiecks.
Die Gewichtungsfaktoren für die Interpolation bestimmen sich aus der Position des Pixels im Dreieck.
\end{defn}

\newglossaryentry{Pixelberechnungen}{name={Pixelberechnungen},description={Arbeitsschritt der GPU. Berechnungen, die für jedes gerasterte Pixel eines Dreiecks vorgenommen werden}}
Schliesslich werden die für jeden Pixel vorzunehmenden Berechnungen ausgeführt\footnote{"`\gls{Pixelberechnungen}"'}.
Ausgabe dieses Schrittes ist ein Farbwert\footnote{Eigentlich ein Farbwert (Rot-Grün-Blau-Tripel) sowie eine Deckkraft ("`Alpha"'), für die Darstellung von transparenten Oberflächen}
der für die Darstellung des Pixels auf dem Monitor verwendet wird.

Tatsächlich sind den Pixelberechnungen nur die interpolierten Ausgaben der Vertexberechnung zugänglich -- auf für jedes Vertex vorliegenden
Eingaben oder Berechnungsergebnisse kann nicht einzeln zugegriffen werden (d.h. bei der Pixelberechnung können nicht Werte wie
"`Position des ersten Dreieckseckpunktes"' ausgelesen werden).

Die Vertex- wie auch Pixelberechnungen sind unabhängig -- d.h. die für ein Vertex oder Pixel ausgeführten Berechnungen hängen
nicht von den Werten anderer Vertices oder Pixel ab. (Tatsächlich wird ein "`Zugriff"' auf andere Vertices oder Pixel gar nicht erlaubt.)
Dies macht die Eckpunkt- und Pixelberechnungen gut parallelisierbar -- die jeweiligen Funktionseinheiten der GPUs sind dementsprechend aufgebaut:
sie führen gleichzeitig die Berechnungen für mehrere Vertices und Pixel aus.
Dazu kommt, das Eckpunkt- und Pixelberechnungen -- dem Wesen von 3D-Objekten geschuldet -- viel mit Vektoren arbeiten. Die Recheneinheiten
der Grafikkarten sind also in der Regel Vektoreinheiten.

\newglossaryentry{Shadingsprache}{name={Shadingsprache},plural={Shadingsprachen},description={Sprachen zur Programmierung von Eckpunkt- und Pixelberechnungen auf GPUs}}
Eine wichtige Eigenschaft ist die \emph{Programmierbarkeit} von Vertex- und Pixelberechnungen
-- die vorgenommenen Berechnungen werden also durch von einem Programmierer bereitgestellte
Programme bestimmt. 

Die GPUs selbst, als Mikroprozessoren, verarbeiten in einem Binärcode vorliegende Programme; dieser Code
wird jedoch von den Programmierschnittstellen "`versteckt"' und Programme werden in einer Hochsprache gegeben\footnote{GLSL bei OpenGL, HLSL bei DirectX}.
Die Sprachen werden "`\glspl{Shadingsprache}"' genannt.

Vertex- und Pixelverarbeitung sind zwei logisch getrennte Verarbeitungsschritte, nehmen verschiedenartige Eingabedaten entgegen und
werden auf zwei logisch verschiedenenen Funktionseinheiten vorgenommen. 
Die beiden hauptsächlich verwendetet Programmierschnittstellen für GPUs -- OpenGL (\cite{glspec4}) und DirectX (\cite{dx10}) -- spiegeln 
den Aufbau der 3D-Grafikprozessoren wider und erfordern, dass für jede Funktionseinheit explizit ein passendes Programm bereitgestellt werden muss:
zur Programmierung einer GPU müssen zwei Programme -- eines, das die Schritte der Vertexverarbeitung beschreibt ("`Vertexprogramm"'),
ein anderes für die Beschreibung der Pixelverarbeitung ("`Pixelprogramm"')
-- sowie eine "`Schnittstellendefinition"' (Ausgaben der Vertexverarbeitung bzw. Eingaben für die Pixelverarbeitung) erstellt werden.
Dabei muss darauf geachtet werden, dass diese drei Teile aufeinander abgestimmt sind: eine unpassende Schnittstellendefinition etwa
führt meist zu einer falschen Interpretation der Eingaben der Pixelverarbeitung und damit zu unbrauchbaren Ergebnissen.

\section{Daten eines 3D-Objektes}
\label{object_data}

Bei der Darstellung von 3D-Objekten verwendete Daten, Eingabedaten wie auch Zwischenergebnisse von Berechnungen,
liegen in verschieder "`Granularität"' vor:

\newglossaryentry{Objektattribut}{name={Objektattribut},plural={Objektattribute},description={Einem 3D-Modell zugeordnete Eigenschaften (z.B. Transformationen, Material)}}
\begin{itemize}
\item Einige Eingabedaten liegen für das \emph{Objekt} vor.
Dies sind vor allem die Transformationen -- verschiedene Objekte haben verschiedene Transformationen,
aber es wäre in der Regel unnötig, jedem Eckpunkt ein einem Dreiecksnetz eine Transformation zuzuweisen.
Auch einige "`Material"'eigenschaften -- z.B. ein auf die Oberfläche gelegtes Bild -- variieren typischerweise von Objekt zu Objekt.
Es kann bei diesen Daten von "`\glspl{Objektattribut}n"' gesprochen werden.
\item Für jedes \emph{Vertex} liegen natürlich die Raumkoordinaten der Vertices vor, aber auch 
die Werte der Vertexattribute -- wie u.a. die Oberflächennormale (bei Beleuchtungsberechnungen verwendet).
\item Für jedes \emph{Pixel} können \emph{Eingabe}daten nicht sinnvoll vorliegen -- schliesslich ist ja nicht bekannt, wie ein Dreieck
schlussendlich gerastert wird. Allerdings liegen Zwischenergebnisse von Berechnungen per Pixel vor -- die  interpolierten Ausgaben der
Eckpunktberechnung sowie Berechnungen in der Pixelverarbeitung selbst, z.B. das Auslesen eines Bildes
zur Färbung der Oberfläche.
\end{itemize}

Je nachdem, auf welchen Eingabedaten bzw. Operanden eine Berechnung operiert, muss diese verschieden oft ausgeführt werden.
Berechnungen, die Operanden verwenden, die in der \emph{Pixelverarbeitung} bestimmt wurden (z.B. aus einem Oberflächenmuster ausgelesene Farbe),
müssen für jedes Pixel ausgeführt werden;
demgegenüber müssen Berechnungen, die von Daten abhängen, die bloss für jedes \emph{Vertex} vorliegen (z.B. Raumkoordinate)
auch nur für jedes \emph{Vertex} ausgeführt werden.

Nun treten praktisch viel mehr Pixel- als Vertex-Berechnungen auf -- Abbildung~\ref{fig:triraster} zeigt beispielhaft,
dass ein durch \emph{drei} Vertices definiertes Dreieck eine \emph{Vielzahl} von Pixeln überdeckt wird.

Eine Folge daraus ist, dass es erstrebenswert ist, möglichst viele Berechnungen in der Vertexverarbeitung vorzunehmen, deren Ergebnisse interpolieren zu lassen
und nur in der Pixelverarbeitung auszurechnen, was wirklich nur dort ausgerechnet werden kann: da, auf die gesamte Darstellung einer 3D-Grafik gesehen,
in der Regel viel weniger Berechnungen vertexweise als pixelweise ausgeführt werden, verringert die Ausführung einer Operation in der Vertexverarbeitung statt in der Pixelverarbeitung
den gesamten Berechnungsaufwand.

\section{Beispiel}

%An einem beispielhaften Shadingprogramms -- geschrieben in Cg -- sollen einige der genannten allgemeinen Konzepte 
%Um einige der genannten allgemeinen Konzepte  sowie die Funktionsweise von 3D-Grafikhardware

Ein Shadingprogramm, geschrieben in Cg, soll als praktisches Beispiel der Programmierbarkeit von 3D-Grafikprozessoren dienen.
Es soll gezeigt werden, wie die Funktionsweise von GPUs sowie einige Konzepte, die in den vorherigen
Abschnitten genannt wurden, sich in Shadingprogrammen äussern. Das Beispielprogramm ist in Abbildung~\ref{fig:simple_cg} aufgelistet.

\begin{figure}[hp]
  \input{simple_cg}
  \caption{Ein Programm-Paar in Cg.}
  %\centering
  %\small Operationen und Werte sind von der Berechnungsfrequenz abhängig markiert (\freqPerMesh{Mesh}, \freqPerVert{Vertex}, \freqPerFrag{Fragment})
  \label{fig:simple_cg}
\end{figure}

\subsection{Programmaufbau}

Das Beispielprogramm ist zwar als \emph{ein} Quelltext gegeben, trotzdem sind die Programme für die Vertexberechnungen
und Pixelberechnungen logisch getrennt -- in diesem Fall, in dem sie durch zwei getrennte Funktionen definiert wurden
(\verb+vertex_main+ für die Vertexberechnungen bzw. \verb+pixel_main+ für die Pixelberechnungen).
% VertexOutput: Vertexausgaben, "Schnittstelle" Vertexausgaben->Pixeleingaben

Der Strukturtyp \verb+VertexOutput+ beschreibt die Ergebnisse der für jedes Vertex vorgenommenen Berechnungen.
Gleichzeitig dient er als Typ eines Eingabeparameter des Programms für die Pixelberechnungen, dient also damit
auch als "`Schnittstellenbeschreibung"' zwischen Vertex- und Pixelprogrammen. Insbesondere sei daran erinnert
dass diese Ergebnisse der Vertexberechnungen vor der Eingabe an das Pixelprogramm interpoliert werden.

\subsection{Eingaben und Ausgaben}

% verschiedene Eingabedaten, für ganzes Objekt wie auch jedes Vertex vorliegend
Das Beispielprogramm benutzt verschiedenartige Eingaben, sowohl Objektattribute wie auch Werte von Vertexattributen.

Zu den Objektattributen (\freqPerMesh{im Quelltext umrandet}), also sich innerhalb eines 3D-Objekts nicht verändernde Werte,
gehört zunächst eine \emph{Transformation} (\verb+ModelViewProj+). Es wird erwartet, dass die verschiedenen typischen Transformationen
(Objektposition und -rotation, Betrachterposition und -blickrichtung, perspektivische Projektion) zu einer einzigen Transformation konkateniert wurden.

\verb+LightColor+, \verb+LightDirObj+ sind Eigenschaften einer Lichtquelle (Farbe bzw. Richtung, aus der Licht scheint);
\verb+Texture+ (Eingabe des Pixelprogramms) ist ein "`Muster"', aus welchem die Oberflächenfarbe abgeleitet wird.
Diese Objektattribute bestimmen also Beleuchtung und Aussehen der Oberfläche.

% ModelViewProj, LightColor, LightDirObj, Texture: Objektattribute
% Position, TexCoord, Normal: jedes Vertex

Vertexattribute (\freqPerVert{hell hinterlegt}) sind \verb+Position+ (Raumkoordinate), \verb+TexCoord+ (2D-Koordinate auf dem Oberflächenmuster)
und \verb+Normal+ (Oberflächennormale).

Die Eingabe \verb+interpolatedVertexOutput+ des Pixelprogramms sind als "`für jedes Pixel vorliegend"' (\freqPerFrag{dunkel hinterlegt}) markiert.
Wie verträgt sich das mit der in Abschnitt~\ref{object_data} gemachten Aussage, Eingabedaten könnten nicht sinnvoll für jedes
Pixel vorliegen? Die für jedes Pixel vorliegenden Eingabeparameter des Pixelprogramms sind keine "`direkten"' Eingaben,
wie sie etwa die Werte der Objekt- oder Vertexattribute sind, sondern \emph{abgeleitete} Eingaben --
aus den Ergebnissen der Vertexberechnung interpolierte Werte.

% vorher: Pixeleingaben "nicht sinnvoll", hier Pixel-Eingaben? -> interpoliert
Zwei Ausgaben haben eine besondere Bedeutung: \verb+output.Position+ des Vertexprogramms und \verb+outColor+ des Pixelprogramms.
\verb+output.Position+ ist die in Monitorkoordinaten transformierte Position eines Vertices. Die Rasterung der Dreiecke wird anhand dieser
Positionen der Dreieckseckpunkte vorgenommen. (In Cg markiert ``\verb+: POSITION+'' die besondere "`Rolle"' dieses Ausgabewertes des Vertexprogramms.)

Die zweite "`besondere"' Ausgabe ist der Ausgabeparameter \verb+outColor+ des Pixelprogramms. Durch diesen wird die auf dem Monitor
darzustellende Pixelfarbe bestimmt. (``\verb+: COLOR+'' ist die Cg-Syntax, um den Parameter als "`Pixelfarbe"' zu kennzeichnen.)
Darüber hinaus wären weitere Ausgaben nicht sinnvoll (so kann ein Monitorpixel nur einen Farbwert besitzen).

\subsection{Berechnungen}

% Programm ist kurz
% setzt beleuchtete, gemusterte Oberfläche um
% Lichtberechnung unter Ausnutzung von Interpolation

Das Beispielprogramm ist zwar kurz, setzt aber einige der in den Abschnitten~\ref{objects} und~\ref{surface_and_shading} genannten Konzepte um.

So wird auf das dargestellte Objekt eine \emph{Transformation}(\verb+ModelViewProj+) angewendet und das Ergebnis als Ausgabekoordinate --
also als Bildschirmkoordinate für ein Vertex -- verwendet (Zuweisung von \verb+output.Position+).

Als einfache Oberflächen- und Beleuchtungsberechnung wird für jedes Vertex ein Beleuchtungswert berechnet, diese werden über die Bildschirmpixel
der Dreiecke interpoliert, und schliesslich noch mit einem Oberflächenmuster "`eingefärbt"'.

Der Beleuchtungswert ist die Ausgabe \verb+output.litColor+. Die Beleuchtungsintensität für die gegebenene Lichtrichtung abhängig von der Oberflächenrichtung
(\verb+dot (...)+-Operation) wird mit der Lichtfarbe (\verb+LightColor+) multipliziert, woraus sich die "`Beleuchtung"' der Oberfläche an dem
Vertex, für den die Vertexberechnungen vorgenommen werden, ergibt. \verb+ambient+ ist eine Annäherung von "`indirektem Licht"' und wird
zu der Gesamtbeleuchtung addiert\footnote{Solche Annäherungen werden verwendet, um schattierte Bereiche aufzuhellen, was von
menschlichen Betrachtern u.U. als "`besser aussehend"' wahrgenommen wird.}.

Die Interpolation dieses Beleuchtungswertes wird nicht explizit angegeben -- diese wird implizit von der GPU während der Dreiecksrasterung
vorgenommen. Das Pixelprogramm "`sieht"' nur den aus den Ergebnissen der Vertexberechnungen interpolierten Eingabewert.

Der Eingabeparameter \verb+TexCoord+ wird von Vertexprogramm unverändert wieder ausgegeben (Zuweisung zu \verb+output.TexCoord+) --
ein Pixelprogramm kann keine Werte von Vertexattributen als Eingaben annehmen, alle solchen Eingaben müssen also im Vertexprogramm
explizit "`durchgeschleift"' werden. Dabei ist zu beachten, dass, wie alle Ausgaben der Vertexberechnung, auch zwischen \verb+output.TexCoord+-Werten
von mehreren Vertices interpoliert wird, bevor es als Eingabe für das Pixelprogramm dient.

Schliesslich wird, im Pixelprogramm, die Oberfläche mit einem "`Muster"' versehen. Der Farbwert des Musters, \verb+surface+, wird aus dem Bild \verb+Texture+
an den Koordinaten \verb+interpolatedVertexOutput.TexCoord+ ausgelesen (\verb+tex2D (...)+-Operation).
Die implizite Interpolation von \verb+interpolatedVertexOutput.TexCoord+ ist also wünschenswert, da dadurch die Bildkoordinaten,
und damit die ausgelesene Musterfarbe, über die Dreieckspixel variieren. (Ohne eine solche Variation -- also nur ein Auslesen an einigen wenigen verschiedenen Koordinaten --
wäre die Darstellung des Musters nicht sehr detailliert.)

Die Einfärbung der Oberflächenfarbe mit dem Beleuchtungswert wird durch eine einfache Multiplikation der Oberflächenfarbe mit
dem Beleuchtungswert erreicht. Damit ergibt sich die ausgegebene Pixelfarbe (\verb+outColor+).

\subsection{Darstellung}

Abbildung~\ref{fig:simple_cg_images} zeigt ein 3D-Modell, welches mit dem Beispielprogramm aus Abbildung~\ref{fig:simple_cg} dargestellt wurde.
Zur Verdeutlichung des Einflusses der verschiedenen Verarbeitungsschritte wurde nicht nur das Endergebnis, sondern auch einige Zwischenergebnisse
visualisiert. Abbildung~\ref{fig:simple_cg_images_large} zeigt vergrößerte Ausschnitte der Bilder aus Abbildung~\ref{fig:simple_cg}.

Bild (a) stellt das 3D-Modell in Drahtgitterdarstellung da. Dies lässt erkennen, wo sich die Vertices des Modells befinden.

Bild (b) zeigt die Anteile der Berechnungen mit  "`Objektattributen"' (speziell wurde der Wert von \verb+ambient+ ausgegeben).

Bild (c) nimmt die Ergebnisse der Vertexberechnungen hinzu (\verb+output.litColor+). In der Vergrößerung lässt sich die Interpolation
dieses, als Ausgaben der Vertexberechnungen vorliegenden, Wertes über die Pixel der Dreiecke erkennen.

Bild (d) zeigt das Ergebnis der "`kompletten"' Berechnung (\verb+outColor+). Gut erkennbar sind die Details aus dem Oberflächenmuster,
wodurch jedes Pixel quasi eine individuelle Farbe erhält: diese Details "`maskieren"' die Interpolation des Beleuchtungswertes, diese ist
praktisch nicht auszumachen.

\begin{figure}[h]
  \centering
  (a) \includegraphics[width=6cm]{mesh_wireframe_thin}\qquad
  (b) \includegraphics[width=6cm]{simple_s1_mesh}\\
  \vspace{1em}
  (c) \includegraphics[width=6cm]{simple_s1_vert}\qquad
  (d) \includegraphics[width=6cm]{simple_s1_frag}
  \caption{3D-Modell, mit Programm aus \ref{fig:simple_cg} dargestellt}
  \small (a): Drahgitterdarstellung\\
  (b): Nur die Anteile aus den Objektattributen\\
  (c): Anteile aus Vertexberechnungen hinzugenommen\\
  (d): Anteile aus Pixelberechnungen hinzugenommen
  \label{fig:simple_cg_images}
\end{figure}

\begin{figure}[h]
  \centering
  (a) \includegraphics[width=6cm]{simple_s1_crop_large_wire}\qquad
  (b) \includegraphics[width=6cm]{simple_s1_crop_large_mesh}\\
  \vspace{1em}
  (c) \includegraphics[width=6cm]{simple_s1_crop_large_vert}\qquad
  (d) \includegraphics[width=6cm]{simple_s1_crop_large_frag}
  \caption{Vergrößerungen aus Abbildung~\ref{fig:simple_cg_images}}
  \label{fig:simple_cg_images_large}
\end{figure}

% \section{Auswirkungen auf Sprache und Compiler}

% Compilerziel: Eingabe _ein_ Programm
% Ziel des Compilers soll es sein, als Eingabe \emph{ein} Shadingprogramm -- mit einer Hauptfunktion usw., nicht nur "`ein Quelltext"' -- entgegenzunehmen
% und daraus Programme zu erzeugen, die für die programmierbaren Grafikchip-Einheiten zur Vertex- bzw. Pixelverarbeitung genutzt werden können.

% Erwähnung "Domänen"/"Frequenzen"/etc. -> klären, in Operationen auf welchen Daten man Prog. formuliert (hier Pixel)
% Shadingprogramme arbeiten mit verschiedenen Daten (Objektattribute, Werte von Vertexattributen, abgeleitete Eingaben der Pixelverarbeitung)
% und bestehen aus zwei Teilprogrammen, die mit Vertex- und Pixelverarbeitung auf verschiedene "`Klassen"' von Berechnungen vornehmen.
% Für die zu übersetzende Shadingsprache muss also entschieden werden, in welcher der "`Klassen"' sie formuliert werden soll --
% in diesem Fall sollen Programme so formuliert werden, als würden sie grundsätzlich für jedes Pixel ausgeführt werden.

% Ausgabe: zwei Programme (Vertex, Pixel)
% Prog.-Ausg.: Vertexkoord., Pixelkoord.
% Berechnung+Verwendung von Werten in versch. Programmen handhaben
% Implizite Interpolation berücksichtigen

% Der Compiler muss also dann für jeden Ausdruck entscheiden, ob er während der Pixelverarbeitung ausgeführt werden muss
% oder während der Vertexverarbeitung ausgeführt werden soll.
% Dabei ist zu berücksichtigen, dass einige Operationen nur in einem der Verarbeitungsschritte sinnvoll sind -- z.B. sollte ein Auslesen
% eines Bildes zur Anwendung eines Oberflächenmusters sinnvollerweise in der Pixelverarbeitung vorgenommen werden.

% Da einige Operation in der Vertex-, andere in der Pixelverarbeitung ausgeführt werden sollen, müssen bei komplexeren
% Ausdrücken Zwischenergebnisse von der Vertex- zur Pixelverarbeitung übergeben werden. Es muss also die "`Schnittstelle"'
% zwischen den Verarbeitungseinheiten generiert werden.

% Auch muss die von der Grafikhardware vorgenommene implizite Interpolation von Ergebnissen der Vertexverarbeitung in Betracht
% gezogen werden. D.h. der Compiler muss die Operationen des Programms so aufteilen, dass die Interpolation bei der Übergabe
% von Werten von der Vertex- zur Pixelverarbeitung nicht die Berechnungen des Programms "`verfälscht"'. (Würde z.B. der Ausdruck 
% $x^2$ in der Vertexberechnung berechnet und interpoliert in der Pixelverarbeitung verwendet werden, so käme dies einer
% lineare Approximation einer quadratischen Kurve gleich -- der Wert des Ausdruck wäre ungenauer, also "`verfälscht"'.)

\section{Zusammenfassung}

Bei der Echtzeit-3D-Grafik werden von der GPU als Dreiecksnetze vorliegende 3D-Modelle dargestellt.
Diese Modelle bestehen aus \emph{``Vertices''}, die die Eckpunkte von Dreiecken bilden. Bei der Darstellung eines
Modelles wird zuerst die \emph{Vertexverarbeitung} vorgenommen; dabei werden die Raumkoordinaten der Vertices transformiert
und weitere Berechnungen auf den Vertices zugeordneten Daten vorgenommen ("`Vertexattribute"').
Als nächsten Schritt der Darstellung werden Dreiecke bei der \emph{Rasterung} auf Pixel des Ausgabegerätes abgebildet.
Bei dieser \emph{Pixelverarbeitung} dienen als Eingaben die Ausgaben der Vertexverarbeitung, allerdings \emph{interpoliert}.
Es werden weitere Berechnung vorgenommen, um Details hinzuzufügen, für die eine Berechnung per Vertex zu "`grob"' wäre,
wie das "`aufziehen"' von Bilddaten auf das 3D-Modell.

Die Verarbeitungsschritte "`Vertexverarbeitung"' und "`Pixelverarbeitung"' sind beide programmierbar, 
jedoch nur getrennt -- ein Programmier muss also für jede der Funktionseinheiten ein eigenes Programm schreiben.
%die Ausgabe des Compilers soll ein Programm-Paar aus Vertex- und Pixelprogramm sein.

% Aus den Verarbeitungsschritten der Echtzeit-3D-Grafik wurde das Konzept der \emph{Berechnungsfrequenz} abgeleitet:
% diese sagt aus, auf welche Verarbeitungseinheit eine Operation eines GPU-Programms ausgeführt werden muss.
% Die Berechnungsfrequenz wird vom Compiler verwendet werden, um zu bestimmen,
% in welches Ausgabeprogramm (Vertex- oder Fragmentprogramm) eine Operation ausgegeben werden muss.

% Als "`3D-Grafik"' wird die Berechnung zweidimensionaler Bilder aus dreidimensionalen Daten (die sog. "`\emph{Szene}"')
%  bezeichnet.
% Anwendung findet sie in vielen Bereichen: Visualisierung abstrakter mathematischer Formeln, Darstellung
% von geologischen Profilen, digitales Erstellen von Konstruktionszeichnungen, Spezialeffekte in Filmen und
% Rundgänge durch künstliche Szenarien in Computerspielen. 

% \section{Vorberechnete 3D-Grafik und Echtzeit-3D-Grafik}

% Die Berechnung von 3D-Grafiken wird als \emph{Rendering} bezeichnet. Bei den Anwendungen für das Rendering
% von 3D-Grafiken ist eine wichtige Untergruppe die der \emph{Echtzeitgrafik}, die sich durch besondere Anforderungen
% an die Berechnungszeit abgrenzt.

% \emph{"`Vorberechnete"'} 3D-Grafiken kommen vor allem zur Anwendung, wenn fast realitätsnahe Bilder gewünscht sind.
% Für deren hohe Bildauflösungen und komplexe Berechnungen werden lange Renderingzeiten (Minuten bis Stunden) in Kauf
% genommen. Beispiele 
% für vorberechnete Grafiken sind computergenerierte Spezialeffekte in Filmen bzw. komplette Kinofilme aus dem Computer.

% Dagegen fordert \emph{Echtzeitgrafik} Bildberechnungen, die nur Bruchteile einer Sekunde benötigen, um
% dynamische Daten mit geringen bis keinen wahrnehmbaren Verzögerungen in einer 3D-Grafik 
% darzustellen.

% Beispiele hierfür sind Konstruktionszeichnungen und Computerspiele. Diese stehen auch für verschiedene Anforderungen,
% die trotzdem unter "`Echtzeitdarstellung"' fallen: Konstruktionszeichnungen müssen meist mit sehr großen Datenmengen 
% agieren, aber trotzdem die Verzögerungen geringstmöglich halten, wobei noch wahrnehmbare Pausen toleriert
% werden. Bildraten ab 15 Bildern/Sekunde werden als "`interaktiv"' bezeichnet. % TODO Ref?
% Computerspiele hingegen haben strengere Anforderungen: um die Illusion von Bewegung zu erzeugen ist es hier nötig,
%  mindestens 25 Bilder in einer Sekunde\footnote{Es wird in der Regel die höchstmögliche Anzahl von Bildern pro Sekunde 
% angestrebt um alle Bewegungen möglichst flüssig darzustellen.} darzustellen. Überzeugende Bewegungsdarstellung und
% geringe Latenzen bei Aktionen des Spielers sind von höchster Wichtigkeit; dafür werden aber, im Vergleich zur
% Verwendung vorberechneter 3D-Grafiken, reduzierte Details in Kauf genommen.

% \section{Renderingmethoden}

% Die zu rendernden zweidimensionalen Bilder werden in fast allen Fällen als Rastergrafiken gespeichert\footnote{Es gibt
% auch Renderer, die Vektorgrafiken erzeugen können.}: für jedes Pixel der Rastergrafik muss aus den gegebenen dreidimensionalen
% Daten ein Farbwert berechnet werden. Die beiden hauptsächlich verwendeten Methoden sind Ray Tracing und Rasterung.

% Beim \emph{Ray Tracing} wird für jeden Bildpunkt ausgehend ein Strahl in die dreidimensionale Szene nachverfolgt. 
% Die Farbe des Bildpixels wird aus dem "`Licht"', welches von der Oberfläche des zuerst "`getroffenen"' Objekts reflektiert wird,
% berechnet. Dieses reflektierte Licht wird entweder durch eine Annäherung oder durch weiteres, rekursives
% Nachverfolgen von Strahlen bestimmt. 
% Vorteile des Ray Tracings sind die einfache Unterstützung von Schatten und Effekten wie spiegelnde
% Oberflächen und Lichtbrechung; Nachteil ist der nötige Rechenaufwand.
% \footnote{Ray Tracing ist detailliert in~\cite{watt_de}, Kap. 12, beschrieben.}

% Beim \emph{Rastern} werden die Daten hingegen auf die Bildpixel projiziert und Farbwerte für diese Pixel berechnet.
% Während dies weniger rechenintensiv als Ray Tracing ist können jedoch Effekte wie Spiegelungen und Schatten nicht so
% einfach berechnet werden, sondern werden meist approximiert.\footnote{Siehe auch~\cite{watt_de}, Kap. 4.}

% Die Geschwindigkeit und Einfachheit des Rasterns ist jedoch vorteilhaft für die Echtzeitgrafik und ist dort die praktisch
% ausschließlich verwendete Variante. % TODO Intel-Ray Tracer
% Vor allem ist spezielle, die Rasterung stark beschleunigende Hardware verfügbar. % TODO siehe Aufbau Hardware

% Ray Tracing dagegen findet vor allem bei der Vorberechnung von 3D-Grafiken statt.
%%Allerdings wird dort zunächst auch Rasterung eingesetzt,
%%gemischt mit Ray Tracing wenn benötigt (z.B. reflektierende Oberflächen). % TODO Ref?

% \section{Grundlegende Strukturen}

% \subsection{Modelle}
% \label{tri_mesh}

% Dreidimensionale Objekte ("`\emph{Modelle}"') einer Szene können auf verschiedene Arten repräsentiert werden~(\cite{watt_de}, S. 45-47). 

% \newglossaryentry{Dreiecksnetz}{name={Dreiecksnetz},description={3D-Modell, Menge von Eckpunkten (Vertices) und Dreiecken}}
% \newglossaryentry{Vertex}{name={Vertex},plural={Vertices},description={Eckpunkt eines Dreiecksnetzes. Mehrzahl: Vertices}}
% Die einfachste Form der Darstellung ist die des \emph{\gls{Dreiecksnetz}es} (engl. ``triangle mesh'' und kürzer ``mesh'').
%  Diese bestehen aus einer Menge von Eckpunkten,
% als \emph{\glspl{Vertex}} bezeichnet, sowie einer Menge von Dreiecken, wobei deren Ecken aus der Menge der Vertices stammen.
% Einem Vertex ist mindestens eine Position im Raum, meist aber auch weitere Daten, die für die Oberflächendarstellung und
% \mbox{-schattierung} verwendet werden,  zugeordnet~(\cite{watt_de}, S. 50).
% Analog sind auch Dreiecken neben Referenzen zu den Eckvertices weitere Daten wie z.B. eine Oberflächenfarbe zugeordnet.


% Um ein passgenaues Abschließen der Dreiecke zu sichern teilen sich in der Regel Ecken mehrerer Dreiecke ein
% Vertex\footnote{Selten haben zwei Ecken in \emph{einem} Dreieck das selbe Vertex -- dies führt zu "`degenerierten"' Dreiecken}. 
% Der Vorteil von Dreiecksnetzen ist deren Einfachheit. Insbesondere das Rastern von Dreiecken kann mit wenig Aufwand
% implementiert werden. Auch können Oberflächen beliebig genau angenähert werden. Diese Eigenschaften sind aber auch
% nachteilig: einige Oberflächen \emph{müssen} angenähert werden. So kann z.B. eine Kugel nicht perfekt durch ein Dreiecksnetz
% abgebildet werden. 

%%Bild Drahtgitter
% \begin{figure}[h]
%   \centering
%   \includegraphics[width=10cm]{drahtgitter}
%   \caption{Ein 3D-Würfel mit schattierten Seiten, als Drahtgittermodell und eine Aufteilung in Dreiecke. Die Vertices
%   sind die Eckpunkte des Würfels.}
%   \label{fig:wirecube}
% \end{figure}

% Hervorzuheben ist, dass auf die Berechnung von 3D-Grafiken spezialisierte Hardware 
% ausschließlich mit Dreiecksdaten arbeiten -- die Hardware kann eigentlich nichts anderes zeichnen. Wegen der Einfachheit der Darstellung
% können aber sehr viele Dreiecke in einer Sekunde ausgegeben werden. 

% Andere Arten der Modelldarstellung, wie die \emph{implizite Darstellung}\footnote{Beschreibung eines Objekts durch eine Formel,
% z.B. $x^2 + y^2 + z^2 = r^2$ für eine Kugel -- siehe~\cite{watt_de}, Abschn. 2.4}, \emph{Voxelgrafiken}\footnote{Voxel: ``volumetric pixel'' --
% Analog zu Bildern sind dies dreidimensionale Raster, an dessen Rasterpunkte Farbwerte o.ä. gespeichert werden -- siehe~\cite{watt_de}, Abschn. 4.4}
% und \emph{Patches}\footnote{Einfach gesagt, gekrümmte Vierecke -- durch mathematische Formeln beschriebene Oberflächen -- siehe~\cite{watt_de}, Kap. 3}
% finden in der Echtzeit-3D-Grafik kaum Verwendung, da sie -- im Vergleich zu Dreiecksnetzen -- aufwändig in der Darstellung sind.

% So müssen auf 3D-Grafik-Hardware gekrümmte Oberflächen (wie Kugeln, Patches) unter Verwendung von Dreiecken visualisiert werden:
% die Oberfläche wird mit einer hohen Anzahl von Dreiecken angenähert.

%%Auch zum Umrechnen von Voxel-Daten existieren Algorithmen, um daraus Dreiecksdaten zu erzeugen. % TODO Ref Marching cubes, Slides
% Auch Voxel-Daten müssen dort durch Dreiecksdaten angenähert werden,
% entweder als Dreiecksnetz einer Oberfläche (``marching cubes''-Algorithmus,~\cite{watt_de} Abschn. 13.3.1)
% oder durch Benutzung von Schnittflächen~(\cite{watt_de} Abschn. 13.6).

%%TODO Skizze Rendering-Pipeline?

% \subsection{Räume, Transformationen und Kamera}

% In praktischen Anwendungen wird selten ein einziges Modell statisch dargestellt. In der Regel müssen mehrere Modelle
% gleichzeitig dargestellt werden (z.B. zusammengesetztes Bauteil), wobei die Modelle
% in bestimmter Weise zueinander positioniert dargestellt werden müssen. Weiterhin soll ein "`Bewegen"' im Raum --
% also die Betrachtung von beliebigen Punkten aus -- möglich sein. Dieser "`Blickpunkt"' des Betrachters ist die \emph{Kamera}.

% Zu diesem Zweck werden verschiedene \emph{virtuelle Räume} definiert~(\cite{watt_de}, S. 166ff).
%  So gibt es für jedes Modell ein \emph{Objektkoordinatensystem}\footnote{engl. ``object space''},
% in dem sich alle Koordinaten des Modells befinden. 
% Die Positionierung verschiedener Modelle zueinander wird im \emph{Weltkoordinatensystem}\footnote{engl. ``world space''} vorgenommen. 
% Dazu wird jedem Modell eine \emph{Transformation} zugewiesen, welche Koordinaten aus dem Objekt- in das
% Weltkoordinatensystem überführt. 

% Eine Transformation wendet Verschiebungen, Skalierungen und Rotationen an. Als Repräsentation von Transformationen
% verwendet man Matrizen\footnote{Genauer: $4 \times 4$-Matrizen -- die dreidimensionalen Koordinaten des Modells werden
% in homogene Koordinaten überführt. Die Verwendung von homogenen Koordinaten
% erlaubt das Darstellen von Verschiebungen in der Matrix.}, % Ref Watt (DE)
% jede Koordinate wird dann mit der Transformationsmatrix multipliziert. Mehrere Transformationen können angewendet werden, indem 
% die entsprechenden Matrizen der Teiltransformationen in der gewünschten Reihenfolge zu der Gesamtmatrix konkateniert werden~(\cite{watt_de}, Kap. 1).

% Die Übersetzung eines Dreiecksnetz-Modells in das Weltkoordinatensystem erfordert nur die Anwendung der Transformationsmatrix
% auf die Koordinaten aller Vertices.

%%TODO Hier Skizze 
% Die Position des Betrachters wird durch das \emph{Kamerakoordinatensystem}\footnote{engl. ``eye space'' oder ``camera space''}
%  bestimmt. Dies ist so definiert, dass der "`Blickpunkt"' am Koordinatenursprung des Systems liegt
% und die "`Blickrichtung"' einer gegebenen Achse entspricht. 
% Durch eine weitere Transformation werden Welt-Koordinaten in Kamera-Koordinaten
% überführt. Dies erlaubt eine beliebige Positionierung des Betrachters in der Szene und eine beliebige Blickrichtung.
% Die zugrundeliegenden Prinzipien sind die selben wie bei der Transformation aus dem Objektkoordinatensystem.

% Der Blickpunkt ist ein Punkt in einem \emph{dreidimensionalem} Raum, eine Szene wird jedoch auf einem
% \emph{zweidimensionalem} Bild dargestellt -- die "`verlorene"' Dimension ist die Tiefe.
% Daher wird eine \emph{Bildebene} in geringem Abstand zum Betrachter gesetzt,
% welche als "`Projektionsfläche"' der Szene dient.

% Weiterhin müssen Modelle \emph{perspektivisch verzerrt} werden. 
% Stark vereinfacht gesagt werden auf die Kamera-Koordinaten eine \emph{Projektionsmatrix} angewendet, welche dazu führt,
% das bei der Projektion auf die Bildebene jede Koordinate durch ihre $z$-Komponente dividiert wird -- eine perspektivische Verzerrung.
% \footnote{Eine ausführliche Beschreibung findet sich in~\cite{watt_de}, Kap. 1.}
%%Bei den vorangegangenen Transformationen werden die Koordinaten
%%als homogene Koordinaten interpretiert. Homogene Koordinaten besitzen eine vierte Komponente $w$, die bei der Anwendung
%%der vorangegangenen Transformationen $1$ ist~(\cite{watt_de}, Kap. 1).
%%Für die perspektivische Verzerrung wird auf die Koordinaten im Kamerakoordinatensystem eine \emph{Projektionsmatrix} angewendet,
%%die als Besonderheit die $w$-Koordinate auf den Wert der $z$-Koordinate -- den Abstand von der Bildebene -- setzt.
%%Werden nun die transformierten Koordinaten durch die $w$-Komponente dividiert so ist dies effektiv die perspektivische Verzerrung.
%%Die Projektionsmatrix kann frei gewählt werden -- z.B. kann sie, durch Setzen der $w$-Koordinate auf $1$, auch orthographische
%%Projektionen darstellen.

% \subsection{Texturen}

% \newglossaryentry{Textur}{name={Textur},plural={Texturen},description={Bilddaten, bei der Fragmentverarbeitung ausgelesen. Typischerweise auf Oberfläche von Modellen "`gespannt"'}}
% Zur Simulation von detaillierten Oberflächen werden \emph{\glspl{Textur}} verwendet. Im Regelfall sind dies zweidimensionale
% Bilder. Einem jeden Dreieck eines Modells ist ein (ebenfalls dreieckiger) Ausschnitt auf einer Textur zugeordnet. 
% Die Zuordnung findet über \emph{Texturkoordinaten} statt, d.h. jedem Vertex ist ein weiteres Zahlenpaar zugeordnet,
% welches einen Punkt auf der Textur angibt.
% Beim Rendering wird nun der durch diese Koordinaten beschriebene Texturausschnitt auf die Oberfläche des Dreiecks 
% "`gespannt"': für jedes gerenderte Pixel des Dreiecks wird die Position des zugehörigen Textur-Pixels (``texel'')
% berechnet. Der Farbwert der Textur an dieser Position wird ausgelesen und dient als Farbwert des gerenderten Pixels~(\cite{watt_de}, S. 160).

% \subsection{Shading}

% \newglossaryentry{Shading}{name={Shading},description={Berechnung der Farbe eines beleuchteten Punktes auf einer 3D-Oberfläche}}
% Bei der visuellen Wahrnehmung spielt die Interaktion von wahrgenommen Oberflächen mit Lichtquellen eine wichtige
% Rolle. Aus Helligkeitsunterschieden, die aus Variationen von Abstand und Lage zu einer Lichtquelle
% herrühren, können auf Objekteigenschaften wie Drehung, Größe und Form sowie auf Oberflächeneigenschaften
% wie deren Struktur geschlossen werden.
% Bei der Computergrafik ist die Berechnung der Beleuchtung einer Oberfläche
% entsprechend wichtig. Es variiert aber nach Anwendungsfall, ob die Beleuchtung die in der Realität stattfindenden physikalischen Vorgänge
% nachbilden soll, oder aber ob diese nicht physikalisch korrekt sein, aber dafür
% eine dreidimensionale Form einfach erkennen lassen soll.

% In der bisherigen Beschreibung der Darstellung von Oberflächen wurde die Berechnung der Beleuchtung einer
% Oberfläche ausgelassen. Diese Berechnung wird \emph{\gls{Shading}} (übersetzt "`Schattierung"') genannt~(\cite{watt_de}, S. 146, 198).
%%Begr. Shading: , Schattierung: Watt (DE) 146, 198 -> Ergebnis ist "Intensität"
% Beim Shading wird eine \emph{Lichtintensität}, d.h. die Intensität des reflektierten Lichts, für Punkte auf der
% Oberfläche berechnet.

% Um das reflektierte Licht zu berechnen wird mindestens der Oberflächenpunkt im Raum sowie die Lage der Oberfläche
% -- als \emph{Oberflächenormale} an dem gegebenen Punkt -- benötigt.

%%TODO Bilder
% Es gibt verschiedene Strategien zur Berechnung von Lichtintensitäten. Die einfachste ist die Berechnung der Lichtintensität
% eines Punktes des Dreiecks und die Verwendung dieses Wertes für das komplette Dreieck. Dieser Ansatz, ``flat shading'',
% ist zwar schnell, hat aber eine sehr "`facettierte"' und kaum realistische Objektdarstellung zur Folge.
%%TODO Ref auf Methoden

% Wird die Intensität für jedes Vertex berechnet und dann über das Dreieck linear interpoliert ("`Gouraud-Shading"') so ist
% das Ergebnis bereits weniger facettiert, allerdings mit Mehraufwand für Intensitätsberechnung und Interpolation verbunden.
% Trotzdem haben Objekte bei Verwendung dieser Methode ein charakteristisches Aussehen, besonders die Kanten von Dreiecken lassen sich leicht erkennen.

% Die aufwändigste Methode ist das Berechnen der Intensität für jedes dargestellte Pixel ("`Phong Shading"'), wobei
% nur per Vertex verfügbare Werte über das Dreieck linear interpoliert werden (analog zur eigentlichen Intensität beim
% Gouraud-Shading). Der Aufwand wird aber damit belohnt, dass keine Facetten und wenig Kanten sichtbar sind.
% \footnote{Ein Vergleich der verschiedenen Interpolationsarten findet sich auch in~\cite{watt_de}, Kap. 18.}
%%@@@ Kanten sichtbar an Umriss

% \section{Aufbau Hardware}

% \subsection{Ablauf Echtzeit-Rendering}

% \begin{figure}[h]
%   \centering
%   \includegraphics{3d_pipeline}
%   \caption{Schematische Darstellung der 3D-Grafik-Pipeline}
%   \label{fig:3d_pipeline}
% \end{figure}

% Die Ausgabe der Grafik soll in der Regel als Rastergrafik auf einem Computermonitor, also auf einer zweidimensionalen Fläche, erfolgen.
% Demgegenüber besitzen 3D-Modelle per Definition Koordinaten in einem dreidimensionalen Raum, deren Komponenten potentiell
% aus der Menge der reellen Zahlen stammen. Es muss also eine \emph{Projektion} vorgenommen werden. 

% Diese Projektion wird mit den Ausgaben der Vertexverarbeitung durchgeführt. Bei der Vertexverarbeitung werden auf alle Vertices die gleichen
% Berechnungen angewendet. Diese werden in der Hardware in der Regel parallel 
% auf mehreren Recheneinheiten ausgeführt. Im Allgemeinen wird dort mit Vektoren gerechnet.
% Die Vertexverarbeitung kann mehrere Werte pro Vertex berechnen, aber minimal muss die Vertex-Koordinate in das Kamerakoordinatensystem
% abgebildet werden.
% \newglossaryentry{Vertexattribut}{name={Vertexattribut},plural={Vertexattribute},description={Weitere, jedem Vertex zugeordnete Werte}}
% In der Regel werden aber weitere Werte berechnet ("`\glspl{Vertexattribut}"'), die als Eingabe der späteren Fragmentverarbeitung dienen.

% \newglossaryentry{Shadingsprache}{name={Shadingsprache},plural={Shadingsprachen},description={Sprachen zur Programmierung von Vertex- und Fragmentverarbeitung auf GPUs}}
% Die beiden Verarbeitungsschritte der "`Vertexverarbeitung'' und "`Fragmentverarbeitung"' sind auf modernen GPUs
% \emph{programmierbar} -- die vorgenommenen Berechnungen werden also durch von einem Programmierer bereitgestellte
% Programme bestimmt. Die GPUs selbst, als Mikroprozessoren, verarbieten in einem Binärcode vorliegende Programme; dieser Code
% wird jedoch von den Programmierschnittstellen "`versteckt"' und Programme werden in einer Hochsprache gegeben\footnote{GLSL bei OpenGL, HLSL bei DirectX}.
% Die Sprachen werden "`\glspl{Shadingsprache}"' genannt.

% Auf der neuesten Generation von GPUs (GeForce 8) % etwas zu GraKa-Generationen sagen
% ist ein weiterer Verarbeitungsschritt verfügbar, die "`Geometrieverarbeitung"'\footnote{engl. geometry shader}. 
% Diese hat die Besonderheit, neue Dreiecke
% mit beliebigen Koordinaten erzeugen zu können: 
% auf eineer Grafikkarte ohne Geometrieeinheit sind alle Verarbeitungsschritte "`statisch"' bezüglich der Vertices -- nur existierende
% Werte können manipuliert werden. Gleiches gilt für Dreiecksdaten. Das \emph{Erzeugen} von Vertices kann bei diesen Grafikkarten
% also nur durch die CPU erfolgen, woraufhin die Daten zur GPU übertragen werden.
% Im Schritt der Geometrieverarbeitung kann die GPU aber selbst Vertices und Dreiecke erzeugen
% und auch entfernen. Dieser Schritt erlaubt die Implementierung von Algorithmen auf der Grafikkarte, die viel 
% Flexibilität bei der Verarbeitung von Modelldaten, speziell der Dreiecksdaten, erfordern.

% \newglossaryentry{Fragment}{name={Fragment},description={Ergebnis der Rasterung eines Dreiecks}}
% \label{rasterung}
% Nach der Vertex- bzw. Geometrieverarbeitung stehen die Koordinaten in das \emph{Kamerakoordinatensystem}\footnote{Betrachter befindet sich am
% Ursprung} transformiert zur Verfügung. Diese werden nun auf das Monitor-2D-Rasterbild mit Hilfe einer einfachen linearen Projektion
% abgebildet. Damit erhält man die Eckpunkte der Dreiecke im Koordinatensystem des Monitors mit denen die Dreiecke selbst
% gezeichnet werden. Dies geschieht durch Rasterung\footnote{siehe auch~\cite{watt_de}, Abschn. 6.4} der Dreiecke. Um die Farbe eines berechneten 
% \emph{\gls{Fragment}s}\footnote{Ein Fragment ist ein Teil eines Pixels des Rasterbildes. Ein Pixel kann aus mehreren Fragmenten bestehen wenn 
% Algorithmen zur Kantenglättung benutzt werden. Zum Verständnis reicht es jedoch aus, anzunehmen, dass ein Fragment genau einem Pixel entspricht.} zu 
% bestimmen werden eine Reihe weiterer Rechnungen vorgenommen. Die Eingaben der Fragmentverarbeitung werden
% durch perspektivisch korrekte lineare Interpolation aus den Vertexattributen der Drei\-ecks\-eck\-punk\-te  
% berechnet. Abbildung~\ref{fig:triraster} zeigt schematisch die Rasterung eines Dreiecks mit einem interpolierten Vertexattribut.

% \begin{figure}[h]
%   \centering
%   \includegraphics[scale=0.8]{triraster1}
%   \qquad
%   \includegraphics[scale=0.8]{triraster2}
%   \qquad
%   \includegraphics[scale=0.8]{triraster3}
%   \caption{Rasterung eines Dreiecks: 1. Nach Transformation in das Koordinatensystem des Monitors.
%   2. Vom Dreieck überlagerte Fragmente. 3. Ein Vertexattribut "`Grauwert"', über die Fragmente interpoliert.}
%   \label{fig:triraster}
% \end{figure}

% In den meisten Fällen wird in der Fragmentverarbeitung eine Textur ausgelesen
% und mit den Vertexattributen durch Operationen kombiniert (z.B. Multiplikation, um eine beleuchtete Oberfläche zu simulieren).
% Wie bei den Vertex-Berechnungen werden auch bei den Fragment-Berechnungen die gleichen Berechnungen auf eine Vielzahl
% von Fragmenten gleichzeitig angewendet und erfolgt parallel auf mehreren Vektorrecheneinheiten.

%%Alle Verarbeitungseinheiten sind auf aktueller Grafikhardware programmierbar.
% \section{Berechnungsfrequenzen}
% \label{berechnungsfrequenz_locker}

% Für das Rendering eines 3D-Modells werden verschiedenartige Daten benötigt. So zuerst das Modell selbst, als Dreiecksnetz. Dazu
% eine Reihe von Transformationen zur Abbildung zwischen Koordinatensystemen -- Objekt zu Welt, Welt zu Kamera und schliesslich
% eine Projektion von Koordinaten im Kameraraum auf Bildschirmpixel. Typischerweise kommen noch weitere, vom Shading verwendete Daten --
% wie eine Oberflächennormale, per Vertex definiert, und eine Textur -- hinzu.

% Zu Beobachten ist, dass diese verschiedenen Daten in ihrer "`Veränderlichkeit"' variieren:
% \begin{itemize}
% \item Die verwendeten Transformationen gelten für das ganze 3D-Modell, verändern sich also \emph{per Mesh}.
% \item Vertexdaten, wie Position im Objektkoordinatensystem oder Oberflächennormale, sind \emph{per Vertex}
% verschieden. Vor allem berechnete Vertexattribute, die bei der Fragmentverarbeitung verwendet werden, werden
% bloss per Vertex berechnet -- die eigentliche Eingabe der Fragmentverarbeitung wird aus den per-Vertex-Werten
% interpoliert.
% \item Texturdaten werden in der Fragmentverarbeitung ausgelesen, solch ausgelesene Werte ändern sich \emph{per Fragment}.
% \end{itemize}

% Aus diesen Beobachtungen leitet sich das Konzept der \emph{Berechnungsfrequenz}\footnote{Zuerst beschrieben in \cite{stanford_rtsl}.} ab.
% Die Berechnungsfrequenz eines Wertes sagt aus, wie oft dieser berechnet werden müsste bzw. in welchem Verarbeitungsschritt
% dies passiert. Je "`höher"' die Frequenz, desto häufiger muss ein Wert potentiell berechnet werden:
% \begin{itemize}
% \item Die theoretisch niedrigste Frequenz besitzen Verknüpfungen statischer Konstanten -- solche Ergebnisse müssen nur ein einziges Mal berechnet werden.
% \item Die für 3D-Grafik nächsthöhere, relevante Frequenz ist die "`Meshfrequenz"': Transformationen werden in der Regel per Mesh spezifiziert,
% eine Verknüpfung von zwei Transformationen muss nur einmal für ein Modell berechnet werden; über die gesamte Ausführungszeit einer Anwendung gesehen
% müssen solche Transformation aber praktisch öfter als ein einziges Mal berechnet werden.
% \item Als nächste Frequenz folgt die "`Vertexfrequenz"' für Werte, die von Vertexdaten abhängen. Augenscheinliches Beispiel sind
% vom Objektkoordinatensystem in das Kamerakoordinatensystem abgebildete Modellkoordinaten. Da ein Modell in der Praxis mehr als ein Vertex besitzt,
% ist ersichtlich, das Berechnungen in Vertexfrequenz öfter ausgeführt werden als solche mit Meshfrequenz.
% \item Die höchstmögliche Frequenz ist die der "`Fragmentfrequenz"' für Werte, die per Fragment berechnet werden müssen.
% Dies sind zum Beispiel aus Vertexdaten berechnete Werte, die sich nicht sinnvoll interpolieren lassen, oder Werte aus Texturen,
% deren Zweck es ja ist, mehr Details zu ermöglichen, als es Vertexdaten allein zulassen würden.
% Ein gerastertes Dreieck überspannt in der Regel mehrere Fragmente; aus diesem Grund werden per Fragment auszuführende Operationen
% öfters berechnet als per Vertex.
% \end{itemize}

% Eine höhere Berechnungsfrequenz korrespondiert prinzipiell mit einer weiter hinten liegenden Verarbeitungsstufe in der Renderingpipeline.
% Statische und Meshfrequenz sind praktisch sogar noch vor der Verarbeitung auf der GPU angesiedelt. Berechnungen in Vertexfrequenz (oder "`per Vertex"')
% entsprechen Berechnungen auf der Vertexeinheit, analog werden Berechnungen in Fragmentfrequenz (oder "`per Fragment) auf der Fragmenteinheit ausgeführt.

% Abbildung~\ref{fig:simple_cg} zeigt ein Programm-Paar für eine einfache Shadingberechnung in Cg. Die verschiedenen auftretenden Berechnungsfrequenzen
% sind dabei farbig markiert. 

% Die Nützlichkeit von Berechnungsfrequenzen besteht in der Verwendbarkeit als Werkzeug zur Optimierung des Renderings von 3D-Modellen.
% Bei der Echtzeitgrafik ist ein grundsätzliches Bestreben, zum Zwecke schnellerem Renderings Operationen so selten wie möglich auszuführen.
% Wird eine Operation, für die eine Berechnung per Vertex ausreichend wäre, auf der Fragmenteinheit ausgeführt, so bedeutet dies
% eine Verschwendung von Rechenleistung. Bestimmt man nun für eine Beschreibung, wie ein Modell in den verschiedenen Renderingschritten zu
% verarbeiten ist, die Frequenz jeder Operation, mit der diese ausgeführt werden muss, so können die Operationen optimal auf die
% Verarbeitungseinheiten verteilt werden, ohne dass Rechenleistung verschwendet wird.

% Programme in der hier beschriebenen Shadingsprache sind genau solche Beschreibungen der Verarbeitungsschritte; der implementierte Compiler
% bestimmt für jede Operation eines Programms die nötige Berechnungsfrequenz und spaltet das Eingabeprogramm entsprechend auf.

% \begin{figure}[hp]
%   \input{simple_cg}
%   \caption{Ein Programm-Paar in Cg.}
%   \centering
%   \small Operationen und Werte sind von der Berechnungsfrequenz abhängig markiert (\freqPerMesh{Mesh}, \freqPerVert{Vertex}, \freqPerFrag{Fragment})
%   \label{fig:simple_cg}
% \end{figure}

% \section{Zusammenfassung}

% Bei der Echtzeit-3D-Grafik werden von der Grafikhardware als Dreiecksnetze vorliegende 3D-Modelle dargestellt.
% Diese Modelle bestehen aus \emph{``Vertices''}, die die Eckpunkte von Dreiecken bilden. Bei der Darstellung eines
% Modelles wird zuerst die \emph{Vertexverarbeitung} vorgenommen; dabei werden die Raumkoordinaten der Vertices transformiert
% und weitere Berechnungen auf den Vertices zugeordneten Daten vorgenommen ("`Vertexattribute"').
% Als nächsten Schritt der Darstellung werden Dreiecke bei der \emph{Rasterung} auf Fragmente (im Wesentlichen Pixel) des Ausgabegerätes abgebildet.
% Bei dieser \emph{Fragmentverarbeitung} dienen als Eingaben die Ausgaben der Vertexverarbeitung, allerdings \emph{interpoliert}.
% Es werden weitere Berechnung vorgenommen, um Details hinzuzufügen, für die eine Berechnung per Vertex zu "`grob"' wäre,
% wie das "`aufziehen"' von \emph{Texturen} (Bilddaten) auf das 3D-Modell.

% Die Verarbeitungsschritte "`Vertexverarbeitung"' und "`Fragmentverarbeitung"' sind beide programmierbar, die Ausgabe des Compilers
% soll ein Programm-Paar aus Vertex- und Fragmentprogramm sein.

% Aus den Verarbeitungsschritten der Echtzeit-3D-Grafik wurde das Konzept der \emph{Berechnungsfrequenz} abgeleitet:
% diese sagt aus, auf welche Verarbeitungseinheit eine Operation eines GPU-Programms ausgeführt werden muss.
% Die Berechnungsfrequenz wird vom Compiler verwendet werden, um zu bestimmen,
% in welches Ausgabeprogramm (Vertex- oder Fragmentprogramm) eine Operation ausgegeben werden muss.

\chapter{Sprachspezifikation}
\label{langspec}

\input{langspec}

\chapter{Implementierung}
\label{implementation}

In diesem Kapitel wird auf die Implementierung des Compilers selbst eingegangen. 
Neben Scanner und Parser werden vor allem die verwendete Zwischencoderepräsentation
für die Weitergabe des Programms zwischen den verschiedenen Arbeitsschritten des Compilers 
sowie die Komponente zur Auftrennung eines Programms -- das eigentliche "`Ziel"' dieser Arbeit -- beschrieben.

\section{Compiler-Aufbau}
\begin{figure}[h]
   \centering
  \includegraphics{compiler_structure}
  \caption{Schematischer Aufbau des Compilers}
  \label{fig:structure}
\end{figure}

Der Aufbau entspricht grösstenteils der Compiler-Standardarchitektur (Abbildung~\ref{fig:structure}): das \emph{Front-End} generiert nach Syntax- und Semantikanalyse
eine Repräsentation des Programms in einem \emph{Zwischencode}.
Ein "`\emph{Middle-End}"' verarbeitet diese Zwischencoderepräsentation weiter, unter anderem werden Optimierungen vorgenommen.
Im letzten Schritt wird im \emph{Back-End} aus der optimierten Zwischencoderepräsentation der tatsächliche Zielcode generiert.

Besonderheit dieses Compilers ist der Schritt \emph{Auftrennung VP/PP} des "`Middle-Ends"'. Hier wird in der Zwischencoderepräsentation untersucht,
% mit welcher Berechnungsfrequenz~(siehe \ref{berechnungsfrequenz_locker} und
% \ref{Berechnungsfrequenz})\footnote{Für "`Meshfrequenz"' wird kein Programm generiert, sie spielt aber eine Rolle bei der Aufspaltung.
%     Generell ist das Konzept der Aufspaltung auch auf weitere Frequenzen erweiterbar.}
% jeder Befehl des Programms ausgeführt werden muss - mit anderen Worten,
% es wird untersucht, 
welche Operationen während der Vertexberechnung und welche während der Pixelberechnung ausgeführt werden müssen. Mit diesen Informationen kann
das Programm entsprechend in ein Vertex- und ein Pixelprogramm aufgeteilt werden. Da zur Laufzeit auch ein "`Übergeben"' von Ausgaben
des Vertexprogramms an Eingaben des Pixelprogramms stattfindet (die implizite Interpolation von Ausgaben der Vertexberechnung), wird auch eine "`Schnittstelle"' generiert,
die die Ausgaben der Vertexberechnungen auf Eingaben 
der Pixelberechnungen abbildet.

Die Programme werden vom Aufspalter in Zwischencode ausgegeben und noch einmal optimiert. % Irgendein besonderer Vorteil?
Abschließend werden ein Vertex- und ein Pixelprogramm im gewünschten Zielcode ausgegeben\footnote{Diese Implementierung benutzt den
gleichen Generator für beide Programme, prinzipiell könnten diese jedoch mit verschiedenen Generatoren ausgegeben werden.}.

\section{Implementierungsdetails}

Als \emph{Programmiersprache}, in der die hier beschriebene Implementierung verfasst ist, wurde C++ gewählt.
Gründe dafür sind:
\begin{itemize}
\item Die Flexibilität der Sprache und deren reichhaltige Standardbibliothek,
\item hohe Portabilität (C++-Compiler sind für praktisch jede Plattform verfügbar),
\item eine reichhaltige Palette an von Dritten hergestellter Bibliotheken,
\item die einfache Verwendbarkeit in anderen Programmiersprachen (direkt oder über eine C-kompatible Schnittstelle).%,
%\item nicht zuletzt die Gewandheit des Autors dieser Arbeit in C++.
\end{itemize}
 
Um eine Wiederverwendung des Compilers zu vereinfachen wurde dieser im Wesentlichen als eine \emph{Bibliothek} realisiert;
eine Kommandozeilenversion des Compilers setzt auch auf diese Bibliothek auf.
 
Zur Sicherstellung der fortwährend korrekten Funktionsweise aller Module des Compilers wurden entwicklungsbegleitend 
jeweils \emph{Tests} der Module geschrieben (Black-Box und White-Box); Ausführen der Tests war regelmässiger Teil des Entwicklungsprozesses.
 
\section{Scanner}

Der \emph{Scanner} wandelt die als Byte-Strom vorliegende Eingabe in eine Folge von "`Tokens"'.
Ein Token ist eine der in Abschnitt~\ref{Lexikalische Einheiten} aufgezählten lexikalischen Einheiten, ein bekanntes Symbol (Operatoren etc.) oder Schlüsselwort. 
Leerzeichen (``Whitespace'') und Kommentare werden bereits vom Scanner ignoriert (d.h. für diese werden keine Tokens produziert).

Der Scanner folgt einer typischen Implementierung wie sie z.B. in \cite{wirth_compiler} beschrieben ist. Auf einige beachtenswerte Aspekte
wird im folgenden eingegangen.

\paragraph{Eingabe.} Da die Spezifikation von Unicode als Eingabe ausgeht, arbeitet der Scanner entsprechend auf der Basis von Unicode-kodierten Zeichen.
Der Byte-Strom der Eingabe wird also in einem Schritt noch vor dem Scanner in einen "`Unicode-Strom"' umkodiert\footnote{Verwendet wird dazu die Bibliothek ICU,
\url{http://site.icu-project.org/}}.

\paragraph{Schlüsselwörter.} Erkennt der Scanner einen Bezeichner, wird auch geprüft, ob es sich um ein Schlüsselwort handelt. Ist dies der Fall
wird im Token eine dem Schlüsselwort eindeutig zugeordnete ID gespeichert.

%Die erste Ausnahme
Eine Ausnahme allerdings bilden die Schlüsselwörter für Vektor- und Matrixtypen (Abschnitte~\ref{Vektortypen}, \ref{Matrixtypen}). Diese entsprechen
jeweils dem Muster $\mathit{typ}\mathrm{N}$ bzw. $\mathit{typ}\mathrm{N}\mathit{x}\mathrm{M}$ (mit $N \in 1 \dots 4, M \in 1 \dots 4$).
Da eine eigene ID für jeden Vektor- oder Matrix insgesamt 20 weitere IDs pro Basis-Typ nach sich ziehen würde -- wobei später noch jeder ID wiederum
die ursprünglichen Werte für $N$ und $M$ nochmals zugeordnet
werden müssten -- wird im generierten Token vermerkt, ob es sich um einen Vektor- oder Matrixtyp handelt.
Dazu überprüft der Scanner, ob ein Bezeichner den angegebenen Muster für Vektor- bzw. Matrixschlüsselwörtern entspricht.
Weiterhin werden bereits $N$ bzw. $M$ aus den Bezeichnern extrahiert und ebenfalls vermerkt.

Abbildung~\ref{fig:LexerToken} stellt die vom Scanner gesammelten Daten als Strukturdefinition dar.

\begin{figure}[h]
   \centering
  \lstinputlisting[language=C++]{snips/LexerToken.txt}
  \caption{Daten eines vom Scanner ausgegebenen Tokens}
  \label{fig:LexerToken}
\end{figure}

% Die zweite Ausnahme bilden Attributnamen~(\ref{Attribute}) inklusive Swizzles~(\ref{Vektorattribute}). Diese sind teilweise recht allgemein, und
% es erscheint wünschenswert, Bezeichner zuzulassen, die Attributnamen entsprechen -- z.B. ``length'', das auch ein Arrayattribut ist, und einbuchstabige
% Bezeichner wie ``x'', ``y'' etc., welche auch Vektorattribute (Swizzles) sind. Syntaktisch gibt es keine Mehrdeutigkeiten zwischen Attributen und
% anderen Bezeichnern -- ein Attribut kann \emph{nur} rechts eines \op{.} auftauchen, ein anderer Bezeichner dort nie.


Weiterhin schreibt die Spezifikation vor, dass zwei Bezeicher als identisch betrachtet werden, wenn sie kanonisch äquivalent im Sinne von Unicode sind.
Der Scanner speichert zu diesem Zweck alle Bezeichner in einer normalisierten Form. Diese ist vom Unicode-Standard vorgegeben:~\cite{unicode}, Annex \#15.

\section{Parser}

Der \emph{Parser} untersucht den vom Scanner gelieferten Strom von Tokens auf syntaktische Strukturen.
Es wird überprüft, ob der Token-Strom gültig im Sinne der in der Sprachspezifikation gegebenen Sprache ist --
sonst liegt ein \emph{Syntaxfehler} vor.

Während der Überprüfung werden auch syntaktische Elemente -- grundsätzlich Terminale wie Bezeichner oder numerische Werte -- extrahiert.
Diese werden bei der \emph{semantischen} Verarbeitung benötigt.

%- Lookahead: unendl.
%- Grammatik: kontextfrei, rechtsrekursiv

%\subsection{Eigenschaften der Grammatik}

%Die Grammatik ist kontextfrei. Die Regeln sind rechtsrekursiv.

\subsection{Aufbau des Parsers}

\newcommand\rulelink[1]{\glq\texttt{\detokenize{#1}}\grq~(\ref{#1})}

Der Parser ist nach der Methode des rekursiven Abstiegs (beschrieben in \cite{wirth_compiler}) handprogrammiert.
Der Aufbau spiegelt im Wesentlichen die Struktur der Regeln wieder -- viele haben ein direktes Gegenstück in einer Methode des Parsers.

\paragraph{Umgang mit Mehrdeutigkeiten:}
An einigen Stellen der Grammatik gibt es Mehrdeutigkeiten.
Werden beim Parsen eines \rulelink{programm_statements} die Tokens \glq\texttt{typ BEZEICHNER}\grq~(\ref{typ}, \ref{BEZEICHNER})  erkannt,
so kann es sich entweder um die Regel \rulelink{funktion_definition} oder um \rulelink{dekl_var} handeln.
Andere Fälle von Mehrdeutigkeiten sind \rulelink{dekl_var} oder \rulelink{kommando} in \rulelink{block} und
\rulelink{funktion_aufruf} oder \rulelink{BEZEICHNER} in \rulelink{asdr_basis}.

Solche Mehrdeutigkeiten lassen sich entweder in der Implementierung des Parsers oder durch Abändern der Grammatik lösen.

Bei der Parser-Lösung werden einfach weitere Tokens betrachtet. Im Falle eines  \rulelink{programm_statements}
wird auch das nächste Token nach \glq\texttt{typ}\grq{} und \glq\texttt{BEZEICHNER}\grq{} überprüft:
handelt es sich um \glq\texttt{(}\grq, ist die anzuwendende Regel \rulelink{funktion_definition};
handelt es sich um \glq\texttt{=}\grq, \glq\texttt{,}\grq{} oder \glq\texttt{;}\grq{} ist die anzuwendende Regel \rulelink{dekl_var};
andere Tokens sind ein Syntaxfehler. Eine Pseudo-Code-Version der Implementierung ist in Abbildung~\ref{fig:ParseProgramStatements}
aufgelistet.

In den Implementierungen der Regeln \rulelink{block} und \rulelink{asdr_basis} wurde analog verfahren.

Bei der Lösung von Mehrdeutigkeiten durch Abändern der Grammatik muss eine Regel erstellt werden,
die mit der mehrdeutigen Token-Sequenz beginnt. Dahinter werden als Alternativen neue Regeln angefügt,
die aus den "`Resttokens"' der ursprünglich mehrdeutigen Regeln bestehen müssen. % Hier ne Ref wäre vllt gut

Allerdings würde damit die Lesbarkeit der Grammatik eingeschränkt. Für die Regel \rulelink{ausdruck} wurde bei der Implementierung dieser Ansatz verfolgt,
die Spezifikation der Grammatik in Kapitel~\ref{langspec} dahingehend aber \emph{nicht} geändert.
Stattdessen sind die in der Implementierung des Parser verwendeten "`Variationen"' der Grammatik in Anhang~\ref{grammar_fixes} beschrieben.

Für die anderen Regeln wurde das "`Vorausschauen"' von Tokens gewählt, da es in diesen Fällen einfach zu implementieren war
und die Grammatik besser lesbar bleibt.

\begin{figure}[!h]
   \centering
  \lstinputlisting[language=Java]{snips/ParseProgramStatements_pseudo.txt}
  \caption{Beispiel einer Parsing-Methode mit Auflösung von Mehrdeutigkeiten}
  \label{fig:ParseProgramStatements}
\end{figure}

\paragraph{Semantische Verarbeitung:}
% Die semantische Verarbeitung wird an ein Interface vom Typ \verb+SemanticHandler+ übergeben.
% Dieses Interface übernimmt die verschiedenen Aspekte der semantischen Verarbeitung, von der Verwaltung der
% Symboltabelle bis zu einer geeigneten internen Repräsentation von Ausdrücken.
Die semantische Verarbeitung wird von einer weiteren Komponente -- hier ``semantic handler'' genannt -- vorgenommen. 
Dieses Komponente übernimmt die verschiedenen Aspekte der semantischen Verarbeitung, von der Verwaltung der
Symboltabelle bis zu einer geeigneten internen Repräsentation von Ausdrücken. Die in der Komponente gespeicherten Informationen sind
in einem Rückkanal dem Parser zugänglich; so werden diese zum Beispiel benutzt um festzustellen, ob ein Bezeichner ein
Typ-Alias oder eine Funktion identifiziert.
Die Ausgabe des ``semantic handlers'' ist eine Zwischencoderepräsentation des Programms.

% \verb+SemanticHandler+ besitzt Methoden, um syntaktische Elemente -- wie Bezeichner und numerische Literale -- in Objekte 
% einzukapseln. Diese Objekte wiederum werden bei der Verarbeitung anderer syntaktischer Elemente
% zurück an das Interface übergeben. % Wenn Code-Schnipsel dann hier verweisen

% Beispiel: Bei einem Ausdruck \verb+a * 2+ werden von \verb+SemanticHandler+ zunächst Repräsentationen für
% \verb+a+ und \verb+2+ erfragt. Zurückgegeben werden Repräsentationen von "`Ausdrücken"'. Diese wiederum
% dienen als Argumente, um eine Repräsentation einer Multiplikation zu erhalten. Diese letzte Repräsentation kann
% dann überall dort verwendet werden, wo Ausdrücke erwartet werden: Zuweisungen, Funktionsparameter etc.

% Vom der \verb+SemanticHandler+-Implementierung zum Parser gibt es auch einen "`Rückkanal"'. Dies ist nötig, da bei einigen
% Konstrukten bekannt sein muss, ob ein Bezeichner eine Variable, eine Funktion oder einen Typ identifiziert:
% Das Ausdruck \verb+foo (1)+ ist, je nachdem ob \verb+foo+ eine Funktion, ein Typ-Alias oder eine Variable bezeichnet,
% entsprechend ein ein Funktionsaufruf, der Aufruf eines Typ-Konstruktors, oder ein ungültiger Ausdruck.

Verglichen mit dem "`klassischen"' Ansatz der semantischen Verarbeitung -- Parser erzeugt Abstract Syntax Tree (AST) als ersten Schritt,
semantische Analyse erzeugt Zwischencoderepräsentation im zweiten Schritt -- finden sich kleine Teile der semantischen
Analyse im Parser; die Erstellung eines ASTs wird übergangen, der ``semantic handler'' nimmt mit den vom
Parser übergebenen Informationen die restliche semantische Analyse vor und erzeugt sofort eine Zwischencoderepräsentation (beschrieben in Abschnitt~\ref{zcr}).

Die Erstellung eines AST wurde übergangen, da diese als unnötig angesehen wurde: eine direkte Ausgabe der Zwischencoderepräsentation
wurde als einfacher umzusetzen und für die weiteren Arbeitsschritte im Compiler als ausreichend angesehen. 
Insbesondere Optimierungen sind in der gewählten Zwischencoderepräsentation (ZCR) einfacher vorzunehmen als auf
einem AST. Auch werden in der ZCR wichtige semantische Informationen, wie Typen von Werten, Funktionssignaturen etc. gespeichert,
es tritt also kein Informationsverlust im Vergleich zu einem AST auf.

Weiterhin wurde die Implementierung so gestaltet, dass die Komponent des ``semantic handler'' relativ einfach austauschbar ist:
aus "`Parser-Sicht"' ist die interne Arbeitsweise und Art der Ausgabe des ``semantic handler'' irrelevant.
Sollte also notwendig werden, dass der Compiler einen AST des Programms erstellen soll, so wäre es prinzipiell möglich,
einen ``semantic handler'' zu schreiben der genau dies tut.

% Die Idee hinter dem \verb+SemanticHandler+ ist eine möglichst vollständige Trennung zwischen syntaktischer
% und semantischer Verarbeitung. Eine minimale Implementierung könnte intern eine
% AST-Repräsentation generieren (allerdings benötigt der Parser trotzdem auch einige semantische Informationen über
% Bezeichner).

% \begin{figure}[h]
%    \centering
%   \lstinputlisting[language=Java]{snips/ParseIf_pseudo.txt}
%   \caption{Zusammenspiel Parser und \texttt{SemanticHandler}: Parsen einer Verzweigung}
%   \label{fig:ParseIf}
% \end{figure}

\paragraph{Fehlerbehandlung:}
In der Implementierung wird die Fehlerbehandlung bei der syntaktischen wie auch semantischen Verarbeitung über \emph{Ausnahmen}
realisiert. Die Parser-Komponente selbst fängt dabei Ausnahmen ab, um zu gewährleisten, dass möglichst viel eines
Programms verarbeitet wird, um möglichst viele potentielle Fehler aufzudecken (wie in \cite{wirth_compiler} empfohlen):
tritt z.B. eine Ausnahme während der Verarbeitung eines Block-Kommandos auf, setzt der Parser die
Verarbeitung nach dem nächsten Semikolon -- also mit dem nächsten Kommando -- fort (sofern kein Ende
des Blockes festgestellt wird).
Die abgefangenen Ausnahmen werden jedoch nicht verworfen, sondern an ein Objekt zur Fehlerbehandlung
übergeben um eine Nachricht für den Benutzer darzustellen.

% \paragraph{Implementierung \texttt{SemanticHandler}:}
% In der vorgenommen Implementierung von \verb+SemanticHandler+ wird gleich eine Umsetzung in die Zwischencoderepräsentation vorgenommen
% (Beschreibung siehe Unten). Die Generierung eines ASTs als Zwischenschritt wurde als unnötig angesehen.
% Die Zwischencoderepräsentation erhält auch wichtige semantische Eigenschaften (wie Typinformationen) und
% die Verarbeitungsschritte "`Auftrennung"' und "`Optimierung"' lassen sich auf der Zwischencoderepräsentation besser vornehmen.

% Zuordnung Variable <-> akt. Register in Symboltabelle

\newpage
\section{Zwischencoderepräsentation}
\label{zcr}

\input{ir_commands}

% Abstrakte(s) Beispiel(e): Quellcode + resultierende Zw.rep.

\subsection{Vorlagen der Zwischencoderepräsentation}

Als Vorlagen für die hier vorgestellte Zwischencoderepräsentation dienten das ``LLVM Instruction Set'',
SafeTSA und ``SIMPLE'' des McCAT Compiler-Projektes.

% "Inspirationen": LLVM, Amme's SSA, GIMPLE/SIMPLE

%Das \emph{LLVM Instruction Set} (hier kurz ``LLVM'') 
\paragraph{LLVM}~\cite{LLVM:CGO04}: LLVM ist ein \emph{Framework} für Compiler. Insbesondere will es ermöglichen, Optimierungen
eines Programms über dessen ganzen "`Lebenszyklus"' (inklusive Link- und Laufzeit) zu ermöglichen.

Das \emph{LLVM Instruction Set} ist der ausgegebene "`Objektcode"'. Das Programm wird -- ähnlich Maschinen-
oder Bytecode -- als eine Folge von einfachen Instruktionen auf Registern repräsentiert. 
Allerdings gibt es eine unbeschränkte Anzahl von typisierten Registern. Typumwandlungen sind immer explizit.
Die Instruktionen sind in SSA-Form.

% LLVM:
% - nicht gedacht als allg. Compiler-IR
% - keine Typsicherheit (nicht mehr als Maschinencode)
% - 
% - LLVM provides an inﬁnite set of typed virtual
% registers which can hold values of primitive types (Boolean,
% integer, ﬂoating point, and pointer). The virtual registers
% are in Static Single Assignment (SSA) form [15]. LLVM
% is a load/store architecture: programs transfer values be-
% tween registers and memory solely via load and store op-
% erations using typed pointers. The LLVM memory model is
% described in Section 2.3.
% - Opcodes: 3-Adress-Form
% - Ich->Mehr Opcodes als LLVM (unäre Op., Vektor-Op.)
% - Expliziter Kontrollflussgraph
% - abgeleitete Typen: Zeiger, Arrays, Structs, Funktionen
% - Typumwandlungen: explizit

% expliziter Kontrollfluss == keine GOTOs, sondern "Verweise" auf Blöcke/nächsten Schritt

\paragraph{SafeTSA}~\cite{SafeTSA}: Eine Art Objektcode, hauptsächlich zur Benutzung
als "`mobiler"' Code, d.h. zur Übertragung von Programmcode über Netzwerke wie das Internet.
Das Design von SafeTSA ist inhärent sicher. Bösartige Manipulationen von Programmen, die zu
problematischem Verhalten wie die Benutzung von undefinierten Werten oder Aliasing von Werten
eines anderen Typs führen, sind nicht möglich bzw. durch eine einfache Verifizierung feststellbar.

Die Instruktionen basieren auf der SSA-Form. Entsprechend gibt es eine beliebige Zahl von Registern.
Register sind in mehrere Sätze organisiert, ein Satz pro Typ. Instruktionen können nur auf einen
spezifischen Registersatz zugreifen. Verschiedene Instruktionsblöcke besitzen eigene Registersätze.

% SafeTSA:
% - erweiterte SSA
% - Zugriff auf Werte über Abstand in Dominatorbaum
% - Typtrennung: mehrere Registersätze; implizite Auswahl des Registersatzes
% - typisierter Konstantenpool
% - Registersätze per Basisblock
% - 

\paragraph{SIMPLE}~\cite{SIMPLE}: Als "`echte"' Compiler-Zwischencoderepräsentation für einen C-Compiler entwickelt
stellt sie Programme auf sehr hoher Ebene dar. Ausdrücke sind nicht in der SSA-Form, allerdings
"`vereinfacht"' auf zwei Operanden und einfache Strukturzugriffe. Symboltabelle und Typinformationen
sind erhalten. Typumwandlung, und andere in C implizite Verhalten, müssen explizit ausgedrückt werden.

% SIMPLE:
% - expliziter Kontrollfluss/zusammengesetzte Flusskontrollstatements
% - Typinformationen
% - klare Semantik (keine impliziten Verhalten wie autom. casts)
% - einfache Referenzen
% - einfache Statements

\paragraph{Zusammenfassung:}
Die gewählte Zwischencoderepräsentation ist größtenteils ein "`Querschnitt"' aus den obigen Repräsentationen
%(allerdings auch mit Aspekten aus keiner Vorlage, wie die Behandlung von Arrays).
(allerdings auch mit eigenständig entwickelten Aspekten, wie die Behandlung von Arrays).
Die meisten Eigenschaften
teilt die Zwischencoderepräsentation mit dem LLVM Instruction Set; chronologisch wurde dieses jedoch als letzte
Repräsentation betrachtet. Aus SafeTSA und SIMPLE stammen deshalb grundsätzliche Aspekte der Zwischencoderepräsentation 
-- einfache Statements, SSA-Form, separate Registersätze.

Anzumerken ist, dass die Shadingsprache keine zufälligen Speicherzugriffe oder Zeiger/Referenzen erlaubt.
Im Umfang ist sie teilweise beschränkt -- es gibt keine Strukturtypen --, besitzt aber als "`Eigenheit"' Vektortypen.
LLVM, SafeTSA und SIMPLE wurden für "`Maschinen"' entwickelt, die die Verwendung von Zeigern erlauben. Entsprechend
stellen sie Lösungen für Probleme, wie die Aliasing\footnote{Zugriff auf ein Datum über mehrere verschiedene Zeiger}-Analyse
oder typsichere Speicherzugriffe, bereit, die mit der hier spezifizierten Shadingsprache nicht vorkommen. Die genannten Repräsentationen sind hier nicht
mit ihren vollständigen Fähigkeiten in Hinsicht auf diese Aspekte beschrieben.

\subsection{Aufbau}

Bei der Gestaltung der \emph{Zwischencoderepräsentation} sollten folgende Rahmenbedingungen erfüllt werden:
\begin{itemize}
\item \emph{Eignung als Zwischenrepräsentation zwischen verschiedenen Arbeitsschritten des Compilers}.
Um die Komplexität des Compilers und den damit verbundenen Implementierungsaufwand klein zu halten
sollte \emph{ein} Format zur Zwischenrepräsentation für den compilerinternen Austausch verwendet werden.
(Andere Compiler verwenden verschiedene Formate zwischen Verarbeitungsschritten, siehe z.B.~\cite{SIMPLE}.)
\item Dies schliesst auch \emph{Eignung für Auftrennung} und \emph{Eignung für Optimierungen} ein.\\
Die Auftrennung sollte mit möglichst feiner "`Granularität"' passieren - bei komplexen Ausdrücken soll es möglich sein,
dass verschiedene Teilausdrücke in verschiedene Teilprogramme ausgegeben werden können.\\
Es sollten auch genug Information enthalten sein, um verschiedene Optimierungsalgorithmen umzusetzen.
Idealerweise sollte die Zwischencoderepräsentation sowohl die Umsetzung der Aufspaltung als auch 
der Optimierungen möglichst unterstützen und vereinfachen.
% \item Eignung als Ausgabe für Auftrenner?
\item Dafür sollte der \emph{Aufbau} möglichst \emph{einfach} sein, damit Programme in der Zwischencoderepräsentation 
unkompliziert traversiert und manipuliert werden können.
\end{itemize}

Die Optimierbarkeit wird unterstützt, in dem der Zwischencoderepräsentation die \emph{``Single Static Assignment''-Form} (SSA, siehe~\cite{ssa1} und \cite{ssa2})
für Ausdrücke zugrunde liegt. Der gewünschte einfache Aufbau äußert sich darin, dass Befehle eines Programmes
in einer einfachen Reihung gespeichert werden -- ohne Sprungmarken oder ähnliches. Verzweigungen und Schleifen werden
durch "`komplexe"' Befehle realisiert (die intern wiederum Reihungen von Befehlen enthalten).

Eine Auftrennung auf der Ebene der Befehle der Zwischencoderepräsentation ermöglicht es, bei komplexen Ausdrücke u.ä.
für einzelne Rechenschritte zu entscheiden, in welches Teilprogramm die Ausgabe erfolgen soll.
Damit wurde die gewünschte "`Granularität"' -- Aufteilung von Teilausdrücken -- erreicht.

Das "`Grundelement"' der Zwischencoderepräsentation ist eine "`Sequenz"'. Eine Sequenz besteht aus "`Operationen"',
die auf "`Registern"' arbeiten. Register sind \emph{typisiert}, es gibt getrennte Registersätze, ein Satz für jeden verwendeten Typ. 
Der Aufbau einer Sequenz ist in Abbildung~\ref{fig:ir_sequence} schematisch dargestellt.

Die in Operationen gespeicherte Registeridentifikation verweist auf den zugehörigen Registersatz, Typinformationen bleiben also erhalten.
Verwendet werden diese Informationen bei der Aufspaltung\footnote{Die "`Aufteilbarkeit"' einer Operation hängt teilweise von den Datentypen der Operanden ab,
siehe~\ref{Interpolierbarkeit}},
Optimierung\footnote{Speziell bei der Konstantenfaltung.} und
Codegenerierung\footnote{Insbesondere da die gewählte Zielsprache -- Cg -- selbst eine Hochsprache ist.},
und ein Abspeichern der Registertypen "`entlastet"' diese Komponenten von der Bestimmung des Typs eines Registerinhalts.
% Satz teil von Register-ID
%Jedes Register besitzt ausserdem einen Namen; dieser wird aber nur verwendet, um generierten Code lesbarer zu machen.

\begin{figure}[h]
   \centering
  \includegraphics{ir_sequence}
  \caption{Teile einer Sequenz}
  \label{fig:ir_sequence}
\end{figure}

Der wesentliche, von der SSA-Form entliehene, Aspekt ist, dass ein Register nur von \emph{einer} Operation der Sequenz beschrieben werden darf
(im Weiteren "`Register-Zuweisungs-Bedingung"' genannt).

Im Gegensatz zu einer "`reinen"' SSA-Form gibt es jedoch keine $\phi$-Operation. Stattdessen werden $\phi$-Operation bereits "`aufgelöst"'
gespeichert: soll z.B. bei einer Verzweigung eine Variable in einem Zweig verändert werden, so werden in beiden Zweigen Zuweisungen zum
entsprechenden Register generiert. Ein Zweig enthält die Zuweisung des neuen Wertes, der andere die Zuweisung des alten Wertes.

Gewählt wurde dieser Ansatz, um Transformationen von Programmen, insbesondere das Entfernen einzelner Operationen, zu vereinfachen:
Das spätere "`Aufspalten"' eines Programms ist praktisch eine Erzeugung von mehreren Ausgabeprogrammen aus einem Eingabeprogramm,
wobei Operationen des Eingabeprogramms teils kopiert, teils ausgelassen werden. Durch ein Auflösen der $\phi$-Operationen können
komplexe Operationen (Sequenzschachtelungen, Verzweigungen, Schleifen)
%durch eine einfache Kopie der Operation in mehrere Programme vervielfältigt werden, ohne dass später folgende Operationen betrachtet werden müssten -- 
trivial aus einem Ausgabeprogramm ausgelassen werden, ohne dass später folgende Operationen betrachtet werden müssten -- 
bei expliziten $\phi$-Operationen müsste zumindest für diese noch überprüft
werden, ob sie noch gültig sind (d.h. die Verzweigung o.ä., auf die sich eine $\phi$-Operation bezieht, existiert noch im Ausgabeprogramm).

%Anzumerken ist, dass dieses Auflösen nicht die oben gegebenen "`Register-Zuweisungs-Bedingung"' verletzt, da Verzweigungen und Schleifen
%jeweils als \emph{eine} Operation in der Sequenz, in der sie verwendet werden, gelten.
Anzumerken ist, dass Sequenzschachtelungen, Verzweigungen und Schleifen in der Sequenz als \emph{eine} Operation gespeichert
werden (welche auf die inneren Sequenzen selbst nur Verweisen). Damit verletzt dieses Auflösen nicht die oben gegebenen "`Register-Zuweisungs-Bedingung"'.
(Bei Verzweigungen wird einem Register, auch wenn ihm in beiden Zweigsequenzen ein Wert zugewiesen wird, zur Laufzeit nur einmal
ein Wert zugewiesen, da nur eine Zweigsequenz ausgeführt wird.
Wertzuweisungen in Schleifenblöcken kann man als Zuweisungen an "`temporäre"' Register betrachten, wobei die Zuweisung an
das tatsächliche Zielregister erst einmalig nach dem letzten Schleifendurchlauf stattfindet.)

Die Sichtbarkeit von Registern ist auf die Sequenz, in der sie deklariert wurden, beschränkt.
%Insbesondere können auf diese nicht implizit
%aus verschachtelten Blöcke (wie sie auch bei Bedingungen oder Schleifen vorkommen) zugegriffen werden. 
Insbesondere gibt es Sequenzoperationen, die andere Sequenzen einschachteln (Verzweigungen, Schleifen, Sequenzschachtelung).
Aus solch eingeschachtelten Blöcken kann \emph{nicht} implizit auf die Register aus dem umgebenden Block
zugegriffen werden.

Stattdessen werden zu eingeschachtelten Blöcken eine Zuordnung zwischen Registern aus dem umgebenden Block
("`extern"') und
Registern des eingeschachtelten Blockes ("`lokal"') gespeichert.
Wie genau die Abbildung von Werten von "`externen"' an "`lokale"' Register stattfindet ist ein Implementierungsdetail, dass dem Generator obliegt;
das Verhalten muss einem "`umleiten"' von Lese- oder Schreibzugriffen von den angegebenen lokalen auf die zugeordneten externen
Registern entsprechen.

Damit wird sichergestellt, dass für eine Sequenz alle Informationen zu von den Operationen verwendeten Registern vorhanden sind.
Verarbeitungsschritte, die die Verwendung oder Inhalte von Registern betrachten können, wegen garantierter "`lokaler"' Definition
von Registern, Gültigkeitsbereiche u.ä. ignorieren; Sequenzen können unabhängig voneinander betrachtet und bearbeitet werden,
da ein Verwalten von "`umgebenden"' Sequenzen, um möglicherweise Informationen von dort verwendeten Registern zu erhalten,
nicht nötig ist.

%Wie genau die Übergabe von Werten von "`externen"' an "`lokale"' Register statfindet ist ein Implementierungsdetail, dass dem Generator obliegt;
%das Verhalten muss jedoch semantisch äquivalent zu einem Kopieren der externen Eingaberegister in lokale Register Anfang des Blockes
%und analog am Ende zu einem zurückkopieren von lokalen Registern in die externen Ausgaberegister sein.

Abbildung~\ref{fig:ir_seq_block_nest} zeigt eine Sequenz, in der die zweite Operation eine Sequenzschachtelung ist.
Der Sequenzoperation sind neben einem Verweis auf die auszuführende Sequenz auch Registerzuordnungen von
Registern der äusseren (einschachtelnden) zu Registern der inneren (eingeschachtelten) Sequenz.

\begin{figure}[h]
   \centering
  \includegraphics{ir_seq_block_nest}
  \caption{Schema einer Sequenzschachtelung}
  \label{fig:ir_seq_block_nest}
\end{figure}

\paragraph{Funktionen:}
Eine Funktion der Zwischencoderepräsentation besteht aus einem eindeutigem Bezeichner, einer Liste von Eingabeparametern,
einer Liste von Ausgabeparametern und einer Sequenz mit den eigentlichen Funktionsoperationen.
Ein eventueller Rückgabewert ist nur ein weiterer Ausgabeparameter.
Abbildung~\ref{fig:ir_function} ist eine schematische Abbildung einer Funktion.

%Jede Überladung einer Funktion wird in der Zwischencoderepräsentation durch einen eindeutigen Bezeichner identifiziert.
%Dieser wird aus dem ursprünglichen Bezeichner sowie einer aus den Parametertypen generierten "`Signatur"' konstruiert.
Bei überladenen Funktionen muss die auszuführende Variante der Funktion in der Zwischencoderepräsentation
explizit angegeben werden.
Aus diesem Grund wird in der Zwischencoderepräsentation jede Überladung einer Funktion durch einen eindeutigen Bezeichner identifiziert.

Parameter werden mit einem Mechanismus, der der Behandlung "`externer"' Register in einem eingeschachteltem
Block ähnelt, übergeben. Die Parameterlisten enthalten zu jedem Eingabeparameter ein lokales Register, in dem die
Sequenz den Wert des Parameters "`erwartet"'. Analog wird jedem Ausgabeparameter ein Register zugeordnet,
in dem bei Verlassen der Funktion der zurückzugebende Wert liegt.
(Die genaue Umsetzung dieses Verhaltens ist ein Implementierungsdetail, dass dem Generator obliegt.)

Ein Parameter, der gleichzeitig Ein- wie auch Ausgabeparameter ist, wird "`verdoppelt"', d.h. es wird daraus
ein nur-Eingabe- sowie auch ein nur-Ausgabe-Parameter generiert. Bei Funktionsaufrufen werden den beiden
Parametern auch entsprechend verschiedene Register zugeordnet.

\begin{figure}[h]
   \centering
  \includegraphics{ir_function}
  \caption{Schema einer Funktionsbeschreibung}
  {\small für eine Funktion deklariert mit \texttt{float lerp (float a, float b, float factor)}.}
  \label{fig:ir_function}
\end{figure}

\paragraph{Globale Variablen:}
Echte globale Variablen sind nicht vorgesehen. Sie werden nachgebildet, in dem in einer Funktion gelesene globale Variablen
auf spezielle, "`versteckte"' Eingabeparameter abgebildet werden. Geschriebene globale Variablen werden
auf spezielle Ausgabeparameter abgebildet. Nur in der Eintrittsfunktion werden globalen Variablen tatsächlich
"`eigene"' Register zugewiesen. Im Prinzip sind "`globale"' Variablen "`versteckte"' lokale Variablen in
der Eintrittsfunktion.

Damit müssen globale Variablen von Optimierungsschritten u.ä. nicht besonders berücksichtigt werden.
Insbesondere müssen keine "`Seiteneffekte"' von Funktionen ermittelt werden: manipuliert eine Funktion eine "`globale"' Variable,
so erhält sie in der Zwischencoderepräsentation einen weiteren Ausgabeparameter.
Betrachtet man den Aufruf dieser Funktion so wird nur eine weitere Variable beschrieben.

Optimierungsschritte wie Konstantenfaltung oder die Entfernung unnötiger Operationen, aber auch der Auftrennungs-Schritt werden vereinfacht,
da nur "`lokale"' Variablen berücksichtigt werden müssen; gleichzeitig werden als global deklarierte Variablen
von solchen Verarbeitungsschritten korrekt behandelt.

%Stattdessen werden zu eingeschachtelten Blöcken gespeichert, welche Register von dem Block gelesen oder
%beschrieben werden sollen

%Soll ein Register in einem eingeschachteltem Block gelesen oder beschrieben werden, 

\paragraph{Behandlung von Arrays:}
Arrays werden als "`ein"' Wert behandelt -- eine Zuweisungsoperation kopiert immer ein ganzes Array.
Das Lesen einzelner Elemente geschieht mit Hilfe der Operation "`Extraktion eines Arrayelements"' ($\mathtt{getelem}$).

Zum Schreiben eines Elements gibt es die Operation "`Änderung eines Arrayelements"' ($\mathtt{setelem}$):
%diese kopiert alle Elemente eines Arrays in das Zielarray \emph{außer} das Element eines gegebenen Indexes;
%im Zielarray wird dort der zu schreibende Wert abgelegt.
diese kopiert alle Elemente, bis auf das zu ändernde Element, eines Arrays in das Zielarray;
dort wird am gegebenen Index der zu schreibende Wert abgelegt.
Dieser Ansatz wurde gewählt, weil er sehr gut in das "`SSA-Prinzip"' passt.
Bei der direkten Umsetzung eines Zugriffs auf Array-Elemente (Ausdrücke wie eine Zuweisung "`$a[i] = x$"') ist es schwierig, sicherzustellen, dass
jedes Element von $a$ wie verlangt nur einmal beschrieben wird (insbesondere bei Schleifen); es
müsste für jedes Array-Element individuell "`verfolgt"' werden, ob es beschrieben wurde.
Ein solches Verfolgen wird weiterhin schwieriger, sobald die Array-Größe nicht bekannt ist
-- die spezifizierte Sprache sieht dies vor. Das betrachten eines Arrays als "`einen"' Wert macht es hingegen einfach,
die Bedingung "`nur eine Zuweisung"' einzuhalten und zu überprüfen.
% Andere Alternativen? Wie in LLVM, SafeTSA? Wer hat sich noch über Arrays Gedanken gemacht?

Für manche Optimierungen ist es trotzdem von Vorteil, die einzelnen Elemente eines Arrays zu verfolgen -- sind diese
z.B. Konstanten können die Werte an einer Konstantenfaltung teilnehmen. Solche Möglichkeiten der Optimierungen
bleiben bestehen: sind Größe und Elementwerte eines Arrays bekannt, kann ein Optimierer diese wie individuelle
Register durch die Arrayoperationen hindurch verfolgen, oder sogar ein Array auf individuelle Register "`aufteilen"'.

\subsection{Sequenz-Operationen}

Dieser Abschnitt zählt alle möglichen Operationen in einer Sequenz auf. Eine Operation greift für die Eingabe auf kein, ein oder mehrere
\emph{Quellregister} zu. Hat die Operation ein Ergebnis, wird dieses in ein \emph{Zielregister} geschrieben. 

Für jede Operation wird ein einfaches Beispielprogramm gegeben; diesem wird der generierte Zwischencode gegenüber gestellt.

%Unter vielen Operationen ist das Verhalten in Pseudo-Code angegeben. Dabei steht $d$ für das Zielregister einer Operation.
%Die Quellregister werden durch $s$, $t$, \dots bezeichnet. 

%\newpage
\subsubsection{Einfache Operationen}

Bei den Textdarstellungen der einfachen Operationen ist das erste Argument das Zielregister der Operation, alle nachfolgenden
Argumente sind die Eingaberegister.

\newcommand\SeqOpSample[2]{
  %\begin{figure}[!h]
  \renewcommand{\baselinestretch}{1.0}\normalsize
  \emph{Beispiel und Zwischencode:}\\
  \makebox[\textwidth]{
    \centering
    \begin{minipage}{7cm}\lstinputlisting{s1source/#1.s1}\end{minipage}
    \hspace{-2cm}\begin{minipage}{8cm}\include{s1latex/#1}\end{minipage}
    %\caption{#2.}
    \label{fig:ir_example_#1}
  %\end{figure}
  }
  \defltbaselinestretch\normalsize
}
\newcommand\SeqOpSampleStackedSeparate[3]{
  %\begin{figure}[!h]
  \vspace*{1em}
  \emph{Beispiel und Zwischencode:}
  \vspace*{-1em}
  \renewcommand{\baselinestretch}{1.0}\normalsize
  %\makebox[\textwidth]{
    \begin{center}
    \begin{minipage}{7cm}\lstinputlisting{s1source/#1.s1}\end{minipage}
    \begin{minipage}{\textwidth}\include{s1latex/#2}\end{minipage}
    %\caption{#2.}
    \label{fig:ir_example_#1}
    \end{center}
    \vspace*{-1em}
  %\end{figure}
  %}
  \defltbaselinestretch\normalsize
}
\newcommand\SeqOpSampleStacked[2]{\SeqOpSampleStackedSeparate{#1}{#1}{#2}}

\paragraph{Zuweisungsoperation:} Kopiert Inhalt eines Registers in ein anderes.
%\\\hspace*{1cm}$d \gets s$

\SeqOpSample{assign}{Zuweisungsoperation}


\paragraph{Konstantenoperation:} Diese weist dem Zielregister eine Boolesche, Integer- (vorzeichenlos oder vorzeichenbehaftet) oder
Fließkommakonstante zu.

%\\\hspace*{1cm}$d \gets \mathrm{Konstante}$
\SeqOpSample{const}{Konstantenoperation}


\paragraph{Typumwandlungsoperation:} Liest das Eingaberegister, wandelt dessen Wert in den Ziel-Typ und schreibt den umgewandelten Wert in das Zielregister.
Kann zwischen Integer- (vorzeichenlos oder vorzeichenbehaftet) und Fließkommawerten umwandeln.

%\\\hspace*{1cm}$d \gets s\ \mathrm{als}\ \mathrm{"`Ziel-Typ``}$
\SeqOpSample{cast}{Typumwandlungsoperation}


% Eventuell Tabelle (Operation|Verknüpfung|Eing-Typ|Ausg-Typ) statt Prosa?
\paragraph{Arithmetische Operation:} Die Inhalte zweier Eingaberegister 
werden durch eine arithmetische Operation verknüpft und das Ergebnis in das Zielregister geschrieben.
Die Eingaberegister und das Zielregister müssen vom gleichen Typ sein -- Integer- (vorzeichenlos oder vorzeichenbehaftet) und Fließkommawerte.

%\\\hspace*{1cm}$d \gets s + t$
%\\\hspace*{1cm}$d \gets s - t$
%\\\hspace*{1cm}$d \gets s * t$
%\\\hspace*{1cm}$d \gets s / t$
\SeqOpSample{arith}{Arithmetikoperationen}


\paragraph{Vergleichsoperation:} Die Inhalte zweier Eingaberegister 
werden miteinander verglichen (gleich, ungleich, größer, größer gleich, kleiner oder kleiner gleich) und das Ergebnis in das Zielregister geschrieben.
Die Eingaberegister müssen vom gleichen Typ sein -- Integer- (vorzeichenlos oder vorzeichenbehaftet) und Fließkommawerte.
Das Zielregister muss vom Typ Boolean sein.

%\\\hspace*{1cm}$d \gets s = t$
%\\\hspace*{1cm}$d \gets s < t$
%\\\hspace*{1cm}$\phantom{d \gets}\vdots$
\SeqOpSample{compare}{Vergleichsoperationen}


\paragraph{Logische Operation:} Die Inhalte zweier Eingaberegister werden durch logisch UND oder logisch ODER verknüpft und das Ergebnis in das Zielregister geschrieben.
Die Eingaberegister und das Zielregister müssen vom Typ Boolean sein.

%\\\hspace*{1cm}$d \gets s \land t$
%\\\hspace*{1cm}$d \gets s \lor t$
\SeqOpSample{logic}{Logische Operationen}


\paragraph{Unäre Operation:} Unäre Operationen sind Vorzeichenumkehrung, logisches NICHT und bitweise Invertierung.\\
Die Vorzeichenumkehrung kehrt das Vorzeichen des Wertes des Eingaberegisters um und schreibt das Ergebnis in das Zielregister.
Die Eingabe- und das Zielregister müssen vom gleichen Typ sein -- Integer- (vorzeichenlos oder vorzeichenbehaftet) und Fließkommawerte.\\
Logisches NICHT invertiert den Wert des Eingaberegisters und schreibt das Ergebnis in das Zielregister.
Die Eingabe- und das Zielregister müssen vom gleichen Typ Boolean sein.\\
Bitweise Invertiertung wird auf das Eingaberegister angewendet und schreibt das Ergebnis in das Zielregister.
Die Eingabe- und das Zielregister müssen von einem Integer-Typ (vorzeichenlos oder vorzeichenbehaftet) sein.

%\\\hspace*{1cm}$d \gets \neg s$
%\\\hspace*{1cm}$d \gets -s$
%\\\hspace*{1cm}$\phantom{d \gets}\vdots$
\SeqOpSample{unary}{Unäre Operationen}


\subsubsection{Vektor- und Matrix-Operationen}

\paragraph{Vektor-Erstellung:} Nimmt als Eingabe ein bis vier Register, je nach der Komponentenanzahl des Zielregisters. Die Eingaberegister müssen alle
den Basistyp des Zielregisters besitzen. Sie werden der Reihe nach den Vektorkomponenten im Zielregister zugeordnet.
%\\\hspace*{1cm}$d \gets (s)$
%\\\hspace*{1cm}$d \gets (s, t)$
%\\\hspace*{1cm}$\phantom{d \gets}\vdots$

\SeqOpSample{makevec}{Vektor-Erstellung}


\paragraph{Extraktion einer Vektorkomponente:} Nimmt neben einem Eingaberegister auch eine Integer-Konstante $N$ im Bereich $0 \dots 3$ entgegen.
Das Eingaberegister muss von einem Vektortyp sein. Das Zielregister muss vom Basistyp des Vektors sein.
Aus dem Eingabevektor wird die Komponente Nummer $N$ extrahiert und in das Zielregister geschrieben.
%\\\hspace*{1cm}$d \gets s_N$

\SeqOpSample{vecextract}{Extraktion einer Vektorkomponente}


\paragraph{Matrix-Erstellung:} Nimmt als Eingabe ein bis sechzehn Register, je nach den Dimensionen des Zielregisters. Die Eingaberegister müssen alle
den Basistyp des Zielregisters besitzen. Sie werden der Reihe nach den Elementen im Zielregister zugeordnet: zuerst das Element der ersten Spalte in der ersten Zeile,
als nächstes das Element der zweiten Spalte in der ersten Zeile, usw.
%\\\hspace*{1cm}$d \gets \left(s\right)$
%\\\hspace*{1cm}$d \gets \left(\begin{array}{cc}s&t\\u&v\end{array}\right)$
%\\\hspace*{1cm}$\phantom{d \gets}\vdots$

\SeqOpSampleStacked{makematrix}{Matrix-Erstellung}

\subsubsection{Array-Operationen}

\paragraph{Array-Erstellung:} Nimmt als Eingabe eine variable Anzahl von Registern, die Anzahl der Eingaberegister bestimmt die Länge des Arrays.
Die Eingaberegister müssen alle den Basistyp des Zielregisters besitzen. Sie werden der Reihe nach den Array-Elementen im Zielregister zugeordnet.
%\\\hspace*{1cm}$d \gets (s, t, \dots)$

\SeqOpSampleStacked{makearray}{Array-Erstellung}


\paragraph{Extraktion eines Arrayelements:} Verwendet zwei Eingaberegister: ein Arrayregister sowie als Index ein Register mit einem vorzeichenlosen Integer.
Aus dem Array wird das Element mit dem gegebenen Index extrahiert und in das Zielregister geschrieben.
Das Zielregister muss den Basistyp des Array-Registers besitzen.
%\\\hspace*{1cm}$d \gets s[t]$

\SeqOpSampleStacked{arrayextract}{Extraktion eines Arrayelements}


\paragraph{Änderung eines Arrayelements:} Verwendet drei Eingaberegister: neben einem Arrayregister und dem Indexregister (vorzeichenloser Integer)
weiterhin ein Register vom Basistyps des Arrays (der "`neue Wert"').\\
Das Zielregister muss den gleichen Typ wie das Arrayregister besitzen.\\
Aus dem Eingabearray werden alle Elemente \emph{außer} das Element des gegebenen Indexes in das Zielarray kopiert;
dort wird stattdessen der "`neue Wert"' abgelegt. Das Zielregister muss den Typ des Arrayregisters besitzen.
%\\\hspace*{1cm}$d \gets (x | x = s[i]\ \mathrm{f"ur\ alle}\ i \neq t, u\ \mathrm{sonst})$

In Pseudocode ausgedrückt:
\begin{lstlisting}
// Eingaben: Array, Index, NeuerWert
// Ausgabe: Zielarray
for element = 0 to Array.length-1
{
  if (element == Index)
    ZielArray[element] = NeuerWert;
  else
    ZielArray[element] = Array[element];
}
\end{lstlisting}

\SeqOpSampleStackedSeparate{arraychange}{arraychange_fixed}{Änderung eines Arrayelements}


\paragraph{Arraylänge:} Nimmt im Eingaberegister ein Array entgegen. Schreibt in das Zielregister, welches vom Typ "`vorzeichenloser Integer"' sein muss,
die Anzahl der Elemente des Arrays.
%\\\hspace*{1cm}$d \gets |s|$

\SeqOpSampleStacked{arraylen}{Arraylänge}

\subsubsection{Komplexe Operationen}

\paragraph{Sequenzschachtelung:} Eine Operation, die auf eine weitere, innere Sequenz verweist, welche beim Ausführen der Operation abgearbeitet wird.
Neben dem Verweis auf eine Sequenz werden auch Listen von "`importierten"' und "`exportierten"' Namen zu der Operation gespeichert.
Jedem Namen ist weiterhin ein Register in der inneren Sequenz zugeordnet.

Für den Zugriff auf Register der "`umgebenden"' Sequenz wird von dieser 
beim Einfügen der Operation eine Zuordnung von "`importierten"' und "`exportierten"' Namen der
inneren Sequenz zu Registern der umgebenden Sequenz vorgenommen. 
%Diese Zuordnung wird benutzt, um vor der Abarbeitung der eingeschachtelten Sequenz Registerwerte von der umgebenden in die eingeschachtelte Sequenz zu kopieren.
%Nach der Abarbeitung erfolgt ein Kopieren in die umgekehrte Richtung.

Eine Sequenzschachtelung gilt als \emph{eine} Operation in der umgebenden Sequenz. Solange die Zuordnung von "`exportierten"' Namen der
eingeschaltelten Sequenz zu Registern der umgebenden Sequenz korrekt ist (es wird kein Register verwendet, das bereits beschrieben wurde), bleibt die Register-Zuweisungs-Bedingung erfüllt.

\SeqOpSampleStacked{nest_seq}{Sequenzschachtelung (Rahmen symbolisiert innere Sequenz)}

\paragraph{Verzweigung:} Eine auf der Sequenzschachtelung basierende Operation. Eingaben sind zwei Sequenzen (eine ``if''- und eine ``else''-Sequenz) sowie ein Register vom
Typ Boolean mit dem Wert der Bedingung. Ist dieser "`wahr"', wird die ``if''-Sequenz ausgeführt, sonst die ``else''-Sequenz. Es müssen immer beide Sequenzen
gegeben werden, Sequenzen können aber leer sein.
%Soll ein Register in einer Verzweigung beschrieben werden, so muss dies immer in \emph{beiden} Blöcken geschehen, da ansonsten je nach Ausführungspfad ein
%Register undefinierte Wert

%Ein Register kann in beiden Blöcken beschrieben werden (z.B. wenn im Quellcode eine Variable von einer Bedingung abhängig unterschiedliche Werte zugewiesen wurden).
%Eine Verzweigung gilt als \emph{eine} Operation in der umgebenden Sequenz. D.h. auch wenn ein Register in beiden Blöcken beschrieben wird, wird es,
%von der umgebenden Sequenz aus gesehen, bloß von einer Operation beschrieben (eben der Verzweigung). Damit bleibt die Register-Zuweisungs-Bedingung erfüllt.
Ein beschriebenes "`exportiertes"' Register muss in beiden Untersequenzen beschrieben werden: würde in einer Verzweigung
in nur einer Sequenz ein Register beschrieben werden, würde bei Ausführung des "`anderen"' Pfades entweder zur Laufzeit das Register einen undefinierten Wert besitzen, oder
es müsste anderweitig überschrieben werden, was die Register-Zuweisungs-Bedingung verletzt. Um diese Probleme zu vermeiden wird verlangt,
dass in der "`anderen"' Sequenz eine Zuweisung (typischerweise vom "`alten"' Wert der dem Register entsprechenden Variable) vorgenommen werden muss.

Da eine Verzweigung als \emph{eine} Operation in der umgebenden Sequenz gilt, wird ein Register, auch wenn es in beiden Blöcken beschrieben wird, 
von der umgebenden Sequenz aus gesehen bloß von einer Operation beschrieben (eben der Verzweigung). Damit bleibt die Register-Zuweisungs-Bedingung erfüllt.

%\\\hspace*{1cm}$\mathrm{if}\ s\ \mathrm{then}\ \mathit{Block}\ \mathrm{else}\ \mathit{Block}$

%Um die SSA-Bedingungen zu erfüllen, aber

Abbildung~\ref{fig:ir_seq_branch} zeigt schematisch eine Verzweigungsoperation in einer Sequenz.
Zuerst wird der Bedingungswert \texttt{Z} berechnet. Die Verzweigungsoperation selbst enthält dazu noch
Verweise auf die ``if''- und ``else''-Sequenzen, zu denen es jeweils Zuordnungen von "`importierten"' und "`exportierten"' 
Namen der umgebenden Sequenz zu Registern der verwiesenen Sequenz gibt.

\begin{figure}[h]
   \centering
  \includegraphics{ir_seq_branch}
  \caption{Schema einer Verzweigungsoperation.}
  \small\includegraphics[height=10pt]{ir_seq_torquoise_arrow} symbolisiert die Registerzuordnungen aus Abb.~\ref{fig:ir_seq_block_nest}.
  \label{fig:ir_seq_branch}
\end{figure}

\SeqOpSampleStacked{branch}{Verzweigung}

\paragraph{While-Schleife:} Eine auf der Sequenzschachtelung basierende Operation. Eingaben sind eine Sequenz sowie zwei Register vom
Typ Boolean, jeweils mit einem Wert der Bedingung: das erste Register enthält die Bedingung \emph{vor} der ersten Ausführung der Sequenz,
das zweite Register die Bedingung \emph{nach} einer Ausführung der Sequenz.

Werte, die sich von Schleifendurchlauf zu Schleifendurchlauf ändern, werden ähnlich behandelt: es muss jedem solchen Wert ein lokales
Register im Schleifenkörper zugeordnet werden. Die Schleifenoperation selber erhält eine Abbildung von einem Paar "`externer"' Register
(Wert vor der ersten Ausführung sowie Wert nach einer Ausführung) zu den lokalen Registern als weitere Eingabe.
Durch diese Verwendung von Paaren von Eingaben ist es möglich, Werte in einem Schleifendurchlauf zu beschreiben
und im nächsten Durchlauf wieder als Eingabe für eine Operation zu verwenden: bei ein Quellcode wie 
\texttt{int i = 0; while (...) \{ i = i + 1; \}} müssten, ohne Registerpaare, bei \texttt{i = i + 1} entweder Eingabe-\texttt{i}
wie auch Ergebnis-\texttt{i} auf das gleiche Register umgesetzt werden -- welches entsprend mehrfach zugewiesen wird -- oder aber verschiedene Register, wobei
Eingabe-\texttt{i} immer den anfänglichen Wert \texttt{0} besitzen würde. Registerpaare erlauben es, dass im ersten Durchlauf
der anfängliche Wert \texttt{0} für Eingabe-\texttt{i} verwendet wird, in anschliessenden Durchläufen aber der Wert des Ergebnis-\texttt{i}
des letzten Durchlaufs.

%Durch die Verwendung eines
%Paares von Eingaben wird die Verwendung der $\phi$-Funktion vermieden.

Ein Register kann also in mehreren Schleifendurchläufen beschrieben werden.
Da aber eine Schleife als \emph{eine} Operation in der umgebenden Sequenz gilt, wird auch ein mehrmals beschriebenes Register,
von der umgebenden Sequenz aus gesehen, bloß von einer Operation beschrieben (eben der Schleife).
Damit bleibt die Register-Zuweisungs-Bedingung erfüllt.

Es gibt keine spezielle Operation für \texttt{for}-Schleifen, diese werden auf \texttt{while}-Schleifen abgebildet.
%\\\hspace*{1cm}$\mathrm{while}\ s\ \mathrm{do}\ \mathit{Block}$

\SeqOpSampleStacked{while}{Schleife}

\subsubsection{Funktions-Operationen}

\paragraph{Funktionsaufruf:} Diese Operation nimmt einen Funktionsbezeichner, eine Liste Eingabe-Register und eine Liste Ausgabe-Register
entgegen.
% Rückgabewert?
Die Eingaberegister werden der Position nach auf die Funktionsparameter abgebildet.

Der "`Bezeichner"' ist eine prinzipiell beliebig wählbare Zeichenkette, die die Funktion bezeichnet. Dem Code-Generator muss
vorher eine Funktionsbeschreibung übergeben worden sein, die durch den Bezeichner identifiziert werden kann.
%\\\hspace*{1cm}$d \gets \mathrm{Funktion}\ (s, \dots)$
%\\\hspace*{1cm}$\mathrm{Funktion}\ (s, \dots)$

\emph{Beispiel siehe nächster Absatz.}


\paragraph{Funktionsrücksprung:} Damit wird die Funktion verlassen. Es wird eine Liste von Registern entgegen genommen. Diese
werden, der Position nach, den Ausgabeparametern der Funktion zugewiesen.
%\\\hspace*{1cm}$\mathrm{return}\ s$
%\\\hspace*{1cm}$\mathrm{return}$

\SeqOpSampleStacked{funccall}{Funktionsaufruf und -rücksprung}


\paragraph{Vordefinierte Funktion:} Diese Operationen führen vordefinierte Funktionen (siehe~\ref{builtins}) aus
und arbeiten analog zu Funktionsaufrufen. Es wird ein Zielregister für den Rückgabewert %, eine Konstante, welche die Funktion identifiziert
und eine Liste Eingabe-Register entgegen genommen. Die Eingaberegister werden wieder der Position nach auf die Funktionsparameter abgebildet.
%\\\hspace*{1cm}$d \gets \mathrm{pow}(s, t)$
%\\\hspace*{1cm}$d \gets s \cdot t$
%\\\hspace*{1cm}$\phantom{d \gets}\vdots$

\SeqOpSampleStacked{funcbuiltin}{Vordefinierte Funktion}


%$\phi$-Funktion: diese konkrete Zwischencoderepräsentation eines compilierten Programmes enthält nicht die bei SSAs wesentliche $\phi$-Funktion.

% \subsection{Textdarstellung}

% Die folgende Tabelle listet auf, wie die verschiedenen Sequenzoperationen in den Beispielen als Text dargestellt werden.
% Bei den Parametern steht $d$ für das Zielregister einer Operation, $s$, $t$ bezeichnen die Quellregister.

% \begin{longtable}{ l l p{4cm} }
% Zuweisung & \begin{array}[t]{ll}\sOassign{d}{s}\\\sOassign{d}{\mathrm{Konstante}}\end{array}\\
% \hline
% Typumwandlung & \begin{array}[t]{ll}\sOcast{float}{d}{s}\\\sOcast{int}{d}{s}\\\sOcast{uint}{d}{s}\end{array}\\
% \hline
% Arithmetische Operationen & \begin{array}[t]{ll}\sOadd{d}{s}{t}\\\sOsub{d}{s}{t}\\\sOmul{d}{s}{t}\\\sOdiv{d}{s}{t}\\\sOmod{d}{s}{t}\end{array}\\
% \hline
% Vergleichsoperation & \begin{array}[t]{ll}\sOcmpeq{d}{s}{t}\\\sOcmpne{d}{s}{t}\\\sOcmplt{d}{s}{t}\\\sOcmple{d}{s}{t}\\\sOcmpgt{d}{s}{t}\\\sOcmpge{d}{s}{t}\end{array}\\
% \hline
% Logische Operation & \begin{array}[t]{ll}\sOand{d}{s}{t}\\\sOor{d}{s}{t}\end{array}\\
% \hline
% Unäre Operation & \begin{array}[t]{ll}\sOinv{d}{s}\\\sOneg{d}{s}\\\sOnot{d}{s}\end{array}\\
% \hline
% Vektor-Erstellung & \begin{array}[t]{ll}\sOmakevec{d}{\dots}\end{array} & Zahl der Quellregister variiert\\
% Extraktion einer Vektorkomponente & \begin{array}[t]{ll}\sOvecextract{d}{s}{\mathrm{n}}\end{array} & $n$ ist konstante Komponentennummer\\
% \hline
% Matrix-Erstellung & \begin{array}[t]{ll}\sOmakematrix{d}{\dots}\end{array} & Zahl der Quellregister variiert\\
% \hline
% Array-Erstellung & \begin{array}[t]{ll}\sOmakearray{d}{\dots}\end{array} & Zahl der Quellregister variiert\\
% Extraktion eines Arrayelements & \begin{array}[t]{ll}\sOgetelem{d}{s}{i}\end{array} & $i$: zu extrahierender Index\\
% Änderung eines Arrayelements & \begin{array}[t]{ll}\sOsetelem{d}{s}{i}{t}\end{array} & $t$: neuer Elementwert\\
% Arraylänge & \begin{array}[t]{ll}\sOarraylen{d}{s}\end{array}\\
% \hline
% Sequenzschachtelung & \begin{array}[t]{ll}\sOnestseq{Sequenz}\end{array}\\
% \hline
% Verzweigung & \begin{array}[t]{ll}\sObranch{c}{if-Sequenz}{else-Sequenz}\end{array} & $c$: Bedingungsregister\\
% \hline
% While-Schleife & \begin{array}[t]{ll}\sOwhile{c_0}{c_n}{Sequenz}\end{array} & $c_0, c_n$: Bedingungsregister erster Durchlauf/weitere Durchläufe\\
% \hline
% Funktionsaufruf & \begin{array}[t]{ll}\sOcall{\mathrm{Funktion}}{\dots}\\\sOcallret{d}{\mathrm{Funktion}}{\dots}\end{array} & Zahl der Quell- und Zielregister variiert\\
% \hline
% Funktionsrücksprung & \begin{array}[t]{ll}\sOreturnvoid\\\sOreturn{s}\end{array}\\
% \hline
%% Vordefinierte Funktion
% Skalarprodukt & \begin{array}[t]{ll}\sObuiltindot{d}{s}{t}\end{array}\\
% Vektorprodukt & \begin{array}[t]{ll}\sObuiltincross{d}{s}{t}\end{array}\\
% Matrixmultiplikation & \begin{array}[t]{ll}\sObuiltinmul{d}{s}{t}\end{array}\\
% Normalisierung & \begin{array}[t]{ll}\sObuiltinnormalize{d}{s}\end{array}\\
% Euklidische Länge & \begin{array}[t]{ll}\sObuiltinlength{d}{s}\end{array}\\
% Minimum & \begin{array}[t]{ll}\sObuiltinmin{d}{s}{t}\end{array}\\
% Maximum & \begin{array}[t]{ll}\sObuiltinmax{d}{s}{t}\end{array}\\
% Potenz & \begin{array}[t]{ll}\sObuiltinpow{d}{s}{t}\end{array}\\
% Textur auslesen & \begin{array}[t]{ll}\sObuiltintexOneD{d}{s}{t}\\\sObuiltintexTwoD{d}{s}{t}\\\sObuiltintexThreeD{d}{s}{t}\\\sObuiltintexCUBE{d}{s}{t}\\\end{array}\\
% \end{longtable}

\subsection{Beispiel}

Abbildung~\ref{fig:ir_sample_src} zeigt ein einfaches Programm in der Sprache, Abbildung~\ref{fig:ir_sample_gen} die generierte Zwischencoderepräsentation.

\begin{figure}[hp]
   \centering
  \lstinputlisting{s1source/sample_minimal.s1}
  \caption{Quelltext eines Programms.}
  \label{fig:ir_sample_src}
\end{figure}
\begin{figure}[hp]
   \centering
  \input{s1latex/sample_minimal.tex}
  \caption{Zu~\ref{fig:ir_sample_src} generierte Zwischencoderepräsentation.}
  \label{fig:ir_sample_gen}
\end{figure}

\newpage
\section{Auftrennung}
\label{Auftrennung}

% Compilerziel: Eingabe _ein_ Programm
Ziel des Compilers soll es sein, als Eingabe \emph{ein} Shadingprogramm -- mit einer Hauptfunktion usw., nicht nur "`ein Quelltext"' -- entgegenzunehmen
und daraus Programme zu erzeugen, die für die programmierbaren Grafikchip-Einheiten zur Vertex- bzw. Pixelverarbeitung genutzt werden können.

Diese Aufgabe wird vom "`\emph{Splitter}"' wahrgenommen.
Er trennt ein als Zwischencoderepräsentation vorliegendes Programm in zwei Ausgabeprogramme, ein \emph{Vertex-} und ein \emph{Pixelprogramm}, auf.
%Die Entscheidung wird für individuelle Sequenzoperationen getroffen: 

% Erwähnung "Domänen"/"Frequenzen"/etc. -> klären, in Operationen auf welchen Daten man Prog. formuliert (hier Pixel)

% Ausgabe: zwei Programme (Vertex, Pixel)
% Prog.-Ausg.: Vertexkoord., Pixelkoord.
% Berechnung+Verwendung von Werten in versch. Programmen handhaben
% Implizite Interpolation berücksichtigen

Es muss für jede individuelle Sequenzoperation entschieden werden, ob diese während der Pixelverarbeitung ausgeführt werden muss
oder während der Vertexverarbeitung ausgeführt werden kann.
Dabei ist zu berücksichtigen, dass einige Operationen nur in einem der Verarbeitungsschritte sinnvoll sind -- z.B. sollte ein Auslesen
eines Bildes zur Anwendung eines Oberflächenmusters sinnvollerweise in der Pixelverarbeitung vorgenommen werden.

Die Entscheidung, in welchem der beiden Ausgabeprogramm eine Sequenzoperationen ausgeführt werden soll,
wird mit Hilfe von "`Berechnungsfrequenzen"' (siehe unten), die sich jeder Operation zuordnen lassen, getroffen.

Da einige Operation in der Vertex-, andere in der Pixelverarbeitung ausgeführt werden sollen, müssen bei komplexeren
Ausdrücken Zwischenergebnisse von der Vertex- zur Pixelverarbeitung übergeben werden. Es muss also die "`Schnittstelle"'
zwischen den Verarbeitungseinheiten generiert werden.
Dabei ist zu beachten, dass nur Werte vom Vertex- zum Pixelprogramm übertragen werden können; % @@@ Eher nicht hier
eine Übertragung in die andere Richtung ist nicht möglich.

Auch muss die von der GPU vorgenommene implizite Interpolation von Ergebnissen der Vertexverarbeitung in Betracht
gezogen werden. D.h. der Compiler muss die Operationen des Programms so aufteilen, dass die Interpolation bei der Übergabe
von Werten von der Vertex- zur Pixelverarbeitung nicht die Berechnungen des Programms "`verfälscht"'. (Würde z.B. der Ausdruck 
$x^2$ in der Vertexberechnung berechnet und interpoliert in der Pixelverarbeitung verwendet werden, so käme dies einer
lineare Approximation einer quadratischen Kurve gleich -- der Wert des Ausdruck wäre ungenauer, also "`verfälscht"'.)

Dies wird durch eine Überprüfung auf "`Interpolierbarkeit"' (siehe Abschnitt~\ref{Interpolierbarkeit}) einer Operation erreicht.

% High-Level Arbeitsweise
%Diese bestimmt die eigentliche "`Auftrennung"', also in welche Teilprogramme eine Operation ausgegeben wird.

\subsection{Berechnungsfrequenzen}
%\subsection{Definition Berechnungsfrequenz}
\label{Berechnungsfrequenz}

% Begriff gewählt weil: "Häufigkeit" auf Zeit der Objekt-Darstellung gesehen
% Frequenz für Operationen; Werte "liegen für Objekt-/Vertex-/Pixel-Berechnungen vor"

In Abschnitt~\ref{object_data} wurde aufgezählt, welche Arten von Daten bei der Darstellung eines 3D-Objektes auftreten.
Dabei wurde zwischen Daten unterschieden, die zwischen verschiedenen Objekten variieren, Daten, die zwischen verschiedenen
Vertices eines Objekt variieren, und Daten, die zwischen verschiedenen Pixeln eines gerasterten Dreiecks variieren.
Auch wurde dargelegt, dass Berechnungen auf den verschiedenen Arten von Daten verschieden häufig sind --
es treten in der Regel mehr Pixelberechnungen als Vertexberechnungen und mehr Vertexberechnungen als Objektberechnungen auf.

Aus diesen Beobachtungen lässt sich der Begriff der "`Berechnungsfrequenz"'\footnote{Verwendet und benannt wurden Berechnungsfrequenzen zuerst in \cite{stanford_rtsl}}
formulieren. 

\begin{defn}
Die \emphalt{Berechnungsfrequenz eines Ausdrucks} beschreibt, wie oft sich der Wert des gegebenen Ausdrucks, auf alle Ausführungen eines
Programmes gesehen, ändert.
\end{defn}

Der Term "`Frequenz"' wird verwendet, da man die Anzahl der ausgeführten Berechnungen auf eine Zeiteinheit bezogen -- hier die "`Lebenszeit"' eines Programmes
-- betrachtet. Zwar sind sowohl die Berechnungsanzahl wie auch die "`Lebenszeit"' abstrakte Größen, lassen trotzdem aber
Vergleiche zu: zur Veranschaulichung sei die Zeiteinheiten das einmalige Darstellen eines 3D-Objektes.
Die Frequenz einer in der Vertexberechnung ausgeführten Operation ist niedriger als die Frequenz einer in der Pixelberechnung ausgeführten Operation, 
da bei der Darstellung des Objekts in der Regel mehr Pixelberechnungen als Vertexberechnungen vorgenommen werden.
Dieses Verhältnis bleibt auch erhalten, wenn man verschiedene Zeiteinheiten wählt -- sei dies zwei 3D-Objekte, zehn 3D-Objekte oder  $N$ 3D-Objekte.

Die kleinstmögliche Frequenz besitzen also statische Konstanten.

Die höchstmögliche Frequenz besitzen Ausdrücke, die bei jeder Auswertung einen anderen Wert liefern.
\emph{(Beispiel: Werte aus einer externen Datenquelle wie einem Zufallsgenerator.)}

%\subsection{Berechnungsfrequenzen bei Shading}
Für die Berechnungen der Echtzeit-3D-Grafik sind vor allem folgende Berechnungsfrequenzen bedeutend:
\begin{itemize}
% \item \emph{Mesh-Frequenz}: Ausdruck ist konstant während der Darstellung eines Dreiecksnetzes, aber nicht zwischen
% verschiedenen Dreiecksnetzen oder Darstellungsläufen. %\emph{(Beispiel: Position in Weltkoordinaten.)}
% \item \emph{Vertex-Frequenz}: Ausdruck ist von per-Vertex vorliegenden Werten abhänging, hat also unterschiedliche Werte bei unterschiedlichen Vertices. %\emph{(Beispiel: Texturkoordinaten.)}
% \item \emph{Fragment-Frequenz}: Ausdruck ist von anderen, per Fragment zu berechnenden Ausdrücken abhänging,
% hat also unterschiedliche Werte für unterschiedliche Fragmente. %\emph{(Beispiel: Aus Textur gelesener Wert.)}
\item \emph{Objekt-Frequenz}, also Berechnungen auf Objektattributen (Daten, die für das Objekt vorliegen)
bzw. davon abgeleiteten Werten.
\item \emph{Vertex-Frequenz}, also Berechnungen auf Werten von Vertexattributen (Daten, die von Vertex zu Vertex verschieden sind)
bzw. davon abgeleiteten Werten.
%\emph{(Beispiel: Texturkoordinaten.)}
\item \emph{Pixel-Frequenz}, also Berechnungen auf Eingaben der Pixelberechnung bzw. davon abgeleiteten Werten.
\end{itemize}

%Als Besonderheit kommt hinzu, dass aus Daten mit \emph{Vertex-Frequenz} durch lineare Interpolation Daten mit
%\emph{Fragment-Frequenz} gewonnen werden. %\emph({Beispiel: für Auslesen einer Textur verwendete Koordinaten)}
%Dies führt dazu, dass Ausdrücke, die nach den folgenden Regeln
%eigentlich Fragment-Frequenz besitzen müssten, Vertex-Frequenz besitzen, unter der Bedingung, dass
%das Ergebnis einer linearen Interpolation des Gesamtausdrucks äquivalent zum Ergebnis bei linearer
%Interpolation aller Teilausdrücke (mit jeweils immer gleicher Gewichtung) ist.
%Dies erlaubt, gewisse Ausdrücke per Vertex statt per Fragment auszuführen. Details zu diesem Aspekt finden sich in
%Abschnitt~\ref{Interpolierbarkeit}.

\subsection{Formulierte Frequenz}
\label{formulierte_frequenz}

% Shadingprogramme arbeiten mit verschiedenen Daten (Objektattribute, Werte von Vertexattributen, abgeleitete Eingaben der Pixelverarbeitung)
% und bestehen aus zwei Teilprogrammen, die mit Vertex- und Pixelverarbeitung auf verschiedene "`Klassen"' von Berechnungen vornehmen.
% Für die zu übersetzende Shadingsprache muss also entschieden werden, in welcher der "`Klassen"' sie formuliert werden soll --
% in diesem Fall sollen Programme so formuliert werden, als würden sie grundsätzlich für jedes Pixel ausgeführt werden.


Zwar soll die Berechnungsfrequenz von Operationen soweit möglich automatisch bestimmt werden, trotzdem muss eine Frequenz
gewählt werden, in der alle Operationen vorerst formuliert werden.

Betrachtet man eine "`niedrige"' Frequenz wie die Vertexfrequenz, so erkennt man, dass sich damit Berechnungen einer höheren
Frequenz (also Pixel) schlecht darstellen lassen. Betrachtet man allerdings Berechnungen mit Pixelfrequenz, so lassen sich
unter Umständen Berechnungen niedrigerer Frequenz ableiten.
Shadingprogramme sollten also grundsätzlich in "`Pixelfrequenz"' formuliert werden.

\subsection{Bestimmung der Berechnungsfrequenz}

Die Berechnungsfrequenz ist zwar eine Eigenschaft von Operationen, allerdings muss zu Registern, Zwischenwerten u.ä. gespeichert
werden, mit welcher Frequenz die zuweisende Operation ausgeführt wurde, da diese "`Zuweisungsfrequenz"' eines Wertes beeinflusst,
mit welcher Frequenz eine Operation ausgeführt werden muss, die den Wert als Eingabe verwendet.

\paragraph{Register:} %Variablen besitzen eine zugeordnete Berechnungsfrequenz, die angibt wie oft sich der enthaltene Wert ändert.
%Diese Frequenz entspricht der Frequenz des zuletzt zugewiesenen Ausdrucks (oder undefiniert wenn noch keine Zuweisung stattfand).
Zu jedem Register wird gespeichert, welche Frequenz die Operation hatte, die den Registerwert bestimmt hat (d.h. in welches der
Ausgabeprogramme diese Operation ausgegeben wurde). 

\paragraph{Arrays:} %Ist die Größe eines Arrays statisch bekannt kann jedes Element als einzelne Variable gesehen werden
%(und entsprechend jedem Element eine eigene Berechnungsfrequenz zugeordnet werden).
%Ist die Größe eines Arrays nicht statisch bekannt, so muss für alle Elemente die höchste, irgendeinem Element möglicherweise zugewiesene
%Frequenz angenommen werden -- 
Wird auf Elemente eines Arrays nur mit statisch bekannten Indizes zugegriffen kann jedes Element als einzelnes Register gesehen werden
(und entsprechend kann jedem Element zugeordnet werden, welche Frequenz die Operation hatte, die den Elementwert bestimmt hat).
Da beim Zugriff mit nicht statisch bekannten Indizes jedoch nicht bestimmt werden kann, welche Berechnungsfrequenz 
die Operation hatte, die einem Element einen Wert zugeweisen hat (da ja auch nicht bekannt ist, auf welche Elemente genau zugegriffen wird),
so muss für alle Elemente die höchste, bei der Zuweisung irgendeines Elements möglicherweise verwendete Berechnungsfrequenz angenommen werden.

%\paragraph{Ausdrücke:} Die Berechnungsfrequenz eines Wertes eines Ausdrucks ergibt sich aus der kleinsten gemeinsamen Frequenz
%der in dem Ausdruck enthaltenen Teilausdrücke \emph{nach} möglicher Anwendung von Umformungen zur Vereinfachung/Optimierung --
%sofern keine \emph{Spezialregeln} greifen (siehe Unten).
\paragraph{Ausdrücke:}
Die notwendige Berechnungsfrequenz für einen Ausdrucks hängt von der grössten gemeinsamen Frequenz,
in der die verwendeten Operanden berechnete wurden, sowie der verwendeten Verknüpfung ab.
Die Abschnitte~\ref{splitter_Berechnungsfrequenzen} und~\ref{Interpolierbarkeit} beschreiben wie die Berechnungsfrequenz für einen Ausdrucks bestimmt werden kann.
Diese Berechnungsfrequenz eines Ausdrucks wird, wie oben genannt, zu den Ergebnisregistern (sofern vorhanden) der Operation gespeichert.

%\subsection{Spezialregeln für Berechnungsfrequenzen von Ausdrücken}

%\paragraph{Manuelle Bestimmung:}
%Bei einigen Ausdrücken kann eine Frequenz nicht automatisch abgeleitet werden, insbesondere bei Eingabeparametern aus der
%Umgebung. 
\paragraph{Programmeingaben:}
Bei Eingabeparametern aus der Umgebung kann eine Frequenz nicht automatisch abgeleitet werden.
Es wird davon ausgegangen, dass die umgebende Anwendung dem Compiler mitteilt, mit welcher Frequenz ein Eingabeparameter
geändert wird.\\

% Die Beschaffenheit der Daten beim Shading erlaubt
% weitere
%einige
% Spezialfälle:
% \paragraph{Lineare Operationen:} Vertexattribute werden über die Fragmente eines Dreiecks linear interpoliert; deswegen ist es
% erlaubt, lineare Operationen auf Vertex-Frequenz zu vollziehen, wenn alle Operatoren mit Vertex-Frequenz oder darunter
% berechnet wurden.

% \paragraph{Spezielle Eigenschaften:} "`Spezialwissen"' über mögliche Werte kann benutzt werden, um die Frequenz eines
% Ausdrucks zu bestimmen, insbesondere wenn diese niedriger als die normalerweise bestimme Frequenz wäre.
% \begin{itemize}
% \item \emph{Einheitsvektoren:} Einheitsvektoren werden oft in Shadingprogrammen benutzt. Einheitsvektoren können aber 
% nicht linear interpoliert werden, da dies einen Verlust der Einheitslänge zur Folge haben kann. Trotzdem kann es effizienter
% sein, einen Einheitsvektor mit Vertex-Frequenz zu berechnen, über die Fragmente linear zu interpolieren und per Fragment
% zu normalisieren, als den Vektor vollständig mit Fragment-Frequenz zu berechnen.
% \end{itemize}

\subsection{Berechnungsfrequenzen in der Aufspaltung}
\label{splitter_Berechnungsfrequenzen}
% Welche Frequenzen?

Für die Aufspaltung relevante Frequenzen sind die Objekt-, % TODO Vergl. Nomenklatur mit Erklärung Freq.; "Freq." besser nicht überladen mit "Verarbeitungsschritt"
% "Uniform" blöd
Vertex- und Pixelfrequenz.

Werte von Objektattributen, also Eingaben, die sich nicht während aufeinanderfolgenden Ausführungen eines Programmes
ändern, können als \emph{dynamische Konstanten} angesehen werden. Deren Werte stammen aus der umgebenden Anwendung.

Werte von Vertexattributen sind den verschiedenen Vertices zugeordnete Eingaben. % TODO Verw. auf Vertexdaten
Auch diese sind Anwendungsdaten.

Eingaben der Pixelberechnung sind die interpolierten Ausgaben des Vertexprogramms (siehe Abschnitt~\ref{schnittstelle} unten). 
Insbesondere besitzen GPUs keinen Mechanismus, der der Anwendung erlauben würden, direkt Eingaben für jedes Pixel
vorzugeben.

"`Echte"', statische Konstanten werden vom Splitter als "`Objekteingaben"' betrachtet.

Für jedes Register wird verfolgt in welchen Teilprogrammen es berechnet wurde.
Dabei kann ein Register in mehreren Teilprogrammen verfügbar sein, wenn es im Vertexprogramm berechnet wurde, aber später 
zur Übertragung an das Pixelprogramm markiert wird (Abschnitt~\ref{schnittstelle}).

%: mit \emph{Vertexfrequenz} (per Vertex) berechnete Operationen werden dem Vertexprogramm zugeordnet.
%Analog werden mit \emph{Fragmentfrequenz} (per Fragment) berechnete Operationen dem Fragmentprogramm. Die Bestimmung der Berechnungsfrequenz hängt von der Operation selbst
%und von den Frequenzen, mit denen die Operanden berechnet wurden, ab. 

Die Teilprogramme, in denen ein Register vorliegt, beeinflussen, in welchen Teilprogrammen Operationen ausgeführt werden können,
die das Register als Operand verwenden: Eine Operation muss mindestens in derjenigen Frequenz ausgeführt werden, welche dem Maximum der Frequenzen
entspricht, in denen die Operanden ausgeführt wurden: eine Operation seltener auszuführen, als sich die Operanden ändern könnten, ist offensichtlich nicht sinnvoll.
So muss z.B. eine Addition von zwei Werten in der Pixelberechnung ausgeführt werden, wenn einer der Summanden in der Pixelberechnung berechnet wurde.
% DIes ist darin begründet, dass Werte nur vom Vertex- zum Fragmentprogramm, aber nicht zurück, übertragen werden können. ... \ref{}

Vorraussetzung für die Ausführung einer Operation in der Vertexberechnung ist damit, dass beide Operanden als Werte von Vertexattributeb vorliegen
bzw. von solchen abgeleitet wurden.
(Darüber hinaus muss die Operation das Kriterium der \emph{Interpolierbarkeit}, beschrieben in Abschnitt~\ref{Interpolierbarkeit}), erfüllen).

\subsubsection{Ausgegebene Programme}
Der Splitter kategorisiert Operationen auch als "`in der Objektberechnung ausgeführt"', generiert jedoch \emph{kein} separates Programm
für die Objektberechnung.
Stattdessen werden Operationen der Objektberechnung sowohl vom Vertex- als auch vom Pixelprogramm ausgeführt. Zwei Annahmen
liegen diesem Zugrunde: zuerst, dass nur relativ einfache Operationen in der Objektberechnung vorgenommen werden, es also kein
Nachteil durch eine mehrfache Ausführung in Vertex- und Pixelprogramm entsteht. Die zweite Annahme ist,
dass durch weitere Optimierungsschritte wie die "`Entfernung unnötiger Operationen"' einige Operationen der Objektberechnung entfernt werden.

% Eingaben: Uniform oder per Vertex; Fragmentfreq. nur Eingaben von VP

\subsection{Schnittstelle Vertex-/Pixelprogramm}
\label{schnittstelle}

Da ein Teil der Operationen des ursprünglichen Programms dem Vertexprogramm zugeordnet wird, ein anderer Teil aber dem
Pixelprogramm, müssen Ergebnisse des einen Programms zum anderen übertragen werden.

Stellt der Splitter die Notwendigkeit des Übertragens für einen Wert fest, wird das Register, welches den Wert enthält, aufgezeichnet.
Diese Liste der zu übertragenden Werte ("`Schnittstelle"' in Abbildung~\ref{fig:structure}) wird später dem Codegenerator übergeben.
Dieser kümmert sich um die "`technischen"' Details wie die Zuordnung von für die Übertragung notwendigen Ressourcen und % @@@ Ress. -> Interpolatoren. Verw
entsprechende Abbildung in der Zieldarstellung.

\subsection{Interpolierbarkeit}
\label{Interpolierbarkeit}
% Kriterium: Interpolation

Programme der Shadingsprache sind grundsätzlich so formuliert, als würden Operationen in der Pixelberechnung ausgeführt (siehe Abschnitt~\ref{formulierte_frequenz}).
Das vom Splitter zu lösende Problem ist damit die Bestimmung von Operationen, die in der Vertexberechnung ausgeführt werden können.
Das Hauptkriterium diese Entscheidung ist die \emph{Interpolierbarkeit} einer Operation.

\subsubsection{Praktische Grundlage}

Die praktische Grundlage der Interpolierbarkeit ist die in Abschnitt~\ref{hw_steps} beschriebene lineare Interpolation von Ausgaben
von Vertexberechnungen, um die Interpolationsergebnisse als Eingabe der Pixelberechnungen zu nutzen.

Das Kriterium "`Interpolierbarkeit"' beschreibt, welche während einer Pixelberechnung vorgenommenen Operationen
auch während einer Vertexberechnung vorgenommen werden und anschliessend interpoliert werden können, ohne dass sich das Ergebnis ändert.

\subsubsection{Ableitung und Definition}
\newcommand\lerp{\mathrm{lerp}}
Vom Vertexprogramm ausgegebene Werte werden, bevor sie wieder dem Pixelprogramm als Eingabe dienen, \emph{linear interpoliert}: % (siehe Abschnitt~\ref{rasterung}):
% TODO: Verw. auf Erklärung/Interpolatoren
Eine lineare Interpolation -- die Funktion sei "`$\lerp$"' genannt -- zwischen zwei Werten $a$ und $b$ mit Faktor $f$ ($0 \le f \le 1$) wird durch $\lerp(a, b, f) = a \cdot (1-f) + b \cdot f$ berechnet.
Der Faktor $f$ "`gewichtet"' zwischen den beiden Werten: der Faktor $0$ gibt also den Wert $a$ zurück ($\lerp(a, b, 0) = a$),
der Faktor $1$ gibt den Wert $b$ zurück ($\lerp(a, b, 1) = b$).

Angenommen, ein Wert soll $x$ von der Vertex- an die Pixelberechnung übergeben werden.
Die Ergebnisse der Vertexberechnung sind verschiedene Werte für verschiedene Vertices, ein Wert $x_1$ für das erste Vertex, ein Wert $x_2$ für das zweite Vertex usw.

Die Eingabe für die Pixelverarbeitung ist das Ergebnis einer implizierten, bei der Rasterung berechneten Interpolation $\lerp(x_1, x_2, f)$\footnote{Tatsächlich muss bei der Rasterung von Dreiecken zwischen drei Werten interpoliert werden. Dieser Abschnitt betrachtet konkret
bloss Interpolation zwischen zwei Werten, die Ergebnisse gelten aber auch bei Interpolation zwischen drei Werten.}.
$f$ wird von der GPU berechnet und variiert mit jedem Pixel. (Für das Pixel, auf das das erste Vertex abgebildet wurde, ist $f = 0$; für das Pixel,
auf das das zweite Vertex abgebildet wurde, ist $f = 1$; Pixel zwischen diesen "`Randpixeln"' haben entsprechend Werte von $f$ dazwischen -- siehe Abbildung~\ref{fig:interp_simple}).

Betrachtet sei eine Rechenoperation $\alpha = g(x)$, die während der Pixelberechnung ausgeführt wird.
$x$ sei dabei eine Ausgabe der Vertexberechnung, also aus Ausgaben $x_1$ und $x_2$ der Vertexberechnung für zwei verschiedene Vertices interpoliert -- $x = \lerp(x_1, x_2, f)$
mit beliebigem $f$. Ein Berechnen der Operation während der Pixelberechnung entspricht einem Berechnen von $\alpha_1 = g(\lerp(x_1, x_2, f))$.
Ein Berechnen der Operation während der Vertexberechnung und anschliessende Interpolation entspricht einem Berechnen von $\alpha_2 = \lerp (g(x_1), g(x_2), f)$.
Die Operation $g(x)$ kann auch in der Vertexberechnung ausgeführt werden, wenn das Ergebnis dieser Berechnung interpoliert werden kann ohne
das Endergebnis in der Pixelberechnung zu verändern, also $\alpha_1 = \alpha_2$ für beliebige $f$ gilt.

Also sei $g(x)$ \emph{interpolierbar} genannt, wenn $g(\lerp(x_1, x_2, f)) = \lerp (g(x_1), g(x_2), f)$ gilt. 

Augenscheinlich muss $g$ eine lineare Funktion sein.

%\begin{defn}
%Eine Funktion $g(x)$ wird \emphalt{interpolierbar} genannt, wenn für ein $x = \lerp(x_1, x_2, f)$ gilt:
%$g(\lerp(x_1, x_2, f)) = \lerp (g(x_1), g(x_2), f)$.
%\end{defn}

Für binäre Rechenoperationen lautet die Bedingung $\lerp (g (x_1, y_1), g (x_2, y_2), f) = g (\lerp (x_1, x_2, f), \lerp (y_1, y_2, f))$.
Rechenoperationen mit mehr Operanden müssen nicht betrachtet werden, da die Shadingsprache höchstens
binäre Rechenoperationen vorsieht bzw. "`komplexere"' Rechenoperationen auf binäre Operationen heruntergebrochen werden
können (siehe auch~\ref{split_builtins}). % Zweistelliges Äquivalent für "lineare Funktion"?

\subsubsection{Allgemein}
Da Rechenoperationen auf Vektoren komponentweise ausgeführt werden,  ist die "`Interpolierbarkeit"' ohne weiteres auch auf Vektoroperationen anwendbar.

Die geforderte Linearität von $g(x)$ führt dazu, dass bloss Operationen auf \texttt{float}-Werten problemlos interpolierbar sind.
Integer-Werte sind nicht interpolierbar, da bei deren Interpolation nicht-Integer-Werte als Zwischenergebnisse entstehen können.
Diese müssen (zwangsweise) gerundet\footnote{Oder Nachkommastelle abgeschnitten usw.} werden -- diese Rundung
ist aber keine stetige Funktion.

Zu Beachten ist, dass Interpolierbarkeit nur Relevanz für die Entscheidung hat, ob eine Operation, bei der mindestens ein Operand in der Vertexberechnung
berechnet wurde bzw. Wert eines Vertexattributes ist, während der Vertex- statt der Pixelberechnung ausgeführt werden kann.
Operationen allein auf Konstanten oder (praktisch konstanten) Objektattributen sind immer auch in der Vertexberechnung ausführbar - das Ergebnis
einer solchen Operation kann nicht zwischen den Berechnungen für verschieden Vertices variieren. Insbesondere können damit
auch Operationen auf Integer-Werten, oder Operationen, die nachfolgend als "`nicht interpolierbar"' klassifiziert werden,
in der Vertexberechnung ausgeführt werden.

% Konkreter: Ausgabe VP: x_1, x_2, ...
% Eingabe FP: lerp (x_1, x_2, f) - implizit

%Allerdings kann eine Operation auf Vertex-Frequenz "`abgesenkt"' werden, wenn eine lineare Interpolation
%des Ergebnisses der Operation äquivalent zu der Operation mit linear interpoliertem Operanden ist
%($\lerp (g (x_1, y_1), g (x_2, y_2), f) = g (\lerp (x_1, x_2, f), \lerp (y_1, y_2, f))$).
% Andere Operandenzahlen betrachten
% Beispiel?

% Stichwort: Linearkombination?
\subsubsection{Interpolierbarkeit einfacher Operationen}

\paragraph{Arithmetische Operationen:} Die Summe oder Differenz von zwei linearen Funktionen
ist wieder eine lineare Funktion, Addition und Subtraktion sind also uneingeschränkt interpolierbar.
% @@@ Beweisen? Zumindest erläutern.

Multiplikation und Division sind interpolierbar, wenn mindestens ein Operand höchstens in der Objektberechnung --
also nicht in der Vertex- oder Pixelberechnung -- bestimmt wurde.
Wurden beide Operanden in der Vertex- oder Pixelberechnung bestimmt, so ist eine Multiplikation oder Division keine lineare,
sondern eine \emph{quadratische} Funktion\footnote{Ersichtlich durch ein Beispiel: seien $a$ und $b$ in der Vertex- und/oder Pixelberechnung bestimmt,
also $a = \lerp(\dots, x, f)$ und $b = \lerp(\dots, y, f)$, so ist das Produkt $a \cdot b = \dots + \cdot f \cdot x \cdot f \cdot y = \dots  + f^2 \cdot x \cdot y$, also quadratisch.}, 
und damit nicht interpolierbar. In der Objektberechnung bestimmte Operanden können aber praktisch als
konstant betrachtet werden, die Multiplikation oder Division mit einem der Objektberechnung bestimmten 
Operanden ist also eine lineare Funktion und damit interpolierbar.

Die Modulo-Operation ist unstetig und daher nicht interpolierbar.

\paragraph{Logische Ausdrücke, Vergleichsoperationen:} Diese Operationen sind ebenfalls unstetig und somit nicht interpolierbar.

\paragraph{Unäre Ausdrücke:} Vorzeichenumkehrung ist offensichtlich interpolierbar.

Logisches NICHT ist, wie die anderen logischen Ausdrücke, nicht interpolierbar.

Bitweises invertieren ist nur für Integer-Werte sinnvoll und damit nicht interpolierbar.

\paragraph{Eingebaute Funktionen:} \label{split_builtins}
Skalarprodukt, Vektorprodukt und Matrixmultiplikation lassen sich alle mit arithmetischen Basisoperationen darstellen.
Da in diesen Darstellungen jeweils auch die Multiplikation enthalten ist, ergeben sich die oben genannten Beschränkungen:
diese Operationen sind nur interpolierbar, wenn mindesten ein Operand in der Objektberechnung bestimmt wurde.

Potenzierung ist im Allgemeinen keine stetige Funktion und damit nicht interpolierbar.

Die Berechnung von "`Normalisierung"' und "`Euklidische Länge"' erfordert das Ziehen einer Wurzel bzw. Potenzieren mit $\frac{1}{2}$.
Damit sind diese Funktionen ebenfalls nicht interpolierbar.

Minimum und Maximum sind im Allgemeinen keine stetigen Funktion und damit nicht interpolierbar.

Die Texturfunktionen sind prinzipbedingt nicht interpolierbar.

\subsection{Ablauf der Auftrennung}
\label{auftrennung_ablauf}

\subsubsection{Prinzipieller Ablauf}
%Kern: auf Sequenzen 
% für Register gespeichert, in welchen Prog. berechnet
% für jede Sequenzop. entschieden, welche Ausgabeprogramme
% Sonderbehandlung: Verzw., Schleifen
% Funktionen: generiert mehrere Varianten einer Funktion, abh. davon, wie Parameter vorliegen

%Bei der eigentlichen Auftrennung eines Programms 
Die Auftrennung wird auf des Basis von Sequenzen vorgenommen. Für jede Sequenzoperation wird nacheinander
entschieden, in welchen Ausgabeprogrammen es berechnet sie kopiert werden soll. Für das Ergebnisregister
wird vermerkt, in welchen Ausgabeprogrammen es berechnet wurde -- diese Information wird für
die "`Auftrennung"' nachfolgender Operationen verwendet.

Die Auftrennung beginnt mit der Eintrittsfunktion des Programms. Für deren Eingabeparameter muss bereits bekannt und gegeben
sein, in welchen Ausgabeprogrammen sie verwendet werden können.

\subsubsection{Auftrennung einfacher Operationen}

Für einfache Operationen entscheidet die oben genannte "`Interpolierbarkeit"', in welche Ausgabeprogramme eine Operation ausgegeben wird.

\subsubsection{Auftrennung von Flusskontrolloperationen}

Neben mathematischen Ausdrücken kann ein aufzuspaltendes Programm auch Operationen der Flusskontrolle enthalten,
die ebenso auf mehrere Ausgabeprogramme aufgespaltet werden müssen.

Grundsätzlich richten sich die Ausführungsfrequenzen von den Ablaufsteuerungsoperationen nach den Frequenzen der 
"`eingebetteten"' Operationen. Im Gegensatz zu "`einfachen"' Operationen wird eine Ablaufsteuerungsoperationen meist
in mehrere oder alle Ausgabeprogramme übernommen, allerdings mit anderen "`eingebetteten"' Operationen.

\paragraph{Sequenzschachtelung:} Eine Sequenzschachtelungsoperation wird prinzipiell zu allen generierten Teilprogrammen hinzugefügt,
allerdings mit unterschiedlichen Sequenzen. Diese sind selbst das Ergebnis einer Aufspaltung der ursprünglichen Sequenz.

\paragraph{Verzweigung:} Eine Verzweigung besteht konzeptionell aus zwei inneren Sequenzen (für die jeweiligen Verzweigungsblöcke)
und einem bool'scher Bedingungswert, nach dessen Wert abhängig verzweigt wird.

Die beiden inneren Verzweigungssequenzen werden selbst aufgespalten.

Der bool'scher Bedingungswert kann entweder in der Objektberechnung oder in der Pixelberechnung bestimmt worden sein:
in der Objektberechnung, wenn er ein Objektattribut ist bzw. allein aus
Objektattributen berechnet wurde. In der Pixelberechnung, wenn er aus Werten berechnet wurden, die in anderen Berechnungsfrequenzen bestimmt wurden.
Aufgrund der Nicht-Interpolierbarkeit von Vergleichs- und Logikoperationen kann ein Bedingungswert nicht in der Vertexberechnung bestimmt worden sein.

Selbst wenn der Bedingungswert nur in der Pixelberechnung vorliegt, kann die Verzweigungsoperation nicht allein in der Pixelberechnung ausgeführt werden:
die Aufspaltung der Verzweigungsblöcke kann auch in in der Objektberechnung bzw. der Vertexberechnung auszuführende Sequenzen resultieren. Diese müssen als "`normale"'
innere Sequenzen, d.h. ohne Verzweigung, zu den Objekt- bzw. Vertexberechnungen hinzugefügt werden. In diesen Berechnungen werden also immer
die Vertexteile beider Verzweigungsblöcke ausgeführt. Zwischenergebnisse müssen an das Pixelprogramm übertragen und dort ausgewählt werden.

Von den Verzweigungsblöcken beschriebene Register sind immer nur in demselben Programm, in dem der Bedingungswerts bestimmt wurde, verfügbar:
Selbst wenn beide Verzweigungen bloss Operationen für die Vertexberechnung enthalten, sind durch die Auswahl nach einer in der Pixelberechnung vorliegenden Bedingung
die berechneten Wert in der Pixelberechnung verfügbar.

\paragraph{Schleife:} Eine Schleifenoperation besteht aus einer inneren Sequenz (dem Schleifenrumpf) sowie
einem booleschem Bedingungswert, der Schleifenbedingung.

Wie bei der Verzweigung kann der boolescher Bedingungswert nur entweder in der Objektberechnung oder in der Pixelberechnung bestimmt worden sein.

Bei der Bestimmung, in welcher Frequenz einzelne Operanden im Schleifenrumpf vorliegen,
ergibt sich das Problem, dass die Teilprogramme, in denen ein Register verfügbar ist, von der Anzahl der Schleifendurchläufe
abhängt: z.B. kann eine Multiplikation eines Registers mit einem in der Vertexberechnung vorliegendem Wert im ersten Durchlauf
eine interpolierbare Operation sein, im zweiten Durchlauf aber nicht mehr, wenn dem Register ein bloss in der Vertexberechnung 
verfügbares Ergebnis aus dem vorherigen Durchlauf zugewiesen wurde.
Um eine "`stabile"' Verfügbarkeit von Registern, die von vorherigen Schleifendurchläufen abhängen, zu ermitteln,
werden zwei Schleifendurchläufe\footnote{Zwei Durchläufe sind ausreichend, da ein Register
nach höchstens zwei Schritten in der höchsten Frequenz verfügbar ist -- von Objekt auf Vertex bzw. von Vertex auf Pixel.}
simuliert und die damit bestimmten Verfügbarkeiten für das Aufspalten des Schleifenrumpfes verwendet.

Teile des Rumpfes können in der Objektberechnung oder der Vertexberechnung ausgeführt werden, wenn die Operationen nicht von vorhergegangenen Schleifendurchläufen
abhängen. Ein Ausführen von Operationen in der Objektberechnung oder der Vertexberechnung, die eine solche Abhängigkeit besitzen, wäre problematisch: es müsste bekannt sein, wieviele Werte vom
Objekt- bzw. Vertexprogramm zum Pixelprogramm übertragen werden sollen. Dies hängt von der Anzahl der Schleifendurchläufe ab,
welche im Allgemeinen nicht zur Übersetzungszeit bestimmt werden kann.
Ausführen von "`echten"' Schleifen ist also nur komplett in der Objektberechnung oder der Pixelberechnung möglich.
%Schleifenoperationen können also nur komplett per Mesh oder per Fragment ausgeführt werden.

\paragraph{Funktionsaufruf:} Der Rumpf einer Funktion ist eine Sequenz,
kann also prinzipiell in einen Teil für die Objektberechnung, einen Teil für die Vertexberechnung und einen Teil für die Pixelberechnung aufgespalten werden.
Das Hauptproblem besteht dabei darin, dass die Verfügbarkeit der Funktionsparameter je nach Aufruf variieren können.

Dies wird gelöst, in dem für eine Funktion bei der Aufspaltung mehrere Varianten generiert werden: bei einem Funktionsaufruf
wird die Funktion aufgespalten, mit den jeweiligen Verfügbarkeiten der übergebenen aktuellen Parameter. Wird die gleiche Funktion
nochmals aufgerufen, aber mit einer anderen "`Signatur"' von Verfügbarkeiten, so wird die Funktion in neue Varianten aufgespalten usw.

Die Verfügbarkeiten von Ausgabeparametern hängen von den Verfügbarkeiten der Eingabeparameter ab, können aber nach dem Aufspalten
einer Variation bestimmt werden.

Das Übertragen von Zwischenwerten einer Funktionsvariation vom Teil der Vertexberechnung zum Teil der Pixelberechnung geschieht über generierte Ausgabe- bzw.
Eingabeparameter; die eigentliche Übertragung geschieht schlussendlich in der Eintrittsfunktion.

%Rekursionen müssen besonders behandelt werden:
Für Rekursionen ergibt sich folgendes Problem:
um die korrekten Verfügbarkeiten der Ausgabeparameter zu bestimmen
muss eine Funktion zunächst aufgespalten werden. Im Falle einer Rekursion wird möglicherweise aber genau die angetroffene
Variante gerade selbst aufgespalten -- die Verfügbarkeiten sind also noch nicht bekannt, der Versuch einer Aufspaltung der
angetroffenen Variante würde über kurz oder lang zum exakt selben Problem führen.

Dieses Problem wird vermieden, in dem rekursive Funktionen besonders behandelt werden: im Wesentlichen wird angenommen,
dass bei einem festgestelltem rekursiven Aufruf die Ausgabeparameter nur in der Pixelberechnung verfügbar sind.
Mit dieser konservativen Annahme kann der Rumpf einer rekursiven Funktion aufgespalten werden.

% Behandlung von: arithm. Ausdr., Logik, Vergl, Unäre Ausdr., Verzweigungen, Schleifen, Funktionen

% Array-Operationen: evtl. nur per Fragment? (bei dyn. Arrays)

% 'Trivial': Zuweisung, Konstante, Typumwandlung, Vektor-Erstellung/-Extraktion, [Array-Erstellung/-Extraktion/-Änderung/-Länge,?]
% 

\subsubsection{Auftrennung von Array-Operationen}

Array-Operationen sind nur interpolierbar, wenn die Länge des Arrays \emph{statisch konstant}
bekannt (also auch kein Objektattribut) ist und bei der Array-Extraktion bzw. \mbox{-Än}\-de\-rung der verwendete Index 
in der Objektberechnung verfügbar ist. Dementsprechend können Array-Operationen nur in der Vertexberechnung ausgeführt werden,
wenn wenigstens auch dass Array, mit dem gearbeitet wird, eine statisch konstante Länge besitzt.
Bei Änderungen von Arrayelement muss ausserdem der zugewiesene Wert in der Vertexberechnung berechnet worden sein.

\subsubsection{Andere Operationen}

Zuweisungen, Konstantenoperationen, Typumwandlung, die Erstellung eines Vektors sowie
die Extraktion einer Komponente können trivialerweise mit derjenigen Frequenz berechnet werden, die der höchsten
der Frequenzen,  in denen die Eingaben berechnete wurden, entspricht.

\subsection{Beispiel}

Ein einfaches Beispiel soll die Ausgabe des Splitters demonstrieren.

\subsubsection{Eingabeprogramm}

Als Eingabe dient das einfache Shading-Programm aus Abbildung~\ref{fig:simple_s1}.
Es basiert auf dem Beispiel in Abbildung~\ref{fig:simple_cg} -- dessen Vertex- und Pixel-Teil wurden hier zusammengeführt.

Das Programm berechnet eine Beleuchtungsintensität für eine Lichtquelle mit konstanter Richtung des Lichteinfalls (also eine Lichtquelle im
Unendlichen) und gegebener Farbe. Diese Beleuchtungsintensität mit der ``ambient''-Farbe (eine Annäherung von "`Streulicht"')
zu einer Gesamtintensität addiert. Diese wird dann mit einer aus einer Textur ausgelesenen Oberflächenfarbe moduliert.

In der Abbildung wurde (manuell) markiert, in welchen Frequenzen die Eingabeparameter vorliegen,
sowie die Frequenz, in der die einzelnen Ausdrücke ausgeführt werden müssten.

% Beispiele
\begin{figure}[ht]
  \input{simple_s1}
  \caption{Ein Programm in der Shading-Sprache.}
  \centering
  \small Markierung der Operationen bzw. Werte gibt an, mit in welchem Berechnungsschritt diese ausgeführt bzw. berechnet werden.
  (\freqPerMesh{Objekt}, \freqPerVert{Vertex}, \freqPerFrag{Pixel})
  \label{fig:simple_s1}
\end{figure}

\subsubsection{Auftrennung}

Die für die Ausdrücke anzuwendenen Aufspaltungsregeln sind:

\paragraph{\texttt{outPosition}}: \texttt{Position} liegt ist der Wert eines Vertexattributs vor, der Gesamtausdruck muss daher mindestens 
in der Vertexberechnung berechnet werden. \texttt{ModelViewProj} ist ein Objektattribut, die Matrixmultiplikation ist interpolierbar,
der Gesamtausdruck kann daher auch in der Vertexberechnung berechnet werden und muss nicht in der Pixelberechnung berechnet werden.

\paragraph{\texttt{ambient}}: Konstante, wird daher als Objektattribut betrachtet.

\paragraph{\texttt{diffuse}}: Das Skalarprodukt zwischen \texttt{LightDirObj} und \texttt{Normal} muss, da \texttt{Normal} der Wert eines Vertexattributes ist,
mindestens in der Vertexberechnung berechnet werden. \texttt{LightDirObj} ist ein Objektattribut, das Skalarprodukt ist also interpolierbar,
kann daher auch in der Vertexberechnung berechnet werden und muss nicht in der Pixelberechnung berechnet werden.

Ebenso ist die Multiplikation von \texttt{LightColor} und dem Skalarprodukt interpolierbar, der Gesamtausdruck kann also
in der Vertexberechnung berechnet werden und muss nicht in der Pixelberechnung berechnet werden.

\paragraph{\texttt{litColor}}: Da \texttt{diffuse} in der Vertexberechnung vorliegt, \texttt{ambient} ein Objektattribut ist, und weiterhin
Additionen uneingeschränkt interpolierbar sind, kann der Gesamtausdruck in der Vertexberechnung berechnet werden und muss nicht in der Pixelberechnung berechnet werden.

\paragraph{\texttt{outColor}}: Da \texttt{litColor} in der Vertexberechnung bestimmt wurde wird
auch das Erstellen eines \texttt{float4}-Vektors aus \texttt{litColor} in der Vertexberechnung vorgenommen.

Das Auslesen des Oberflächenmusters mit \texttt{tex2D} kann nur in der Pixelberechnung erfolgen. Damit muss auch die Multiplikation des Texturwertes mit
dem \texttt{float4}-Vektor in der Pixelberechnung erfolgen.

\subsubsection{Ausgabe}

Abbildungen~\ref{fig:simple_s1_split_vp} und~\ref{fig:simple_s1_split_fp} enthalten das Ergebnis nach Aufspaltung in Zwischencoderepräsentation.
(Vor oder nach der Aufspaltung wurden keine Optimierungen angewendet.)

%Die erste Hälfte stellt das Vertexprogramm dar. Direkt Ergebnisse der Aufspaltung sind:
Die Aufspaltung wirkt sich auf alle Aspekte der Programme aus:
\begin{itemize}
\item \emph{Eingabeparameter:} Im Vertexprogramm sind alle Eingabeparameter des Originalprogramms erhalten,
auch \texttt{Texture}, welches nur im Pixelprogramm ausgelesen wird.

Bei den Eingabeparametern des Pixelprogramms fehlen die als Werte von Vertexattributen vorliegenden Eingaben -- diese werden
stattdessen vom Vertexprogramm weitergegeben ("`Übertragene Register"'). Allerdings gibt es auch
hier "`unnötige"' Eingaben, wie \texttt{ModelViewProj}. 

\item \emph{Ausgabeparameter:} Dies sind die vom jeweiligen Verarbeitungsschritt zu berechnenden Ausgaben --
die projizierte Vertex-Position im Falle des Vertexprogramms bzw. die finale Pixelfarbe im Falle des
Pixelprogramms.

\item \emph{Übertragene Register:} Die "`Schnittstelle"' zwischen Vertex- und Pixelprogramm.
Dabei enthält $\sOreg{m\_TexCoord\_B0}$ den Wert des Eingabeparameters \texttt{TexCoord}, der als Wert eines Vertexattributs vorliegt,
aber nur im Pixelprogramm verwendet wird. $\sOreg{i\_tmp12}$ das Ergebnis der Beleuchtungsberechnung
-- der rechte Faktor in der abschliessenden Multiplikation nach \texttt{outColor} --
welches im Pixelprogramm mit der aus dem Oberflächenmuster ausgelesenen Farbe multipliziert werden soll.

Der Aufspalter hat diese Register zur Übertragung ausgewählt, da deren Werte in der Vertexberechnung bestimmt wurden,
aber im Pixelprogramm verwendet werden.

\item \emph{Operationen:} Der Splitter hat die in der Vertexberechnung und per in der Pixelberechnung auszuführenden Operationen
genau so aufgeteilt, wie es nach der manuellen Klassifizierung im Eingabeprogramm zu erwarten war.
Die in der Objektberechnung zu berechnenden Operationen wurden, wie in Abschnitt~\ref{splitter_Berechnungsfrequenzen}
beschrieben, sowohl in das Vertex- wie auch das Pixelprogramm ausgegeben. In diesem Fall ist dies
nur die Zuweisungen von $\sOreg{v\_ambient}$ und $\sOreg{i\_tmp11}$. Diese Werte werden im Pixel-Programm nicht verwendet,
die Operationen selbst bleiben aber in diesem Fall wegen nicht vorgenommener Optimierungen dort erhalten.

\end{itemize}

\begin{figure}[h!t]
  \centering
  \input{simple_s1_split_vp}
  \caption{Vertexprogramm aus \ref{fig:simple_s1} nach der Aufspaltung.}
  %\small Operationen und Werte sind von der Berechnungsfrequenz abhängig markiert (\freqPerMesh{Mesh}, \freqPerVert{Vertex}, \freqPerFrag{Fragment})
  \label{fig:simple_s1_split_vp}
\end{figure}

\begin{figure}[h!t]
  \centering
  \input{simple_s1_split_fp}
  \caption{Pixelprogramm aus \ref{fig:simple_s1} nach der Aufspaltung.}
  %\small Operationen und Werte sind von der Berechnungsfrequenz abhängig markiert (\freqPerMesh{Mesh}, \freqPerVert{Vertex}, \freqPerFrag{Fragment})
  \label{fig:simple_s1_split_fp}
\end{figure}

% Abbildung~\ref{fig:simple_s1_images} visualisiert die Anteile der Berechnungen der verschiedenen Berechnungsfrequenzen
% an der finalen Pixelfarbe. Dafür wurde mit Hilfe des Compilers das Eingabeprogramm in ein Vertex- und Pixelprogramm
% in der Shadingsprache Cg übersetzt. Diese wurden für die Visualisierung der Anteil der Objektberechnungen bzw. Vertexberechnungen leicht bearbeitet
% um eben diese Anteile auszugeben. Die Bilder selbst wurden mit Hilfe eines kurzen, selbstgeschriebenen Programms erstellt,
% dass ein 3D-Dreiecksmodel mit Oberflächenmuster unter Verwendung der Shadingprogramme darstellt.

% Das erste Bild zeigt den Anteil der Objektberechnung (\texttt{ambient}) und zeigt dementsprechend eine durchgängige Färbung.

% Im zweiten Bild zeigt wurde der Anteil der Vertexberechnung (\texttt{litColor}) hinzugenommen. Es ist deutlich erkennbar,
% dass die Farbe über das Modell stark variiert und damit eine Beleuchtung aus der rechten oberen Richtung suggeriert.
%Allerdings sind auch Facettierungen von der Vertexberechnung erkennbar (am deutlichsten auf dem Ausguss oder dem Henkel).

% Im dritten Bild wurde schliesslich auch der Anteil der Pixelberechnung hinzugenommen. Die Farbveränderung aus der "`Beleuchtung"'
% ist noch klar erkennbar, aber das Auslesen einer Oberflächenfarbe aus einer Textur fügt weitere visuelle Details hinzu.
%und reduziert die Sichtbarkeit der Facettierungen.

Abbildung~\ref{fig:simple_s1_images} visualisiert die Anteile der Berechnungen der verschiedenen Berechnungsschritte
an der finalen Pixelfarbe. Dafür wurde mit Hilfe des Compilers das Eingabeprogramm in ein Vertex- und Pixelprogramm
in der Shadingsprache Cg übersetzt. Diese Ausgabeprogramme sind semantisch äquivalent zum Beispielprogramm aus
Abbildung~\ref{fig:simple_cg} -- dementsprechend sind auch die Bilder identisch zu denen in Abbildung~\ref{fig:simple_cg_images}.

Abbildung~\ref{fig:simple_s1_images}(a) zeigt den Anteil der Objektberechnung (\texttt{ambient}) und zeigt dementsprechend eine durchgängige Färbung.

Abbildung~\ref{fig:simple_s1_images}(b) zeigt wurde der Anteil der Vertexberechnung (\texttt{litColor}) hinzugenommen. Es ist deutlich erkennbar,
dass die Farbe über das Modell stark variiert und damit eine Beleuchtung aus der rechten oberen Richtung suggeriert.
%Allerdings sind auch Facettierungen von der Vertexberechnung erkennbar (am deutlichsten auf dem Ausguss oder dem Henkel).

Im Abbildung~\ref{fig:simple_s1_images}(c) wurde schließlich auch der Anteil der Pixelberechnung hinzugenommen. Die Farbveränderung aus der "`Beleuchtung"'
ist noch klar erkennbar, aber das Auslesen einer Oberflächenfarbe aus einer Textur fügt weitere visuelle Details hinzu.
%und reduziert die Sichtbarkeit der Facettierungen.

\begin{figure}[h]
  \centering
  (a) \includegraphics[width=4cm]{simple_s1_mesh}\qquad
  (b) \includegraphics[width=4cm]{simple_s1_vert}\qquad
  (c) \includegraphics[width=4cm]{simple_s1_frag}
  \caption{Programm aus \ref{fig:simple_s1}}
  \small (a) nur Anteil der Objektberechnungen an Pixelfarbe\\
  (b) zusätzlich mit Anteil der Vertexberechnungen\\
  (c) vollständige Pixelfarbe\\
  \label{fig:simple_s1_images}
\end{figure}

% Force figures to appear before section
\clearpage
\section{Optimierer}

\newcommand\OptSampleStacked[4]{
  \begin{figure}[!h]
    \centering
    \lstinputlisting{s1source/opt_ex/#1.s1}
    \caption{#2.}
    \label{fig:ir_optex_#1_in}
  \end{figure}
  \begin{figure}[!h]
    \centering
    \include{s1latex/opt_ex/#1_unopt}
    \caption{#3.}
    \label{fig:ir_optex_#1_unopt}
  \end{figure}
  \begin{figure}[!h]
    \centering
    \include{s1latex/opt_ex/#1_opt}
    \caption{#4.}
    \label{fig:ir_optex_#1_opt}
  \end{figure}
}

Die Aufgabe eines \emph{Optimierers} ist es, ein gegebenes Programm so umzuschreiben, dass es zur Laufzeit
schnellstmöglich ausgeführt wird. Im Allgemeinen erstrecken sich mögliche Optimierungen von Vereinfachungen,
wie ein Entfernen von unbenötigten Operationen und ein Berechnen von Ausdrücken zur Übersetzungszeit,
bis hin zu komplexen Umsortierungen oder Zusammenfassung von Operationen, z.B. um ``multiply-add''-Operation
besser auszunutzen.

Ein Optimierer, der Redundanzen u.ä. entfernt, erlaubt als Nebeneffekt auch, dass die vorhergehenden Arbeitsschritte
eines Compilers -- im vorliegenden Compiler insbesondere der Splitter --
nicht selbst optimalen Zwischencode erzeugen müssen. Die Implementierungen jener Arbeitsschritte kann damit
einfacher gehalten werden.

\subsection{Aufbau}

% Ein-, Ausgabe: Programme

Der Optimierer im vorliegenden Compiler nimmt als Eingabe ein komplettes Programm entgegen
und liefert als Ausgabe entsprechend auch ein komplettes Programm.

Das Arbeiten auf ganzen Programmen erlaubt es prinzipiell, funktionsübergreifende Optimierungen
vorzunehmen, von einem Entfernen unbenötigter Funktionen über ein Einbetten von Funktionsaufrufen bis zu einem Entfernen
einzelner, nicht benötigter Funktionsparameter.

Allerdings beschränken sich die implementierten, unten beschriebenen Optimierungen auf Sequenzen
von Operationen; diese Sequenzoptimierungen werden auf alle Funktionen eines Programms unabhängig
voneinander angewendet.

% mehrere Stufen
Die einzelnen Sequenzenoptimierungen werden nacheinander angewendet. Bei Bedarf kann eine
Optimierung mehrmals angewendet werden -- z.B. kann die Konstantenfaltung einen Ausführungszweig
einer Verzweigung auswählen; in diesem Fall wird eine erneute Blockauflösung veranlasst,
um die dadurch eingefügte Sequenzschachtelungsoperation zu vereinfachen.
% bei Bedarf mehrere Durchgänge -> z.B. erneutes BI when CF einen Branch o.ä. "geinlined" hat

\subsection{Blockauflösung}

% 'entfernt' Block-Seqop.
Die \emph{Blockauflösung} ersetzt alle Sequenzschachtelungsoperationen einer Sequenz durch
die in der inneren Sequenz enthaltenen Operationen. Dabei werden die von den
Operationen verwendeten bzw. veränderten Register angepasst: Register, die einem importiertem
oder exportiertem Namen zugeordnet sind, werden durch ihre Gegenstücke in der umgebenden
Sequenz ersetzt. Andere Register werden umbenannt um Kollisionen zu vermeiden.

% v.a. "Hilfsschritt" für andere Opt.
Die von der Blockauflösung vorgenommen Änderungen an einer Sequenz haben keine Auswirkungen auf das
Laufzeitverhalten des Programms. Dieser Optimierungsschritt dient vor allem als "`Hilfsschritt"',
um die Implementierungen anderer Optimierungsschritte zu vereinfachen: einerseits können
Sequenzschachtelungsoperationen als "`nicht vorhanden"' angenommen werden, andererseits kann
ein Auflösen von Blöcken -- z.B. wegen der statischen Auswahl eines Verzweigungsblockes --
einfach vorgenommen werden, da die nötige "`Hauptarbeit"' später vom Blockauflösungsschritt
vorgenommen wird.

Abbildungen~\ref{fig:ir_optex_bi_in} bis~\ref{fig:ir_optex_bi_opt} vergleichen ein einfaches Programm vor und nach der Anwendung der Blockauflösung.

\OptSampleStacked{bi}{Blockauflösung: Quellcode}{Blockauflösung: Zwischencoderepräsentation unoptimiert}{Blockauflösung: Zwischencoderepräsentation optimiert}

\subsection{Konstantenfaltung}

% Berechnung von konstanten Ausdrücken
% (Cast, Arithmetische, Logische, Unäre, Vergleichsop., Builtins, Arraylänge, Array getelem)
% Entfernung von Branches/Schleifen mit konst. Bedingung
\emph{Konstantenfaltung} berechnet das Ergebnis einer Sequenzoperation zur Übersetzungszeit
wenn alle Eingabeoperanden zur Übersetzungszeit bekannte Konstanten sind. Berücksichtigt
werden Zuweisungs-, Cast-, arithmetische, logische, unäre und Vergleichsoperationen, alle eingebauten
Funktionen (mit Ausnahme von Texturfunktionen) sowie die Operationen "`Arraylänge"' und
"`Extraktion eines Arrayelements"'.
Weiterhin werden Verzweigungsoperationen, deren Bedingung ein konstanter Wert ist,
durch eine Schachtelung der entsprechenden Sequenz ersetzt (die andere Sequenz wird verworfen).
Auch Schleifenoperationen, deren Schleifenbedingung den konstanten Wert "`falsch"' besitzt,
werden verworfen.

% Fkt.weise: speichert für jedes Reg., ob konst., und wenn ja, dessen Wert;
% Op. auf Konstanten zur Kompilierzeit berechnet
In der Implementierung der Konstantenfaltung wird eine Zuordnung zwischen Registern und konstanten
Werten verwendet; ist einem Register kein solcher Wert zugeordnet besitzt es keinen bekannten
konstanten Wert. Eine solche Zuordnung wird erstellt, wenn eine Operationen ein konstantes
Ergebnis hat. Dies sind zuvorderst Konstantenoperationen.
Bei Operationen, die einer der oben genannten Arten entsprechen, wird überprüft, ob alle Operanden
konstante Werte sind. Ist dies der Fall wird das Ergebnis der Operation vom Compiler berechnet
und die Operation durch eine einfache Konstantenoperation ersetzt.

% Zukunft: Funktionen mit rein konstanten Argumenten

Abbildungen~\ref{fig:ir_optex_cf_in} bis~\ref{fig:ir_optex_cf_opt} vergleichen ein einfaches Programm vor und nach der Anwendung der Konstantenfaltung.
Anzumerken ist, dass die Addition vom Compiler ausgerechnet und durch eine Konstantenoperation ersetzt
wird; die Konstantenoperationen der Quelloperanden bleiben jedoch erhalten - deren Entfernung ist
die Aufgabe der "`Entfernung unnötiger Operationen"', welche aber in diesem Beispiel nicht durchgeführt wurde.

\OptSampleStacked{cf}{Konstantenfaltung: Quellcode}{Konstantenfaltung: Zwischencoderepräsentation unoptimiert}{Konstantenfaltung: Zwischencoderepräsentation optimiert}

\subsection{Entfernung unnötiger Operationen}

Die "`\emph{Entfernung unnötiger Operationen}"' entfernt unnötige Sequenzoperationen; eine Operation ist "`unnötig"',
wenn keines der von ihr geschriebenen Register jemals benutzt wird.

% entfernt Op., deren Ergebnis nie benutzt wird

In der Implementierung werden die Operationen einer Sequenz \emph{von hinten} betrachtet.
Es wird eine Menge von "`ausgelesenen"' Registern gespeichert. Bei jeder Operation wird
zunächst überprüft, ob wenigstens eins der Ausgaberegister ein solches "`ausgelesenes"'
Register ist. Ist dies nicht der Fall, wird die Operation verworfen. Andernfalls wird
die Operation beibehalten und alle ihre Eingaberegister als "`ausgelesen"' markiert.

Die Menge der "`ausgelesenen"' Register benötigt eine anfängliche Menge von Registern, die als
benutzt angenommen werden  -- ohne diese würden alle Operationen einer Sequenz verworfen
werden. Dies sind immer die Ausgabeparameter der Funktion, die die zu optimierende Sequenz enthält.
Für Sequenzen, die z.B. in Verzweigungen eingeschachtelt sind, dient die Menge der
ausgelesenen Register der umgebenden Sequenz als anfängliche Menge benutzter Register.

% Fkt.weise: iteriert Operationen rückwärts
% speichert zu jedem Reg., ob gelesen
% verwirft Op., deren Zielregister nie gelesen wurde
% verwirft Blöcke, bei denen kein "exportiertes" Register gelesen wurde
% verwirft Fkt.aufrufe, bei denen kein Ausgabereg. gelesen wurde
% benötigt "Saat-Register" (Ausgabeparameter)

Abbildungen~\ref{fig:ir_optex_dce_in} bis~\ref{fig:ir_optex_dce_opt} vergleichen ein einfaches Programm vor und nach der Anwendung der Entfernung unnötiger Operationen:
die Ergebnisse einiger Operationen im Programm~\ref{fig:ir_optex_dce_in} werden offentsichtlich nicht verwendet.
Im optimierten Ausgabeprogramm~\ref{fig:ir_optex_dce_opt} wurden diese Operationen entfernt, und nur die Berechnungen,
die für die Werte der Ausgabeparameter nötig sind, sind erhalten.
% Dargestellt sind die Zwischencoderepräsentationen nach der Aufspaltung des Programms.
% In den unoptimierten Programmen werden beide Ausgabeparameter sowohl in Vertex- als auch Pixelprogramm
% beschrieben, obwohl jeweils nur einer tatsächlich verwendet wird. Aus den optimierten Programmen wurde die jeweils unnötige
% Zuweisung entfernt.

\OptSampleStacked{dce}{Entfernung unnötiger Operationen: Quellcode}{Entfernung unnötiger Operationen: Zwischencoderepräsentation unoptimiert}{Entfernung unnötiger Operationen: Zwischencoderepräsentation optimiert}

\clearpage
\section{Code-Generator}

Der \emph{Code-Generator} übersetzt ein in der Zwischencoderepräsentation vorliegendes Programm in eine \emph{Zieldarstellung}.
Diese "`Darstellung"' kann wieder eine Hochsprache sein, prinzipiell kann ein Code-Generator aber auch Assembler-Quelltext oder eine
Binärformat ausgeben.

\subsection{Eingaben und Aufgaben}

Der \emph{Code-Generator} erhält als Eingabe eine Liste von Funktionsbeschreibungen.
Eine Funktionsbeschreibung besteht aus dem eindeutigen Bezeichner, einer Liste von Parametern (getrennt nach Ein- und Ausgabeparametern)
und einer Sequenz mit den eigentlichen Operationen. Eine Funktion aus der Liste ist als "`Eintrittsfunktion"' markiert.

\begin{figure}[h]
   \centering
  \includegraphics{ir_program}
  \caption{Zusammensetzung eines Programms in der Zwischencoderepräsentation}
  \label{fig:ir_program}
\end{figure}

\newpage
Die Aufgaben des Code-Generators bestehen aus:
\begin{itemize}
\item Nötige Umformungen für die Zieldarstellung -- z.B. Schleifen ausrollen oder "`Einbettung"' von Funktionen.
\item Übertragung der Funktionsbeschreibungen in eine entsprechende Deklaration in der Zieldarstellung.
\item Übersetzung der Sequenzoperationen in die Zieldarstellung. 
\item Ressourcenallokation, wenn nötig (z.B. bei begrenzter Registerzahl in der Zieldarstellung).
\item Generierung von "`Schnittstellen-Anweisungen"' wie z.B. bei der Übergabe von Parametern an Funktionen
oder die Behandlung von Werten "`vor dem ersten Durchlauf, nach dem ersten Durchlauf"' wie sie bei Schleifen
auftreten.
\end{itemize}

\subsection{Generator für Cg}

%\renewcommand{\baselinestretch}{1.40}\normalsize
In der vorliegenden Implementierung wurde als Zieldarstellung die Sprache Cg~(\cite{cgpaper}, \cite{cg_home}) gewählt.

Cg als Hochsprache kennt selbst Konstrukte wie Funktionen und Schleifen. Umformungen durch den Codegenerator
sind also nicht nötig.

Jede Funktion wird also direkt auf eine Cg-Funktion abgebildet.

Jedem Register der Zwischencoderepräsentation wird eine Variable zugeordnet -- eine Re\-gis\-ter\-al\-lo\-ka\-tion ist unnötig, diese wird später vom Cg-Compiler selbst vorgenommen.
"`Einfache"' Sequenzoperation (arithmetische Operationen u.ä.) lassen sich auf einen einzelnen Cg-Befehl übertragen. 
Weiterhin werden die meisten eingebauten Funktionen und Attribute direkt von Cg unterstützt (Ausnahme ist das Matrix-Attribut \texttt{inverted}).

Kompliziertere Operationen -- Verzweigungen, Schleifen, Funktionsaufrufe -- resultieren in mehreren Statements, obwohl es sich bei dem
zusätzlichen "`Aufwand"' meist nur um Zuweisungen zwischen Variablen handelt, wie z.B. die Auswahl des Bedingungsregisters basierend zwischen
den Wert vor und nach dem ersten Schleifendurchlauf.

Die spezifizierte Sprache unterstützt Zeichenketten aus Unicode-Buchstaben und -Ziffern als Bezeichner;
Cg nur eine Untermenge von ASCII. Für die Ausgabe als Cg-Code werden Bezeichner in eine Darstellung in der akzeptieren
Zeichenmenge umgewandelt\footnote{Als Kodierung wurde Punycode~(\cite{rfc3492}) gewählt da dies die aus ASCII bestehenden Teile eines Bezeichners
gut lesbar lässt.}.

% Original-Schnipsel und Generator-Output
%\defltbaselinestretch\normalsize

%\newpage
\section{Zusammenfassung}

Grundsätzlich folgt der Aufbau des Compilers der Standardarchitektur; die Abweichnung ist der Verarbeitungsschritt der "`Auftrennung"' in mehrere
Programme.

Die Auftrennung nutzt dabei Eigenschaften von GPUs aus, deren Aufbau auf den Ablauf des Echtzeit-3D-Renderings abgestimmt ist.
Speziell werden Operationen in der Vertex- statt Pixelberechnung ausgeführt, sofern das Ergebnis zur ursprünglichen Operation mathematisch äquivalent ist
(unter Berücksichtigung der von der GPU vorgenommen Interpolation von Ausgaben der Vertexberechnung).

Auch hervorzuheben ist die verwendete Zwischencoderepräsentation, die als Übergabeformat zwischen allen Verarbeitungsschritten von der
semantischen Analyse bis zur Codegenerierung dient. Weiterhin ist sie darauf ausgerichtet, die Implementierung von Optimierungsschritten
möglichst zu vereinfachen.

\chapter{Evaluation}

\newcounter{program}
\newcommand\prglisting[3]{\refstepcounter{program}\label{#1}#3\vspace{-1.5em}\begin{center}{\small Programm \arabic{program}: #2}\end{center}}

% zZ:
% - Verhalten bei Prog. mit Viel Logik in VP
% - Verhalten bei Prog. mit Viel Logik in FP
% - Was mit Schleifen
% - Was mit Arrays
% - Was mit Funktionen

In diesem Kapitel sollen Verhalten und Ausgabe des Compilers bewertet werden.

Um möglichst praxisnahe Fälle zu betrachten wurden die Programme, anhand derer die Bewertungen vorgenommen werden,
aus existierenen Cg-Programmen "`erstellt"'; dazu wurden die als separate Vertex- und Pixelprogramme vorliegenden
Quellen in Programme der zu übersetzenden Shadingsprache umgewandelt\footnote{Wegen der großen syntaktischen Ähnlichkeiten
konnte dies größtenteils durch Kopieren von Quelltextblöcken vorgenommen werden.} und anschliessen vom Compiler übersetzt.
Die Ausgabe des Compilers, die "`generierten Programme"', sind wiederum Cg-Programme. Zur Überprüfung der syntaktischen Korrektheit wurden die
generierten Programme mit dem Cg-Compiler \verb+cgc+ übersetzt (alle generierten Programme wurden fehlerfrei übersetzt,
sind also syntaktisch korrekt). Schliesslich wurden, zur Effizienzbewertung, ursprüngliche
wie auch generierte Cg-Programme durch den Cg-Compiler in eine Assembler-artige Shadingsprache übersetzt und diese jeweiligen Ausgaben miteinander verglichen.

Die Ausgabe-Programme des entwickelten Compilers können, da diese ja selbst Cg-Programme sind, mit der Eingabe prinzipiell direkt verglichen
werden. Praktisch werden Vergleiche dadurch erschwert, dass die ausgebenen Programme prinzipbedingt drastisch anders formatiert sind, Variablen andere Namen als in den Eingabeprogrammen besitzen usw.

Folgende Aspekt wurden im Vergleich von Eingabe- und Ausgabeprogrammen betrachtet:
\begin{itemize}
\item Grundsätzliche \emph{Semantische Äquivalenz} der beiden Programme. Diese ist von höchster Wichtigkeit.
\item \emph{Effizienz} des Ausgabeprogrammes, Wirksamkeit von Optimierungen: das Ausgabeprogramm sollte keine unnötigen Operationen enthalten und
es sollten möglichst wenige Werte vom Vertexprogramm ausgegeben werden.
\end{itemize}

Die meisten der verwendeten Eingabe-Cg-Programme stammen aus dem Buch ``The Cg Tutorial'' (\cite{cg_tutorial}).
Die Programme wurden ausgewählt, da sie einerseits Einführungs-Charakter besitzen -- sie sind vergleichsweise einfach aufgebaut --
aber andererseits ohne Weiteres praktisch einsetzbar sind.

% C5E1v_basicLight
% C5E2v_fragmentLighting , The C5E3f_basicLight
% C5E4v_twoLights

% Listings nummerieren
% Zeilennummern

\section{Beispielprogramm}

Das erste betrachtete Programm ist das in der Einführung verwendete Beispielprogramm (Abbildung~\ref{fig:simple_cg}):
es berechnet für jedes Vertex des Modells einen Beleuchtungswert; dieser wird über die Pixel der ausgebenen
Dreiecke (implizit) interpoliert. Weiterhin wird für jedes Pixel eine "`Materialfarbe"' aus einem Oberflächenmuster gelesen und
mit dem Beleuchtungswert moduliert.

% Kurz: was es macht

\prglisting{lst:example_cg}{Ursprüngliches Programm in Cg (Vertex- und Pixelprogramm)}
{\lstinputlisting[basicstyle=\ttfamily\scriptsize,numbers=left,breaklines,xleftmargin=1cm]{eval/simple.cg}}

\prglisting{lst:example_s1}{Eingabeprogramm für den Compiler in der Shadingsprache}
{\lstinputlisting[basicstyle=\ttfamily\scriptsize,numbers=left,breaklines,xleftmargin=1cm]{eval/simple.s1}}

\prglisting{lst:example_compiled}{Ausgabe des Compilers in Cg}
{\lstinputlisting[basicstyle=\ttfamily\scriptsize,numbers=left,breaklines,xleftmargin=1cm]{eval/simple_compiled.cg}}

\subsubsection*{Bewertung}
\paragraph{Semantik:} Sowohl das ursprüngliche Cg-Programm wie auch die Ausgabe des Compilers sind semantisch
äquivalent.

In den Vertexprogrammen (\verb+vertex_main+ in Programm~\ref{lst:example_cg}, \verb+vertex_main_+ in Programm~\ref{lst:example_compiled}) werden die Ausgabeposition (\verb+output.Position+ bzw. \verb+ooutPosition_+) sowie 
der Beleuchtungswert (\verb+output.litColor+ bzw. \verb+v_litColor1_cqa_+) berechnet. Die Zuweisung der Bildkoordinate des Musters
(\verb+TexCoord+ bzw. \verb+iTexCoord_+) an eine Ausgabe des Vertexprogramms (\verb+output.TexCoord+ bzw. \verb+v2f.m_TexCoord_B0_+)
wurde für das Ausgabeprogramm vom Compiler automatisch generiert. Die Ausgabe des generierten Vertexprogramms (die Struktur \verb+V2F+)
entspricht der Ausgabe des ursprünglichen Programms~\ref{lst:example_cg} (dort die Struktur \verb+VertexOutput+), allerdings wird die transformierte
Vertex-Koordinate beim generierten Vertexprogramm (\verb+vertex_main_+ in Programm~\ref{lst:example_compiled}) als Ausgabeparameter \verb+ooutPosition_+ anstatt als
Element der Struktur \verb+V2F+ ausgegeben.

Im ursprünglichen Pixelprogramm (\verb+pixel_main+ in Programm~\ref{lst:example_cg}) 
wie auch generierten Pixelprogramm (\verb+fragment_main_+ in Programm~\ref{lst:example_compiled}) werden die gleichen Operationen vorgenommen:
ein Auslesen eines Farbwertes aus dem Oberflächenmuster (\verb+surface+ bzw. \verb+v_surface_+)
und eine Modulierung der Oberflächenfarbe mit dem Beleuchtungswert (\verb+outColor+ bzw. \verb+ooutColor_+).

\paragraph{Effizienz:} Der generierte Cg-Code (Programm~\ref{lst:example_compiled}) enthält einige unnötige Zuweisungen.
Diese werden von Eigenschaften der Zwischencoderepräsentation verursacht:
Für eine ``Swizzle''-Operation\footnote{Auswahl/Umordnung von Vektorkomponenten, siehe Abschnitt~\ref{Vektorattribute}}
werden mehrere Zwischencodeoperationen zum Extrahieren einzelner Komponenten generiert; mit diesen wird der Ergebnisvektor
konstruiert. Zeile 17 im Eingabeprogramm~\ref{lst:example_s1} ist eine solche ``Swizzle''-Operation,
Zeile 23 in Programm~\ref{lst:example_compiled} ist das Ergebnis der von dieser Operation verursachten Kombination von Zwischencodeoperationen.

Die Zuweisung von Teilkomponenten eines Vektors (Zeile 19 im Eingabeprogramm~\ref{lst:example_s1}) trägt eine Schwäche des Compilers 
bei solchen Zuweisungen zu Tage: die unveränderten Komponenten des zu verändernden Vektors werden extrahiert
und bei der Konstruktion des Ergebnisvektors benutzt. Grundsätzlich nötig, um den Wert der unveränderten Komponenten
zu erhalten, führt dieses Verhalten bei Vektoren mit undefinierten Komponenten dazu, dass undefinierte Werte für den neuen
Ergebnisvektor verwendet werden. Im Ausgabeprogramm~\ref{lst:example_compiled}, Zeile 26, ist der Wert
\verb+m_outColor_B0_.w+ ein solcher uninitialisierter Wert.

Verwendung undefinierter Werte ist mindestens unnötig, aber auch störend: der Cg-Compiler mahnt dies an.
Vermieden könnte diese Verwendung werden, in dem der Compiler oder Code-Generator verfolgt, welche
Register "`undefinierte"' Werte enthalten und mit Hilfe dieser Informationen den generierten Zwischencode bzw. Ausgabecode anpassen (z.B. durch Auslassung von Zuweisungen
von undefinierten Werten oder ein Ersetzen von undefinierten Vektorkomponenten durch einen beliebigen Wert).

Die Funktionen des generierten Programms werden mit Parametern deklariert, die von den Funktionen selbst nicht verwendet
werden (z.B. Parameter \verb+iLightColor_+ der Funktion \verb+fragment_main_+). Dies ist ein Ergebnis der Aufspaltung: diese
kopiert die Eingabeparameter einer aufzuspaltenden Eingabefunktionen einfach vollständig in alle aufgespalteten Ausgabefunktionen. Abhilfe würde ein
Optimierungsschritt schaffen, der für jeden Parameter einer Funktion überprüft, ob dieser tatsächlich verwendet wird und entsprechend
unbenutzte Parameter entfernt.

Praktisch führen die unnötigen Operationen allerdings nicht zu Nachteilen: der Cg-Compiler nimmt selbst Optimierungen
auf zu übersetzenden Programmen vor; dadurch führt ein Übersetzen des Ursprungsprogramms
sowie des generierten Programms mit dem Cg-Compiler zu identischen Ergebnisprogrammen.

% Semantik: gleich
% VP-Ausgabe: gleich
% Operationen:
% - einige unnötige Zuweisungen -> fehlende Optimierung
% - Verwendung eines uninit. Wertes (m_outColor_B0_.w) -> Zwischencode-Generierung, könnte wegoptimiert werden

\section{Einfache Beleuchtung für jedes Pixel}

% Neue Syntax: if

Dieses Programm berechnet nur einen Beleuchungswert und verwendet diesen als Oberflächenfarbe. Im Gegensatz zum
vorherigen Programm wird diese Beleuchtungsberechnung im Pixelprogramm vorgenommen.
Weiterhin ist die Beleuchtungsberechnung selbst komplexer.

\prglisting{lst:fraglight_cg_vp}{Beleuchtungsberechnung im Pixelprogramm: Vertexprogramm}
{\lstinputlisting[basicstyle=\ttfamily\scriptsize,numbers=left,breaklines,xleftmargin=1cm]{eval/C5E2v_fragmentLighting.cg}}

\prglisting{lst:fraglight_cg_fp}{Beleuchtungsberechnung im Pixelprogramm: Pixelprogramm}
{\lstinputlisting[basicstyle=\ttfamily\scriptsize,numbers=left,breaklines,xleftmargin=1cm]{eval/C5E3f_basicLight.cg}}

Die Eingabe-Cg-Programme verwenden keine Struktur, um die Ausgaben des Vertexprogramms bzw. Eingaben
des Pixelprogramms zu beschreiben, sondern eine explizite Zuordnung von Eingabe- bzw. Ausgabeparametern
zu "`Plätzen"' für interpolierte Werte -- Schlüsselwörter wie \texttt{COLOR} oder \texttt{TEXCOORD0} sorgen dafür,
dass eine interpolierte Ausgabe des Vertexprogramms dem Parameter des Pixelprogramms als Eingabe dient,
der mit dem gleichen Schlüsselwort markiert wurde (z.B. ist die Vertexprogrammausgabe \texttt{objectPos}
der Pixelprogrammeingabe \texttt{position} zugeordnet).

\prglisting{lst:fraglight_s1}{Eingabeprogramm für Compiler in der Shadingsprache}
{\lstinputlisting[basicstyle=\ttfamily\scriptsize,numbers=left,breaklines,xleftmargin=1cm]{eval/fragmentLighting.s1}}

\prglisting{lst:fraglight_compiled}{Ausgabe des Compilers in Cg}
{\lstinputlisting[basicstyle=\ttfamily\scriptsize,numbers=left,breaklines,xleftmargin=1cm]{eval/fragmentLighting_compiled.cg}}

\subsubsection*{Bewertung}
\paragraph{Semantik:}
%Sowohl das ursprüngliche Cg-Programm wie auch die Ausgabe des Compilers sind semantisch äquivalent.
Das Vertexprogramm des generierten Cg-Programms (Funktion \verb+vertex_main_+ in Programm~\ref{lst:fraglight_compiled})
ist ähnlich einfach wie das ursprüngliche Vertexprogramm~\ref{lst:fraglight_cg_vp}.
Allerdings unterscheiden sich die Ausgaben des Vertexprogramms: im ursprünglichen Programm
werden die Werte \verb+position+ und \verb+normal+ "`durchgeschleift"'. Im generierten Programm wird
dies mit zwar \verb+inormal_+ getan, statt dem Wert \verb+iposition_+ oder \verb+v_P_+ werden aber
Zwischenergebnisse von Berechnungen ausgegeben. Die Ursache dafür ist die Arbeitsweise des Aufspalters:
Zwischenwerte werden als Ausgabe des Vertexprogramms bzw. Eingabe des Pixelprogramms markiert,
sobald eine nicht interpolierbare Operation mit dem Zwischenwert vorgenommen wird.
Die Subtraktionen auf Zeilen 30 und 35 im Programm~\ref{lst:fraglight_s1} sind interpolierbar, werden
also in das Vertexprogramm ausgegeben. Die Funktion \verb+normalize+ allerdings nicht und 
muss in das Pixelprogramm ausgegeben werden -- die Argumente von \verb+normalize+, Werte \verb+i_tmp7_+ und
\verb+i_tmp16_+, werden also aus dem Vertexprogramm ausgegeben um als Eingabe des Pixelprogramms
zu dienen.

Im ursprünglichen Programm~\ref{lst:fraglight_cg_fp} hat die Verzweigung nur einen \verb+if+-Zweig; im generierten
Programm~\ref{lst:fraglight_compiled} wurde ein \verb+else+-Zweig hinzugefügt, da in der Zwischencoderepräsentation
der Variable \verb+specularLight+ des Eingabeprogramms wegen der Zuweisung ein neues Register zugeordnet wurde,
und der hinzugefügte \verb+else+-Zweig sicherstellt, dass dieses neue Register den "`alten"' Wert der Variable erhält,
sollte die Bedingung für die Verzweigung nicht eingetreten sein.

Generell finden sich alle Operationen der ursprünglichen Programme~\ref{lst:fraglight_cg_vp} und~\ref{lst:fraglight_cg_fp}
auch im Ausgabeprogramm~\ref{lst:fraglight_compiled}, wenn auch, bedingt durch die Arbeitsweise des
Compilers und Aufspalters, teilweise in anderer Reihenfolge und mit expliziten Zuweisungen von Zwischenwerten zu Variablen.

\paragraph{Effizienz:}
Wie im vorherigen Programm gibt es, aus den gleichen Gründen, wieder einige unnötige Zuweisungen,
unbenutzte Funktionsparameter und eine Verwendung eines undefinierten Wertes.

Im Vergleich zu den ursprünglichen Programmen~\ref{lst:fraglight_cg_vp} und~\ref{lst:fraglight_cg_fp}
wurden zwei Operationen aus dem Pixel- in das Vertexprogramm "`verschoben"'; vergleicht man
die Übersetzungsergebnisse des Cg-Compilers von ursprünglichem und generiertem Programm
so enthält das Ergebnis-Vertexprogramm eine zusätzliche Operation,
das Ergebnis-Pixelprogramm allerdings zwei Operationen weniger -- das vom Compiler generierte Programm
ist also leicht effizienter.

\section{Einfache Beleuchtung für jedes Vertex}

Diese Programm verwendet die gleiche Beleuchtsberechnung wie im vorherigen Programm; allerdings soll die Berechnung,
wie im ersten Beispielprogramm, für jedes Vertex berechnet werden und über die Ausgabepixel interpoliert werden.

\prglisting{lst:vertlight_cg_vp}{Beleuchtungsberechnung für jedes Vertex: Vertexprogramm}
{\lstinputlisting[basicstyle=\ttfamily\scriptsize,numbers=left,breaklines,xleftmargin=1cm]{eval/C5E1v_basicLight.cg}}

\prglisting{lst:vertlight_cg_fp}{Beleuchtungsberechnung für jedes Vertex: Pixelprogramm}
{\lstinputlisting[basicstyle=\ttfamily\scriptsize,numbers=left,breaklines,xleftmargin=1cm]{eval/C2E2f_passthru.cg}}

Die Berechnungen zur Beleuchtung stimmen mit denen aus Programm~\ref{lst:vertlight_cg_fp} überein,
finden sich aber hier im Vertexprogramm. Das Pixelprogramm gibt nur den Beleuchtungswert aus.

\prglisting{lst:vertlight_s1}{Eingabeprogramm für Compiler in der Shadingsprache}
{\lstinputlisting[basicstyle=\ttfamily\scriptsize,numbers=left,breaklines,xleftmargin=1cm]{eval/basicLight.s1}}

Dieses Programm ist mit dem Programm~\ref{lst:fraglight_s1} praktisch identisch.

\prglisting{lst:vertlight_compiled}{Ausgabe des Compilers in Cg}
{\lstinputlisting[basicstyle=\ttfamily\scriptsize,numbers=left,breaklines,xleftmargin=1cm]{eval/basicLight_compiled.cg}}

% Semantik: Beleuchtung in FP statt VP!
\subsubsection*{Bewertung}
\paragraph{Semantik:}
Im generierten Cg-Programm~\ref{lst:vertlight_compiled} findet sich die Beleuchtungsberechnung im
Pixelprogramm, statt im Vertexprogramm wie es in den ursprünglichen Programmen~\ref{lst:vertlight_cg_vp}
und~\ref{lst:vertlight_cg_fp} der Fall ist.

Verantwortlich dafür ist die Arbeitsweise des "`Splitters"'. Wie in Abschnitt~\ref{formulierte_frequenz} beschrieben,
werden die Eingabeprogramme so betrachtet, als würden sie Pixelberechnungen formulieren.
Nur unter gewissen Bedingungen ("`Interpolierbarkeit"', siehe Abschnitt~\ref{Interpolierbarkeit}) werden
Operationen in die Vertexberechnung verschoben. Diese Bedingungen sind im Eingabeprogramm nicht erfüllt --
der Compiler muss also die Mehrzahl der Operationen in die Pixelberechnungen ausgeben.

Um ein generiertes Programm zu erhalten, dass mit dem ursprünglichen Programmen übereinstimmt, wäre im Compiler ein Mechanismus
(Schlüsselwort o.ä.) nötig, um explizit anzugeben, dass eine Programmoperation in der Vertex- statt in der Pixelberechnung ausgeführt werden soll.
Der Splitter müsste entsprechend angepasst werden, um für solche markierten Operationen die "`Interpolierbarkeit"' als gegeben anzunehmen.

Abgesehen davon, dass die Beleuchtungsberechnung vom Splitter in das "`falsche"' Teilprogramm ausgegeben wurde,
stimmen die Operation selbst mit denen der ursprünglichen Programme überein.

\paragraph{Effizienz:}
Das Eingabeprogramm~\ref{lst:vertlight_s1} entspricht genau dem vorherigem Eingabeprogramm, dementsprechend treffen
die dort gemachten Effizienzbetrachtungen auch hier zu.

\section{Beleuchtung unter Verwendung zweier Lichtquellen}

Dieses Programm verwendet die gleichen Beleuchtungsberechnung wie die vorherigen zwei Programmen,
allerdings für zwei Lichtquellen.

% Neue Syntax: Array, Funktionen

\prglisting{lst:twolights_cg_vp}{Beleuchtung mit zwei Lichtquellen: Vertexprogramm}
{\lstinputlisting[basicstyle=\ttfamily\scriptsize,numbers=left,breaklines,xleftmargin=1cm]{eval/C5E4v_twoLights.cg}}

\prglisting{lst:twolights_cg_fp}{Beleuchtung mit zwei Lichtquellen: Pixelprogramm}
{\lstinputlisting[basicstyle=\ttfamily\scriptsize,numbers=left,breaklines,xleftmargin=1cm]{eval/C2E2f_passthru.cg}}

Die Beleuchtungsberechnung wurde in eine Funktion verschoben. Die Parameter der Lichtquellen werden als
Arrays übergeben.

\prglisting{lst:twolights_s1}{Eingabeprogramm für Compiler in der Shadingsprache}
{\lstinputlisting[basicstyle=\ttfamily\scriptsize,numbers=left,breaklines,xleftmargin=1cm]{eval/twoLights.s1}}

Die die Shadingsprache keine Verbundtypen kennt mussten diese in einzelne Variablen "`ausgepackt"' werden.
Die Größe der Eingabearrays wurde als Compiler-Option spezifiziert (hier nicht sichtbar).

\prglisting{lst:twolights_compiled}{Ausgabe des Compilers in Cg}
{\lstinputlisting[basicstyle=\ttfamily\scriptsize,numbers=left,breaklines,xleftmargin=1cm]{eval/twoLights_compiled.cg}}

\subsubsection*{Bewertung}
\paragraph{Semantik:}
Auch in diesem Programm wird, wie im vorherigen Programm, der Großteil der Berechnungen in das Pixelprogramm ausgegeben;
Grund ist auch die Arbeitsweise des Compilers.

Die Funktion \verb+C5E5_computeLighting+ des ursprünglichen Programms~\ref{lst:twolights_cg_vp} (Zeilen 20 bis 41)
findet ihre Entsprechung im generierten Programm~\ref{lst:twolights_compiled} in der Funktion der Zeilen 53 bis 80.
Diese Funktionen führen äquivalente Berechnungen durch, der "`Kern"' von ursprünglichem und generiertem Programm
stimmen also überein. 

Die Iterationen über die Lichtquellen sind im generierten Programm~\ref{lst:twolights_compiled} (Zeilen 92 bis 108)
als \verb+while+-Schleife ausgeführt, es ist aber einfach erkennbar, dass diese genauso oft und mit den gleichen
Werten für die Schleifenvariable \verb+i+ durchlaufen wird wie es im ursprünglichen Programm~\ref{lst:twolights_cg_vp} (Zeilen 67 bis 73)
der Fall ist.

\paragraph{Effizienz:}
Auffällig im generierten Programm~\ref{lst:twolights_compiled} ist die leere, nicht verwendete Funktion der Zeilen 7 bis 9:
hier hat der Splitter bei der Aufspaltung der Funktion \verb+C5E5_computeLighting+ des ursprünglichen Programms~\ref{lst:twolights_cg_vp}
eine Variante der Funktion für die Verwendung bei der Vertexberechnung (erkennbar am Präfix "`\verb+vertex_+"' des Funktionsbezeichners) ausgegeben.
Diese wurde aber letztendlich nicht verwendet: Grund dafür ist, dass die ursprüngliche Funktion in der Schleife verwendet wird;
Schleifen werden aber, wie in Abschnitt~\ref{auftrennung_ablauf} beschrieben, nie in die Vertexberechnung ausgegeben --
damit wird auch die Variante der Funktion für die Vertexberechnung nicht verwendet.

Solche unnötigen Funktionen könnten durch einen zusätzlichen Optimierungsschritt verhindert werden, der untersucht, welche
Funktionen eines Programms bzw. eines Teilprogramms tatsächlich verwendet werden und nicht verwendete Funktionen verwirft.

Praktisch, nach einer Übersetzung des generierten Programms mit dem Cg-Compiler, folgen aus dieser "`überflüssigen"' Funktion keine Nachteile:
der Cg-Compiler entfernt die nicht verwendete Funktion.

Wie beim vorherigen Beispielprogramm finden sich auch hier die Berechnungen im generierten Programm~\ref{lst:twolights_compiled} 
im Teilprogramm zur Pixelberechnung
statt, wie im ursprünglichen Programm~\ref{lst:twolights_cg_vp}, in der Vertexberechnung. Grund ist auch hier die Arbeitsweise des
Compilers. Damit ist auch die "`Lösung"' dieses Problems die Gleiche.

\section{Zusammenfassung}

Der Vergleich von "`realistischen"' Cg-Programmen mit der Ausgabe des Compilers, nachdem die Programme von Cg in die Shadingsprache
übersetzt wurden, zeigt, dass die Übersetzung prinzipiell semantisch übereinstimmende Programme erzeugen kann.

Eine Schwäche des Compilers ist dessen Korrektheit -- in dem Sinne, das Operationen nur für die Vertexberechnung ausgegeben werden,
wenn eine Interpolation der Ergebnisse der Vertexberechnung die gleichen Ergebnisse wie eine Ausführung in der Pixelberechnung hätte.
Damit wurden im direkten Vergleich bei einigen Programmen Operationen, die ursprünglich in der Vertexberechnung ausgeführt wurden,
in die Pixelberechnungen "`verschoben"'.

Weiterhin gibt es weiteren Bedarf für Optimierungen, von einer Entfernung nicht verwendeter Funktion über die Vermeidung unnötiger Zuweisungen
hin zu einer Entfernung nicht verwendeter Funktionsparameter. Zwar hat eine Ausgabe in die Sprache Cg den Vorteil, dass der
Cg-Compiler selbst noch Optimierungen vornimmt und damit die fehlenden Optimierungen des Shadingsprachen-Compilers dadurch wenig
ins Gewicht fallen, bei anderen Zielsprachen muss dies aber nicht der Fall sein -- weitergehende Optimierungen wären in solchen Fällen vorteilhaft.

% Ausgabe: äquivalent
% mehr Optimierungsbedarf (Cg-Compiler optimiert, bei anderen Backends womöglich nicht)
% mehr Kontrolle Vertex-/Pixelberechnung

\chapter{Ausblick}

% AST: nützlich, wenn FEs für anderen Sprachen, oder komplexer (Strukturen)
% Manuelles spezifizieren von per-Vertex Ops // keyword 'interpolate'

Die übersetzte Sprache ist eine zwar vergleichsweise einfache, aber grundsätzlich praktisch nutzbare
Shadingsprache, die es erlaubt, Shadingprogramme zu schreiben, ohne den Hardwareaufbau aus verschiedenen Funktionseinheiten
berücksichtigen zu müssen.

Die vom Compiler ausgegebenen Programme können grundsätzlich praktisch eingesetzt werden. Die Evaluation hat jedoch gezeigt,
das der Compiler-"`Prototyp"' einigen Anwendungsfällen nicht gerecht wird:
der in Abschnitt~\ref{Auftrennung} beschriebene "`Splitter"' arbeitet konservativ in dem Sinne, dass eine Operation nur in das Ausgabe-Vertexprogramm
"`verschoben"' wird, wenn das Ergebnis mathematisch äquivalent zu einer Berechnung im Ausgabe-Pixelprogramm wäre.
Praktisch sollen aber manchmal bewusst Ergebnisse approximiert werden, in dem Operationen während der Vertexberechnung ausgeführt werden
(aus Geschwindigkeitsgründen
bei komplexen oder oftmals verwendeten Programmen). Die Sprache sollte deswegen noch um ein Schlüsselwort o.ä. erweitert werden
welches ein manuelles Bestimmen der Berechnungseinheit für eine Operation erlaubt.

Viele Programmiersprachen unterstützen Verbundtypen. Dies wäre eine sinnvolle Spracherweiterung 
um das Erstellen von komplexeren Programmen zu vereinfachen. Auch praktisch nützlich wären die von anderen Shadingsprachen wie Cg, GLSL usw. meist bereitgestellten
Typen mit unterschiedlichen Genauigkeiten (wie ``half''- oder ``double precision''-Fließkommazahlen). Diese lassen den Programmierer, je nach Anforderungen,
zwischen Genauigkeit und Berechnungsgeschwindigkeit abwägen. 

Auch bieten sie anderen Shadingsprachen noch weitere "`Komfortfunktionen"' für oft verwendete
Berechnungen (z.B. für die lineare Interpolation von Werten oder Vektoren).  Diese können zwar prinzipiell mit den vorhandenen Operationen
und eingebauten Funktionen nachgebildet werden. Ein zur Verfügung stellen als eingebaute Funktion wäre jedoch für Benutzer der Sprache komfortabler.

Denkbar ist es auch, den Compiler so zu erweitern, dass Programme aus "`üblichen"' Shadingsprachen mit getrennten Vertex- und Pixelprogrammen
-- wie Cg -- akzeptiert werden. Die Ausgabe des Compilers wären funktional äquivalente Vertex- und Pixelprogramme,
allerdings mit einer potenziell besseren Verteilung von Operationen auf Verarbeitungseinheiten.

Bei der Implementierung besteht noch Verbesserungspotential im Aufspalter. 
Vor allem rekursive Funktionen werden nur im Pixelprogramm ausgeführt - dies stellt zwar ein korrektes
Ergebnis sicher, ist aber nicht in allen Fällen die optimale Lösung.

%Der Compiler selbst nimmt in der vorliegenden Implementierung noch keine Optimierungsschritte vor. In Anbetracht der bewussten Ausrichtung
%der Zwischencoderepräsentation auf möglichst einfache Optimierungen sowie die bei der Implementierung gemachten Annahmen (z.B. im Aufspalter) über das
%Vorhandensein von Optimierungsschritten wäre es der nächste sinnvolle Schritte, diese Optimierungsschritte tatsächlich umzusetzen.

Zur weiteren praktischen Verwendung des Compilers ist eine Integration in eine "'3D-Engine"' (also Bibliothek für 3D-Visualisierungen), wie es einige
unter Open-Source-Lizenzen gibt, anstrebenswert.

\cleardoublepage
\appendix

\chapter[Anhang]{}
%\phantomsection
%\pdfbookmark[1]{Anhang}{myPDFappendixLabel}

\section{Vom Parser verwendete Grammatik-Regeln}
\label{grammar_fixes}

Die in Kapitel~\ref{langspec} angegebene Grammatik enthält Mehrdeutigkeiten und eignet sich in dieser Form nicht direkt zur Implementierung;
sie wurde vor allem auf Verständlichkeit hin ausgerichtet.

Der im Compiler implementierte Parser basiert auf Varianten der Regeln, die um Mehrdeutigkeiten bereinigt wurden.
Bereinigte Versionen der Regeln, die damit von der Grammatik in Kapitel~\ref{langspec} abweichen, sind hier aufgeführt. 

\subsection{Ausdrücke}
\Gnt{ausdruck}:\label{ORIG_ausdruck}\\
\hspace*{1cm}\Gnt{asdr\_logisch\_oder}{\scriptsize (\ref{asdr_logisch_oder})} \Gspace\Gopt{\Galt{\Gnt{asdr\_suffix\_ternaer}{\scriptsize (\ref{asdr_suffix_ternaer})} \Gor{}\Gnt{asdr\_suffix\_zuweisung}{\scriptsize (\ref{asdr_suffix_zuweisung})} }}\\

Der Ausdruck höchster Präzedenz ist die Zuweisung.
%, auf welche einfach in der Regel für
%allgemeine Ausdrücke verwiesen wird.


\subsubsection{Zuweisung}
\Gnt{asdr\_suffix\_zuweisung}:\label{asdr_suffix_zuweisung}\\
\hspace*{1cm}\Gt{=}\Gspace\Gnt{ausdruck}{\scriptsize (\ref{ausdruck})} \\

Ein Zuweisungsausdruck setzt sich aus einem \Gnt{ausdruck}{\scriptsize (\ref{ausdruck})} (der "`linken Seite"') sowie einem
direkt folgenden \Gnt{asdr\_suffix\_zuweisung}{\scriptsize (\ref{asdr_suffix_zuweisung})} (die "`rechte Seite"') zusammen.
Dem Ausdruck der linken Seite wird der Wert des Ausdrucks
auf der rechten Seite zugewiesen. Der Ausdruck auf der linken Seite muss eine Variable oder ein Arrayelement
bzw. von diesen ein Swizzle-Attribut (siehe \ref{Vektorattribute}) bezeichnen.

Der Typ des zugewiesenen Ausdrucks muss zuweisungskompatibel (siehe unten) zur linken Seite der Zuweisung sein.

Ein Zuweisungsausdruck selbst hat den Wert der linken Seite nach der Zuweisung.

\emph{Anfang des Zuweisungsausdrucks siehe \Gnt{ausdruck}{\scriptsize (\ref{ORIG_ausdruck})}.}

\subsubsection{Ternärer Ausdruck}\label{Ternaerer Ausdruck}
\Gnt{asdr\_suffix\_ternaer}:\label{asdr_suffix_ternaer}\\
\hspace*{1cm}\Gt{?}\Gspace\Gnt{ausdruck}{\scriptsize (\ref{ausdruck})} \Gspace\Gt{:}\Gspace\Gnt{ausdruck}{\scriptsize (\ref{ausdruck})} \\

Ein ternärer Ausdruck setzt sich aus einem \Gnt{ausdruck}{\scriptsize (\ref{ausdruck})} (der "`Bedingung"') sowie einem
direkt folgenden \Gnt{asdr\_suffix\_ternaer}{\scriptsize (\ref{asdr_suffix_ternaer})} zusammen.
Die \emph{Bedingung} muss ein boolescher Ausdruck sein. Ergibt sich dieser Ausdruck zu \kw{true},
so wird der \emph{Wahr-Ausdruck} (dem \kw{?} folgend) ausgewertet, und der Wert des ternären
Ausdrucks ergibt sich zu dem Wert des \emph{Wahr-Ausdrucks}.
Ergibt sich die \emph{Bedingung} zu \kw{false}, so wird der \emph{Falsch-Ausdruck} (dem \kw{:} folgend)
ausgewertet, und der Wert des ternären
Ausdrucks ergibt sich zu dem Wert des \emph{Falsch-Ausdrucks}.

\emph{Wahr-} und \emph{Falsch-Ausdruck} müssen vom gleichen Typ sein.

\emph{Anfang des ternären Ausdrucks siehe \Gnt{ausdruck}{\scriptsize (\ref{ORIG_ausdruck})}.}

\subsection{Typen}

\Gnt{typ}:\label{typ}\\
\hspace*{1cm}\Gnt{typ\_basis}{\scriptsize (\ref{typ_basis})} \Gspace\Gopt{\Gnt{typ\_suffix\_array}{\scriptsize (\ref{typ_suffix_array})} }\\

\subsubsection{Arraytypen}
\Gnt{typ\_suffix\_array}:\label{typ_suffix_array}\\
\hspace*{1cm}\Gt{[}\Gspace\Gt{]}\Gspace\Gopt{\Gnt{typ\_suffix\_array}{\scriptsize (\ref{typ_suffix_array})} }\\

\printglossaries

\bibliography{thesis_de}
\addcontentsline{toc}{chapter}{Literatur}

\chapter*{Selbstständigkeitserklärung}
%\addcontentsline{toc}{chapter}{Selbstständigkeitserklärung}

Ich erkläre hiermit, dass ich die vorliegende Arbeit selbstständig und nur unter Verwendung der angegebenen Quellen und Hilfsmittel angefertigt habe.

Seitens des Verfassers bestehen keine Einwände die vorliegende Diplomarbeit für die öffentliche Benutzung im Universitätsarchiv zur Verfügung zu stellen. 

\vspace{7em}
Ort, Datum, Unterschrift

\end{document}
