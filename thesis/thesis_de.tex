\documentclass[twoside,a4paper,fleqn,12pt]{book}
\usepackage{fancyhdr,a4wide,graphicx}
\usepackage[paper=a4paper,left=20mm,right=20mm,top=25mm,bottom=25mm]{geometry}
\pagestyle{fancy}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
%\usepackage[]{amsfonts}
\usepackage{amsmath}
\usepackage[usenames,dvipsnames]{color}
\usepackage{colortbl}
%\usepackage{mathptmx}
\usepackage[bitstream-charter]{mathdesign}
\usepackage{charter}
\usepackage{helvet}
\usepackage{courier}
\usepackage{verbatim}
\usepackage{sectsty}
\usepackage{listings}
\usepackage{listingsutf8}
\usepackage{scalefnt}
\usepackage{setspace}
\usepackage{ngerman}
\usepackage{subfig}
\usepackage{longtable}

% Anm.: vor hyperref um Glossar-Ref nicht "klickbar" zu machen
\usepackage[toc]{glossaries}
\renewcommand{\glossaryname}{Glossar}

\definecolor{darkred}{rgb}{.5,0,0}
\definecolor{darkblue}{rgb}{0,0,.5}
% Screen
%\usepackage[plainpages=false,pdfpagelabels,colorlinks=true,urlcolor=darkblue,pagecolor=darkred,citecolor=darkred,linkcolor=darkred]{hyperref}
% Print
\usepackage[plainpages=false,pdfpagelabels,colorlinks=true,urlcolor=black,pagecolor=black,citecolor=black,linkcolor=black]{hyperref}
%\newcommand\url[1]{\texttt{#1}}

\lstset{basicstyle=\ttfamily\small,lineskip=-0.5em,language={},tabsize=8,inputencoding=utf8/latin1}

% define the title
\author{Frank Richter 68278\\frank.richter@gmail.com}
\title{\usefont{OT1}{phv}{b}{n}\selectfont Entwicklung eines Compilers für eine auf Cg basierende Sprache zur Programmierung von Grafikkarten \normalfont}
\date{\today}

\makeglossaries

\begin{document}

\sloppy

\newcommand\btxandlong{und}
\newcommand\btxandshort{u}
\newcommand\Btxinlong{In}
\newcommand\Btxinshort{I}
\newcommand\btxpageslong{Seiten}
\newcommand\btxetalshort{et al}
\newcommand\btxeditionlong{Auflage}
\bibliographystyle{mystyle}

% Zeilenabstand 1.5
\renewcommand{\baselinestretch}{1.50}\normalsize

% Helvetica für Section-Titel
\allsectionsfont{\usefont{OT1}{phv}{b}{n}\selectfont}

% Different font in captions
\newcommand{\captionstyle}{\small\centering}

\makeatletter  % Allow the use of @ in command names
\long\def\@makecaption#1#2{%
  \vskip\abovecaptionskip
  \sbox\@tempboxa{{\captionstyle #1: #2}}%
  \ifdim \wd\@tempboxa >\hsize
    {\captionstyle #1: #2\par}
  \else
    \hbox to\hsize{\hfil\box\@tempboxa\hfil}%
  \fi
  \vskip\belowcaptionskip}
\makeatother   % Cancel the effect of \makeatletter

% Fussnoten: alle Zeilen einrücken
\makeatletter
\newlength{\myFootnoteWidth}
\newlength{\myFootnoteLabel}
\setlength{\myFootnoteLabel}{1.2em}%  <-- can be changed to any valid value
\renewcommand{\@makefntext}[1]{%
  \setlength{\myFootnoteWidth}{\columnwidth}%
  \addtolength{\myFootnoteWidth}{-\myFootnoteLabel}%
  \noindent\makebox[\myFootnoteLabel][r]{\@makefnmark\ }%
  \parbox[t]{\myFootnoteWidth}{#1}%
}
\makeatother

% ---------- normal title ---------- %
\titlepage
\maketitle
\thispagestyle{empty}
\newpage
\thispagestyle{empty}
\mbox{}

% ---------- Fancyheader ---------- %
\fancyhead[L]{}
\fancyhead[R]{}
\fancyfoot[C]{\today}
\fancyfoot[R]{\footnotesize \thepage{}}
\renewcommand{\headrulewidth}{0pt}
%\setlength{\headheight}{24pt}
%\setlength{\parskip}{0pt plus 1pt}

% generates the title

% ---------- table of contents ---------- %
\newpage
\pagenumbering{roman}
%\addcontentsline{toc}{section}{Inhaltsverzeichnis}
\pdfbookmark[1]{Inhaltsverzeichnis}{myPDFtocLabel}
\tableofcontents

\cleardoublepage
\pagenumbering{arabic}
\newcommand\todo[1]{\footnote{\textcolor{red}{TODO: #1}}}
\newcommand\fcite[1]{\footnote{\cite{#1}}}
\newcommand\fciteX[2]{\footnote{\cite{#1}, #2}}

\chapter{Einleitung}

\section{Zielstellung}

In der Echtzeit-3D-Grafik werden 3D-Objekte überwiegend aus Dreiecken aufgebaut, welche für die Darstellung
auf einem Bildschirm gerastert werden.

\newglossaryentry{GPU}{name={GPU},description={``Graphics Processing Unit'', auf Darstellung von 3D-Grafik spezialisierte Prozessoren}}
Diese groben Arbeitsschritte spiegeln sich in dem Aufbau von 3D-Grafikprozessoren~("`\gls{GPU}"'),
deren Programmierschnittstellen~(\cite{glspec4}, \cite{dx10}), und, da GPUs programmierbar sind,
auch in den auf den Grafikprozessoren laufenden Programmen wieder.

GPU-Programme  kommen sowohl während der Verarbeitung von Dreiecken (bzw. deren Eckpunkten -- "`Vertexverarbeitung"') 
und der Berechnung der Rasterbildpunkte ("`Fragmentverarbeitung"') zum Einsatz.
Allerdings muss der Programmier die Aufteilung von Berechnungen gemäss dieser Verarbeitungsschritte sowie die Definition der "`Schnittstelle"'
zwischen den beteiligten Verarbeitungseinheiten manuell vornehmen.

Ziel dieser Arbeit ist es, einen Compiler zu entwickeln, der die Aufteilung in Programme für die Vertex- und Fragmentverarbeitung
(und die entsprechended Schnittstellendefinition) automatisch vornimmt,
ohne dass der Programmierer explizit angeben muss, auf welcher der Funktionseinheiten ein bestimmter Befehl ausgeführt wird.
Berücksichtigt werden müssen, dass Vertex- und Fragmentprogramme verschiedene Eingaben annehmen.
Auch muss bei der Auftrennung das Verhaltens der "`Schnittstelle"' zwischen den Verarbeitungseinheiten --
diese Schnittstelle nimmt selbst Interpolationen vor -- beachtet werden.
%Die Programme sollen in der in Abschnitt~\ref{langspec} spezifizierten Sprache formuliert werden.
%Die Implementierung des Compilers wird in Abschnitt~\ref{implementation} beschrieben.

% Nochmal Abschnitt mit kurzer Beschreibung wichtiger Konzepte? (meshes, Vertices vs Fragmente, ...)

\section{Gliederung}

Zuerst wird eine Einführung in Grundlagen der 3D-Grafik vorgenommen. Diese sind nötig um die Absicht und Besonderheit des entwickelten Compilers zu verstehen.
Auch in den weiteren Kapiteln vorkommende, fachspezifische Begriffe werden dort erklärt. Insbesondere das für die Arbeit des Compilers essentielle Konzept
der Berechnugsfrequenzen wird dort einführend erläutert.

Im Kapitel "`Sprachspezifikation"' wird die Sprache spezifiziert, in der die Programme geschrieben werden sollen.
Es werden allgemeine Anforderungen an die Sprache gestellt sowie auf spezielle Aspekte der vorzunehmenden Auftrennung von Programmen eingegangen.
Unter Berücksichtigung dieser Anforderungen und der speziellen Aspekte wird die Sprachsyntax sowie eine Auswahl vordefinierter Funktionen spezifiert.

Im darauf folgenden Kapitel wird schliesslich auf die Implementierung des Compilers selbst eingegangen. Insbesondere werden die verwendete Zwischencoderepräsentation
für die Weitergabe des Programmen zwischen den verschiedenen Arbeitsschritten des Compilers sowie das eigentliche "`Ziel"' dieser Arbeit,
die Komponente zur Auftrennung eines Programms, beschrieben. Auch der umgesetzte Generator für die Programm-Ausgabe sowie vorgenommene Optimierungen
werden erläutert.

% Abschluss?

\chapter{Einführung 3D-Grafik}

Als "`3D-Grafik"' wird die Berechnung zweidimensionaler Bilder aus dreidimensionalen Daten (die sog. "`\emph{Szene}"')
 bezeichnet.
Anwendung findet sie in vielen Bereichen: Visualisierung abstrakter mathematischer Formeln, Darstellung
von geologischen Profilen, digitales Erstellen von Konstruktionszeichnungen, Spezialeffekte in Filmen und
Rundgänge durch künstliche Szenarien in Computerspielen. 

\section{Vorberechnete 3D-Grafik und Echtzeit-3D-Grafik}

Die Berechnung von 3D-Grafiken wird als \emph{Rendering} bezeichnet. Bei den Anwendungen für das Rendering
von 3D-Grafiken ist eine wichtige Untergruppe die der \emph{Echtzeitgrafik}, die sich durch besondere Anforderungen
an die Berechnungszeit abgrenzt.

\emph{"`Vorberechnete"'} 3D-Grafiken kommen vor allem zur Anwendung, wenn fast realitätsnahe Bilder gewünscht sind.
Für deren hohe Bildauflösungen und komplexe Berechnungen werden lange Renderingzeiten (Minuten bis Stunden) in Kauf
genommen. Beispiele 
für vorberechnete Grafiken sind computergenerierte Spezialeffekte in Filmen bzw. komplette Kinofilme aus dem Computer.

Dagegen fordert \emph{Echtzeitgrafik} Bildberechnungen, die nur Bruchteile einer Sekunde benötigen, um
dynamische Daten mit geringen bis keinen wahrnehmbaren Verzögerungen in einer 3D-Grafik 
darzustellen.

Beispiele hierfür sind Konstruktionszeichnungen und Computerspiele. Diese stehen auch für verschiedene Anforderungen,
die trotzdem unter "`Echtzeitdarstellung"' fallen: Konstruktionszeichnungen müssen meist mit sehr großen Datenmengen 
agieren, aber trotzdem die Verzögerungen geringstmöglich halten, wobei noch wahrnehmbare Pausen toleriert
werden. Bildraten ab 15 Bildern/Sekunde werden als "`interaktiv"' bezeichnet. % TODO Ref?
Computerspiele hingegen haben strengere Anforderungen: um die Illusion von Bewegung zu erzeugen ist es hier nötig,
 mindestens 25 Bilder in einer Sekunde\footnote{Es wird in der Regel die höchstmögliche Anzahl von Bildern pro Sekunde 
angestrebt um alle Bewegungen möglichst flüssig darzustellen.} darzustellen. Überzeugende Bewegungsdarstellung und
geringe Latenzen bei Aktionen des Spielers sind von höchster Wichtigkeit; dafür werden aber, im Vergleich zur
Verwendung vorberechneter 3D-Grafiken, reduzierte Details in Kauf genommen.

\section{Renderingmethoden}

Die zu rendernden zweidimensionalen Bilder werden in fast allen Fällen als Rastergrafiken gespeichert\footnote{Es gibt
auch Renderer, die Vektorgrafiken erzeugen können.}: für jedes Pixel der Rastergrafik muss aus den gegebenen dreidimensionalen
Daten ein Farbwert berechnet werden. Die beiden hauptsächlich verwendeten Methoden sind Ray Tracing und Rasterung.

Beim \emph{Ray Tracing} wird für jeden Bildpunkt ausgehend ein Strahl in die dreidimensionale Szene nachverfolgt. 
Die Farbe des Bildpixels wird aus dem "`Licht"', welches von der Oberfläche des zuerst "`getroffenen"' Objekts reflektiert wird,
berechnet. Dieses reflektierte Licht wird entweder durch eine Annäherung oder durch weiteres, rekursives
Nachverfolgen von Strahlen bestimmt. 
Vorteile des Ray Tracings sind die einfache Unterstützung von Schatten und Effekten wie spiegelnde
Oberflächen und Lichtbrechung; Nachteil ist der nötige Rechenaufwand.
\footnote{Ray Tracing ist detailliert in~\cite{watt_de}, Kap. 12, beschrieben.}

Beim \emph{Rastern} werden die Daten hingegen auf die Bildpixel projiziert und Farbwerte für diese Pixel berechnet.
Während dies weniger rechenintensiv als Ray Tracing ist können jedoch Effekte wie Spiegelungen und Schatten nicht so
einfach berechnet werden, sondern werden meist approximiert.\footnote{Siehe auch~\cite{watt_de}, Kap. 4.}

Die Geschwindigkeit und Einfachheit des Rasterns ist jedoch vorteilhaft für die Echtzeitgrafik und ist dort die praktisch
ausschließlich verwendete Variante. % TODO Intel-Ray Tracer
Vor allem ist spezielle, die Rasterung stark beschleunigende Hardware verfügbar. % TODO siehe Aufbau Hardware

Ray Tracing dagegen findet vor allem bei der Vorberechnung von 3D-Grafiken statt.
%Allerdings wird dort zunächst auch Rasterung eingesetzt,
%gemischt mit Ray Tracing wenn benötigt (z.B. reflektierende Oberflächen). % TODO Ref?

\section{Grundlegende Strukturen}

\subsection{Modelle}
\label{tri_mesh}

Dreidimensionale Objekte ("`\emph{Modelle}"') einer Szene können auf verschiedene Arten repräsentiert werden~(\cite{watt_de}, S. 45-47). 

\newglossaryentry{Dreiecksnetz}{name={Dreiecksnetz},description={3D-Modell, Menge von Eckpunkten (Vertices) und Dreiecken}}
\newglossaryentry{Vertex}{name={Vertex},plural={Vertices},description={Eckpunkt eines Dreiecksnetzes. Mehrzahl: Vertices}}
Die einfachste Form der Darstellung ist die des \emph{\gls{Dreiecksnetz}es} (engl. ``triangle mesh'' und kürzer ``mesh'').
 Diese bestehen aus einer Menge von Eckpunkten,
als \emph{\glspl{Vertex}} bezeichnet, sowie einer Menge von Dreiecken, wobei deren Ecken aus der Menge der Vertices stammen.
Einem Vertex ist mindestens eine Position im Raum, meist aber auch weitere Daten, die für die Oberflächendarstellung und
\mbox{-schattierung} verwendet werden,  zugeordnet~(\cite{watt_de}, S. 50).
Analog sind auch Dreiecken neben Referenzen zu den Eckvertices weitere Daten wie z.B. eine Oberflächenfarbe zugeordnet.


Um ein passgenaues Abschließen der Dreiecke zu sichern teilen sich in der Regel Ecken mehrerer Dreiecke ein
Vertex\footnote{Selten haben zwei Ecken in \emph{einem} Dreieck das selbe Vertex -- dies führt zu "`degenerierten"' Dreiecken}. 
Der Vorteil von Dreiecksnetzen ist deren Einfachheit. Insbesondere das Rastern von Dreiecken kann mit wenig Aufwand
implementiert werden. Auch können Oberflächen beliebig genau angenähert werden. Diese Eigenschaften sind aber auch
nachteilig: einige Oberflächen \emph{müssen} angenähert werden. So kann z.B. eine Kugel nicht perfekt durch ein Dreiecksnetz
abgebildet werden. 

% Bild Drahtgitter
\begin{figure}[h]
  \centering
  \includegraphics[width=10cm]{drahtgitter}
  \caption{Ein 3D-Würfel mit schattierten Seiten, als Drahtgittermodell und eine Aufteilung in Dreiecke. Die Vertices
  sind die Eckpunkte des Würfels.}
  \label{fig:wirecube}
\end{figure}

Hervorzuheben ist, dass auf die Berechnung von 3D-Grafiken spezialisierte Hardware 
ausschließlich mit Dreiecksdaten arbeiten -- die Hardware kann eigentlich nichts anderes zeichnen. Wegen der Einfachheit der Darstellung
können aber sehr viele Dreiecke in einer Sekunde ausgegeben werden. 

Andere Arten der Modelldarstellung, wie die \emph{implizite Darstellung}\footnote{Beschreibung eines Objekts durch eine Formel,
z.B. $x^2 + y^2 + z^2 = r^2$ für eine Kugel -- siehe~\cite{watt_de}, Abschn. 2.4}, \emph{Voxelgrafiken}\footnote{Voxel: ``volumetric pixel'' --
Analog zu Bildern sind dies dreidimensionale Raster, an dessen Rasterpunkte Farbwerte o.ä. gespeichert werden -- siehe~\cite{watt_de}, Abschn. 4.4}
und \emph{Patches}\footnote{Einfach gesagt, gekrümmte Vierecke -- durch mathematische Formeln beschriebene Oberflächen -- siehe~\cite{watt_de}, Kap. 3}
finden in der Echtzeit-3D-Grafik kaum Verwendung, da sie -- im Vergleich zu Dreiecksnetzen -- aufwändig in der Darstellung sind.

So müssen auf 3D-Grafik-Hardware gekrümmte Oberflächen (wie Kugeln, Patches) unter Verwendung von Dreiecken visualisiert werden:
die Oberfläche wird mit einer hohen Anzahl von Dreiecken angenähert.

%Auch zum Umrechnen von Voxel-Daten existieren Algorithmen, um daraus Dreiecksdaten zu erzeugen. % TODO Ref Marching cubes, Slides
Auch Voxel-Daten müssen dort durch Dreiecksdaten angenähert werden,
entweder als Dreiecksnetz einer Oberfläche (``marching cubes''-Algorithmus,~\cite{watt_de} Abschn. 13.3.1)
oder durch Benutzung von Schnittflächen~(\cite{watt_de} Abschn. 13.6).

% TODO Skizze Rendering-Pipeline?

\subsection{Räume, Transformationen und Kamera}

In praktischen Anwendungen wird selten ein einziges Modell statisch dargestellt. In der Regel müssen mehrere Modelle
gleichzeitig dargestellt werden (z.B. zusammengesetztes Bauteil), wobei die Modelle
in bestimmter Weise zueinander positioniert dargestellt werden müssen. Weiterhin soll ein "`Bewegen"' im Raum --
also die Betrachtung von beliebigen Punkten aus -- möglich sein. Dieser "`Blickpunkt"' des Betrachters ist die \emph{Kamera}.

Zu diesem Zweck werden verschiedene \emph{virtuelle Räume} definiert~(\cite{watt_de}, S. 166ff).
 So gibt es für jedes Modell ein \emph{Objektkoordinatensystem}\footnote{engl. ``object space''},
in dem sich alle Koordinaten des Modells befinden. 
Die Positionierung verschiedener Modelle zueinander wird im \emph{Weltkoordinatensystem}\footnote{engl. ``world space''} vorgenommen. 
Dazu wird jedem Modell eine \emph{Transformation} zugewiesen, welche Koordinaten aus dem Objekt- in das
Weltkoordinatensystem überführt. 

Eine Transformation wendet Verschiebungen, Skalierungen und Rotationen an. Als Repräsentation von Transformationen
verwendet man Matrizen\footnote{Genauer: $4 \times 4$-Matrizen -- die dreidimensionalen Koordinaten des Modells werden
in homogene Koordinaten überführt. Die Verwendung von homogenen Koordinaten
erlaubt das Darstellen von Verschiebungen in der Matrix.}, % Ref Watt (DE)
jede Koordinate wird dann mit der Transformationsmatrix multipliziert. Mehrere Transformationen können angewendet werden, indem 
die entsprechenden Matrizen der Teiltransformationen in der gewünschten Reihenfolge zu der Gesamtmatrix konkateniert werden~(\cite{watt_de}, Kap. 1).

Die Übersetzung eines Dreiecksnetz-Modells in das Weltkoordinatensystem erfordert nur die Anwendung der Transformationsmatrix
auf die Koordinaten aller Vertices.

% TODO Hier Skizze 
Die Position des Betrachters wird durch das \emph{Kamerakoordinatensystem}\footnote{engl. ``eye space'' oder ``camera space''}
 bestimmt. Dies ist so definiert, dass der "`Blickpunkt"' am Koordinatenursprung des Systems liegt
und die "`Blickrichtung"' einer gegebenen Achse entspricht. 
Durch eine weitere Transformation werden Welt-Koordinaten in Kamera-Koordinaten
überführt. Dies erlaubt eine beliebige Positionierung des Betrachters in der Szene und eine beliebige Blickrichtung.
Die zugrundeliegenden Prinzipien sind die selben wie bei der Transformation aus dem Objektkoordinatensystem.

Der Blickpunkt ist ein Punkt in einem \emph{dreidimensionalem} Raum, eine Szene wird jedoch auf einem
\emph{zweidimensionalem} Bild dargestellt -- die "`verlorene"' Dimension ist die Tiefe.
Daher wird eine \emph{Bildebene} in geringem Abstand zum Betrachter gesetzt,
welche als "`Projektionsfläche"' der Szene dient.

Weiterhin müssen Modelle \emph{perspektivisch verzerrt} werden. 
Stark vereinfacht gesagt werden auf die Kamera-Koordinaten eine \emph{Projektionsmatrix} angewendet, welche dazu führt,
das bei der Projektion auf die Bildebene jede Koordinate durch ihre $z$-Komponente dividiert wird -- eine perspektivische Verzerrung.
\footnote{Eine ausführliche Beschreibung findet sich in~\cite{watt_de}, Kap. 1.}
% Bei den vorangegangenen Transformationen werden die Koordinaten
% als homogene Koordinaten interpretiert. Homogene Koordinaten besitzen eine vierte Komponente $w$, die bei der Anwendung
% der vorangegangenen Transformationen $1$ ist~(\cite{watt_de}, Kap. 1).
% Für die perspektivische Verzerrung wird auf die Koordinaten im Kamerakoordinatensystem eine \emph{Projektionsmatrix} angewendet,
% die als Besonderheit die $w$-Koordinate auf den Wert der $z$-Koordinate -- den Abstand von der Bildebene -- setzt.
% Werden nun die transformierten Koordinaten durch die $w$-Komponente dividiert so ist dies effektiv die perspektivische Verzerrung.
% Die Projektionsmatrix kann frei gewählt werden -- z.B. kann sie, durch Setzen der $w$-Koordinate auf $1$, auch orthographische
% Projektionen darstellen.

\subsection{Texturen}

\newglossaryentry{Textur}{name={Textur},plural={Texturen},description={Bilddaten, bei der Fragmentverarbeitung ausgelesen. Typischerweise auf Oberfläche von Modellen "`gespannt"'}}
Zur Simulation von detaillierten Oberflächen werden \emph{\glspl{Textur}} verwendet. Im Regelfall sind dies zweidimensionale
Bilder. Einem jeden Dreieck eines Modells ist ein (ebenfalls dreieckiger) Ausschnitt auf einer Textur zugeordnet. 
Die Zuordnung findet über \emph{Texturkoordinaten} statt, d.h. jedem Vertex ist ein weiteres Zahlenpaar zugeordnet,
welches einen Punkt auf der Textur angibt.
Beim Rendering wird nun der durch diese Koordinaten beschriebene Texturausschnitt auf die Oberfläche des Dreiecks 
"`gespannt"': für jedes gerenderte Pixel des Dreiecks wird die Position des zugehörigen Textur-Pixels (``texel'')
berechnet. Der Farbwert der Textur an dieser Position wird ausgelesen und dient als Farbwert des gerenderten Pixels~(\cite{watt_de}, S. 160).

\subsection{Shading}

\newglossaryentry{Shading}{name={Shading},description={Berechnung der Farbe eines beleuchteten Punktes auf einer 3D-Oberfläche}}
Bei der visuellen Wahrnehmung spielt die Interaktion von wahrgenommen Oberflächen mit Lichtquellen eine wichtige
Rolle. Aus Helligkeitsunterschieden, die aus Variationen von Abstand und Lage zu einer Lichtquelle
herrühren, können auf Objekteigenschaften wie Drehung, Größe und Form sowie auf Oberflächeneigenschaften
wie deren Struktur geschlossen werden.
Bei der Computergrafik ist die Berechnung der Beleuchtung einer Oberfläche
entsprechend wichtig. Es variiert aber nach Anwendungsfall, ob die Beleuchtung die in der Realität stattfindenden physikalischen Vorgänge
nachbilden soll, oder aber ob diese nicht physikalisch korrekt sein, aber dafür
eine dreidimensionale Form einfach erkennen lassen soll.

In der bisherigen Beschreibung der Darstellung von Oberflächen wurde die Berechnung der Beleuchtung einer
Oberfläche ausgelassen. Diese Berechnung wird \emph{\gls{Shading}} (übersetzt "`Schattierung"') genannt~(\cite{watt_de}, S. 146, 198).
% Begr. Shading: , Schattierung: Watt (DE) 146, 198 -> Ergebnis ist "Intensität"
Beim Shading wird eine \emph{Lichtintensität}, d.h. die Intensität des reflektierten Lichts, für Punkte auf der
Oberfläche berechnet.

Um das reflektierte Licht zu berechnen wird mindestens der Oberflächenpunkt im Raum sowie die Lage der Oberfläche
-- als \emph{Oberflächenormale} an dem gegebenen Punkt -- benötigt.

% TODO Bilder
Es gibt verschiedene Strategien zur Berechnung von Lichtintensitäten. Die einfachste ist die Berechnung der Lichtintensität
eines Punktes des Dreiecks und die Verwendung dieses Wertes für das komplette Dreieck. Dieser Ansatz, ``flat shading'',
ist zwar schnell, hat aber eine sehr "`facettierte"' und kaum realistische Objektdarstellung zur Folge.
% TODO Ref auf Methoden

Wird die Intensität für jedes Vertex berechnet und dann über das Dreieck linear interpoliert ("`Gouraud-Shading"') so ist
das Ergebnis bereits weniger facettiert, allerdings mit Mehraufwand für Intensitätsberechnung und Interpolation verbunden.
Trotzdem haben Objekte bei Verwendung dieser Methode ein charakteristisches Aussehen, besonders die Kanten von Dreiecken lassen sich leicht erkennen.

Die aufwändigste Methode ist das Berechnen der Intensität für jedes dargestellte Pixel ("`Phong Shading"'), wobei
nur per Vertex verfügbare Werte über das Dreieck linear interpoliert werden (analog zur eigentlichen Intensität beim
Gouraud-Shading). Der Aufwand wird aber damit belohnt, dass keine Facetten und wenig Kanten sichtbar sind.
\footnote{Ein Vergleich der verschiedenen Interpolationsarten findet sich auch in~\cite{watt_de}, Kap. 18.}
% @@@ Kanten sichtbar an Umriss

\section{Aufbau Hardware}

\subsection{Ablauf Echtzeit-Rendering}

\begin{figure}[h]
  \centering
  \includegraphics{3d_pipeline}
  \caption{Schematische Darstellung der 3D-Grafik-Pipeline}
  \label{fig:3d_pipeline}
\end{figure}

Die Ausgabe der Grafik soll in der Regel als Rastergrafik auf einem Computermonitor, also auf einer zweidimensionalen Fläche, erfolgen.
Demgegenüber besitzen 3D-Modelle per Definition Koordinaten in einem dreidimensionalen Raum, deren Komponenten potentiell
aus der Menge der reellen Zahlen stammen. Es muss also eine \emph{Projektion} vorgenommen werden. 

Diese Projektion wird mit den Ausgaben der Vertexverarbeitung durchgeführt. Bei der Vertexverarbeitung werden auf alle Vertices die gleichen
Berechnungen angewendet. Diese werden in der Hardware in der Regel parallel 
auf mehreren Recheneinheiten ausgeführt. Im Allgemeinen wird dort mit Vektoren gerechnet.
Die Vertexverarbeitung kann mehrere Werte pro Vertex berechnen, aber minimal muss die Vertex-Koordinate in das Kamerakoordinatensystem
abgebildet werden.
\newglossaryentry{Vertexattribut}{name={Vertexattribut},plural={Vertexattribute},description={Weitere, jedem Vertex zugeordnete Werte}}
In der Regel werden aber weitere Werte berechnet ("`\glspl{Vertexattribut}"'), die als Eingabe der späteren Fragmentverarbeitung dienen.

\newglossaryentry{Shadingsprache}{name={Shadingsprache},plural={Shadingsprachen},description={Sprachen zur Programmierung von Vertex- und Fragmentverarbeitung auf GPUs}}
Die beiden Verarbeitungsschritte der "`Vertexverarbeitung'' und "`Fragmentverarbeitung"' sind auf modernen GPUs
\emph{programmierbar} -- die vorgenommenen Berechnungen werden also durch von einem Programmierer bereitgestellte
Programme bestimmt. Die GPUs selbst, als Mikroprozessoren, verarbieten in einem Binärcode vorliegende Programme; dieser Code
wird jedoch von den Programmierschnittstellen "`versteckt"' und Programme werden in einer Hochsprache gegeben\footnote{GLSL bei OpenGL, HLSL bei DirectX}.
Die Sprachen werden "`\glspl{Shadingsprache}"' genannt.

Auf der neuesten Generation von GPUs (GeForce 8) % etwas zu GraKa-Generationen sagen
ist ein weiterer Verarbeitungsschritt verfügbar, die "`Geometrieverarbeitung"'\footnote{engl. geometry shader}. 
Diese hat die Besonderheit, neue Dreiecke
mit beliebigen Koordinaten erzeugen zu können: 
auf eineer Grafikkarte ohne Geometrieeinheit sind alle Verarbeitungsschritte "`statisch"' bezüglich der Vertices -- nur existierende
Werte können manipuliert werden. Gleiches gilt für Dreiecksdaten. Das \emph{Erzeugen} von Vertices kann bei diesen Grafikkarten
also nur durch die CPU erfolgen, woraufhin die Daten zur GPU übertragen werden.
Im Schritt der Geometrieverarbeitung kann die GPU aber selbst Vertices und Dreiecke erzeugen
und auch entfernen. Dieser Schritt erlaubt die Implementierung von Algorithmen auf der Grafikkarte, die viel 
Flexibilität bei der Verarbeitung von Modelldaten, speziell der Dreiecksdaten, erfordern.

\newglossaryentry{Fragment}{name={Fragment},description={Ergebnis der Rasterung eines Dreiecks}}
\label{rasterung}
Nach der Vertex- bzw. Geometrieverarbeitung stehen die Koordinaten in das \emph{Kamerakoordinatensystem}\footnote{Betrachter befindet sich am
Ursprung} transformiert zur Verfügung. Diese werden nun auf das Monitor-2D-Rasterbild mit Hilfe einer einfachen linearen Projektion
abgebildet. Damit erhält man die Eckpunkte der Dreiecke im Koordinatensystem des Monitors mit denen die Dreiecke selbst
gezeichnet werden. Dies geschieht durch Rasterung\footnote{siehe auch~\cite{watt_de}, Abschn. 6.4} der Dreiecke. Um die Farbe eines berechneten 
\emph{\gls{Fragment}s}\footnote{Ein Fragment ist ein Teil eines Pixels des Rasterbildes. Ein Pixel kann aus mehreren Fragmenten bestehen wenn 
Algorithmen zur Kantenglättung benutzt werden. Zum Verständnis reicht es jedoch aus, anzunehmen, dass ein Fragment genau einem Pixel entspricht.} zu 
bestimmen werden eine Reihe weiterer Rechnungen vorgenommen. Die Eingaben der Fragmentverarbeitung werden
durch perspektivisch korrekte lineare Interpolation aus den Vertexattributen der Drei\-ecks\-eck\-punk\-te  
berechnet. Abbildung~\ref{fig:triraster} zeigt schematisch die Rasterung eines Dreiecks mit einem interpolierten Vertexattribut.

\begin{figure}[h]
  \centering
  \includegraphics[scale=0.8]{triraster1}
  \qquad
  \includegraphics[scale=0.8]{triraster2}
  \qquad
  \includegraphics[scale=0.8]{triraster3}
  \caption{Rasterung eines Dreiecks: 1. Nach Transformation in das Koordinatensystem des Monitors.
  2. Vom Dreieck überlagerte Fragmente. 3. Ein Vertexattribut "`Grauwert"', über die Fragmente interpoliert.}
  \label{fig:triraster}
\end{figure}

In den meisten Fällen wird in der Fragmentverarbeitung eine Textur ausgelesen
und mit den Vertexattributen durch Operationen kombiniert (z.B. Multiplikation, um eine beleuchtete Oberfläche zu simulieren).
Wie bei den Vertex-Berechnungen werden auch bei den Fragment-Berechnungen die gleichen Berechnungen auf eine Vielzahl
von Fragmenten gleichzeitig angewendet und erfolgt parallel auf mehreren Vektorrecheneinheiten.

%Alle Verarbeitungseinheiten sind auf aktueller Grafikhardware programmierbar.
\section{Berechnungsfrequenzen}
\label{berechnungsfrequenz_locker}

Für das Rendering eines 3D-Modells werden verschiedenartige Daten benötigt. So zuerst das Modell selbst, als Dreiecksnetz. Dazu
eine Reihe von Transformationen zur Abbildung zwischen Koordinatensystemen -- Objekt zu Welt, Welt zu Kamera und schliesslich
eine Projektion von Koordinaten im Kameraraum auf Bildschirmpixel. Typischerweise kommen noch weitere, vom Shading verwendete Daten --
wie eine Oberflächennormale, per Vertex definiert, und eine Textur -- hinzu.

Zu Beobachten ist, dass diese verschiedenen Daten in ihrer "`Veränderlichkeit"' variieren:
\begin{itemize}
\item Die verwendeten Transformationen gelten für das ganze 3D-Modell, verändern sich also \emph{per Mesh}.
\item Vertexdaten, wie Position im Objektkoordinatensystem oder Oberflächennormale, sind \emph{per Vertex}
verschieden. Vor allem berechnete Vertexattribute, die bei der Fragmentverarbeitung verwendet werden, werden
bloss per Vertex berechnet -- die eigentliche Eingabe der Fragmentverarbeitung wird aus den per-Vertex-Werten
interpoliert.
\item Texturdaten werden in der Fragmentverarbeitung ausgelesen, solch ausgelesene Werte ändern sich \emph{per Fragment}.
\end{itemize}

Aus diesen Beobachtungen leitet sich das Konzept der \emph{Berechnungsfrequenz}\footnote{Zuerst beschrieben in \cite{stanford_rtsl}.} ab.
Die Berechnungsfrequenz eines Wertes sagt aus, wie oft dieser berechnet werden müsste bzw. in welchem Verarbeitungsschritt
dies passiert. Je "`höher"' die Frequenz, desto häufiger muss ein Wert potentiell berechnet werden:
\begin{itemize}
\item Die theoretisch niedrigste Frequenz besitzen Verknüpfungen statischer Konstanten -- solche Ergebnisse müssen nur ein einziges Mal berechnet werden.
\item Die für 3D-Grafik nächsthöhere, relevante Frequenz ist die "`Meshfrequenz"': Transformationen werden in der Regel per Mesh spezifiziert,
eine Verknüpfung von zwei Transformationen muss nur einmal für ein Modell berechnet werden; über die gesamte Ausführungszeit einer Anwendung gesehen
müssen solche Transformation aber praktisch öfter als ein einziges Mal berechnet werden.
\item Als nächste Frequenz folgt die "`Vertexfrequenz"' für Werte, die von Vertexdaten abhängen. Augenscheinliches Beispiel sind
vom Objektkoordinatensystem in das Kamerakoordinatensystem abgebildete Modellkoordinaten. Da ein Modell in der Praxis mehr als ein Vertex besitzt,
ist ersichtlich, das Berechnungen in Vertexfrequenz öfter ausgeführt werden als solche mit Meshfrequenz.
\item Die höchstmögliche Frequenz ist die der "`Fragmentfrequenz"' für Werte, die per Fragment berechnet werden müssen.
Dies sind zum Beispiel aus Vertexdaten berechnete Werte, die sich nicht sinnvoll interpolieren lassen, oder Werte aus Texturen,
deren Zweck es ja ist, mehr Details zu ermöglichen, als es Vertexdaten allein zulassen würden.
Ein gerastertes Dreieck überspannt in der Regel mehrere Fragmente; aus diesem Grund werden per Fragment auszuführende Operationen
öfters berechnet als per Vertex.
\end{itemize}

Eine höhere Berechnungsfrequenz korrespondiert prinzipiell mit einer weiter hinten liegenden Verarbeitungsstufe in der Renderingpipeline.
Statische und Meshfrequenz sind praktisch sogar noch vor der Verarbeitung auf der GPU angesiedelt. Berechnungen in Vertexfrequenz (oder "`per Vertex"')
entsprechen Berechnungen auf der Vertexeinheit, analog werden Berechnungen in Fragmentfrequenz (oder "`per Fragment) auf der Fragmenteinheit ausgeführt.

Abbildung~\ref{fig:simple_cg} zeigt ein Programm-Paar für eine einfache Shadingberechnung in Cg. Die verschiedenen auftretenden Berechnungsfrequenzen
sind dabei farbig markiert. 

Die Nützlichkeit von Berechnungsfrequenzen besteht in der Verwendbarkeit als Werkzeug zur Optimierung des Renderings von 3D-Modellen.
Bei der Echtzeitgrafik ist ein grundsätzliches Bestreben, zum Zwecke schnellerem Renderings Operationen so selten wie möglich auszuführen.
Wird eine Operation, für die eine Berechnung per Vertex ausreichend wäre, auf der Fragmenteinheit ausgeführt, so bedeutet dies
eine Verschwendung von Rechenleistung. Bestimmt man nun für eine Beschreibung, wie ein Modell in den verschiedenen Renderingschritten zu
verarbeiten ist, die Frequenz jeder Operation, mit der diese ausgeführt werden muss, so können die Operationen optimal auf die
Verarbeitungseinheiten verteilt werden, ohne dass Rechenleistung verschwendet wird.

Programme in der hier beschriebenen Shadingsprache sind genau solche Beschreibungen der Verarbeitungsschritte; der implementierte Compiler
bestimmt für jede Operation eines Programms die nötige Berechnungsfrequenz und spaltet das Eingabeprogramm entsprechend auf.

\newcommand\freqPerMesh[1]{\framebox{#1}}
\newcommand\freqPerVert[1]{\colorbox{SpringGreen}{\textcolor{Black}{#1}}}
\newcommand\freqPerFrag[1]{\colorbox{BlueViolet}{\textcolor{White}{#1}}}
\begin{figure}[hp]
  \input{simple_cg}
  \caption{Ein Programm-Paar in Cg.}
  \centering
  \small Operationen und Werte sind von der Berechnungsfrequenz abhängig markiert (\freqPerMesh{Mesh}, \freqPerVert{Vertex}, \freqPerFrag{Fragment})
  \label{fig:simple_cg}
\end{figure}

\section{Zusammenfassung}

Bei der Echtzeit-3D-Grafik werden von der Grafikhardware als Dreiecksnetze vorliegende 3D-Modelle dargestellt.
Diese Modelle bestehen aus \emph{``Vertices''}, die die Eckpunkte von Dreiecken bilden. Bei der Darstellung eines
Modelles wird zuerst die \emph{Vertexverarbeitung} vorgenommen; dabei werden die Raumkoordinaten der Vertices transformiert
und weitere Berechnungen auf den Vertices zugeordneten Daten vorgenommen ("`Vertexattribute"').
Als nächsten Schritt der Darstellung werden Dreiecke bei der \emph{Rasterung} auf Fragmente (im Wesentlichen Pixel) des Ausgabegerätes abgebildet.
Bei dieser \emph{Fragmentverarbeitung} dienen als Eingaben die Ausgaben der Vertexverarbeitung, allerdings \emph{interpoliert}.
Es werden weitere Berechnung vorgenommen, um Details hinzuzufügen, für die eine Berechnung per Vertex zu "`grob"' wäre,
wie das "`aufziehen"' von \emph{Texturen} (Bilddaten) auf das 3D-Modell.

Die Verarbeitungsschritte "`Vertexverarbeitung"' und "`Fragmentverarbeitung"' sind beide programmierbar, die Ausgabe des Compilers
soll ein Programm-Paar aus Vertex- und Fragmentprogramm sein.

Aus den Verarbeitungsschritten der Echtzeit-3D-Grafik wurde das Konzept der \emph{Berechnungsfrequenz} abgeleitet:
diese sagt aus, auf welche Verarbeitungseinheit eine Operation eines GPU-Programms ausgeführt werden muss.
Die Berechnungsfrequenz wird vom Compiler verwendet werden, um zu bestimmen,
in welches Ausgabeprogramm (Vertex- oder Fragmentprogramm) eine Operation ausgegeben werden muss.

\chapter{Sprachspezifikation}
\label{langspec}

\input{langspec}

\chapter{Implementierung}
\label{implementation}

In diesem Kapitel wird auf die Implementierung des Compilers selbst eingegangen. 
Neben Scanner und Parser werden vor allem die verwendete Zwischencoderepräsentation
für die Weitergabe des Programms zwischen den verschiedenen Arbeitsschritten des Compilers 
sowie die Komponente zur Auftrennung eines Programms -- das eigentliche "`Ziel"' dieser Arbeit -- beschrieben.

\section{Compiler-Aufbau}
\begin{figure}[h]
   \centering
  \includegraphics{compiler_structure}
  \caption{Schematischer Aufbau des Compilers}
  \label{fig:structure}
\end{figure}

Der Aufbau entspricht grösstenteils der Compiler-Standardarchitektur (Abbildung~\ref{fig:structure}): das \emph{Front-End} generiert nach Syntax- und Semantikanalyse
eine Repräsentation des Programms in einem \emph{Zwischencode}. Auf dieser Zwischencoderepräsentation werden im "`Middle-End"' % Ref wo das gesagt wird, oder besseres Wort
Optimierungen vorgenommen. Im letzten Schritt wird im \emph{Back-End} aus der optimierten Zwischencoderepräsentation der tatsächliche Zielcode generiert.

Besonderheit dieses Compilers ist der Schritt \emph{Auftrennung VP/FP}. Hier wird in der Zwischencoderepräsentation untersucht, mit
welcher Berechnungsfrequenz~(siehe \ref{berechnungsfrequenz_locker} und \ref{Berechnungsfrequenz})
\footnote{Für "`Meshfrequenz"' wird kein Programm generiert, sie spielt aber eine Rolle bei der Aufspaltung. Generell ist das Konzept der Aufspaltung auch auf weitere Frequenzen erweiterbar.}
jeder Befehl des Programms ausgeführt werden muss - mit anderen Worten,
es wird untersucht, welche Befehle auf der Vertex-Einheit und welche auf der Fragment-Einheit ausgeführt werden müssen. Mit diesen Informationen kann
das Programm entsprechend in ein Vertex- und ein Fragment-Programm aufgeteilt werden. Da zur Laufzeit auch ein "`Übergeben"' von Ausgaben
des Vertexprogramms an Eingaben des Fragmentprogramms stattfindet wird auch eine "`Schnittstelle"' generiert, die die Vertex-Ausgaben auf Fragment-Eingaben
abbildet.

Die Programme werden vom Aufspalter in Zwischencode ausgegeben und können noch einmal optimiert werden. % Irgendein besonderer Vorteil?
Abschließend werden ein Fragment- und ein Vertexprogramm im gewünschten Zielcode ausgegeben\footnote{Diese Implementierung benutzt den
gleichen Generator für beide Programme, prinzipiell könnten diese jedoch mit verschiedenen Generatoren ausgegeben werden.}.

\section{Implementierungsdetails}

Als \emph{Programmiersprache}, in der die hier beschriebene Implementierung verfasst ist, wurde C++ gewählt.
Gründe dafür sind:
\begin{itemize}
\item Die Flexibilität der Sprache und deren reichhaltige Standardbibliothek,
\item hohe Portabilität (C++-Compiler sind für praktisch jede Plattform verfügbar),
\item eine reichhaltige Palette an von Dritten hergestellter Bibliotheken,
\item die einfache Verwendbarkeit in anderen Programmiersprachen (direkt oder über eine C-kompatible Schnittstelle).%,
%\item nicht zuletzt die Gewandheit des Autors dieser Arbeit in C++.
\end{itemize}
 
Um eine Wiederverwendung des Compilers zu vereinfachen wurde dieser im Wesentlichen als eine \emph{Bibliothek} realisiert;
eine "`Kommandozeilenversion"' des Compilers setzt auch auf diese Bibliothek auf.
 
Zur Sicherstellung der fortwährend korrekten Funktionsweise aller Module des Compilers wurden entwicklungsbegleitend 
jeweils \emph{Tests} der Module geschrieben (Black-Box und White-Box); Ausführen der Tests war regelmässiger Teil des Entwicklungsprozesses.
 
\section{Scanner}

Der \emph{Scanner} wandelt die als Byte-Strom vorliegende Eingabe in eine Folge von "`Tokens"'.
Ein Token ist eine der in Abschnitt~\ref{Lexikalische Einheiten} aufgezählten lexikalischen Einheiten, ein bekanntes Symbol (Operatoren etc.) oder Schlüsselwort. 
Leerzeichen (``Whitespace'') und Kommentare werden bereits vom Scanner ignoriert (d.h. für diese werden keine Tokens produziert).

Der Scanner folgt einer typischen Implementierung wie sie z.B. in \cite{wirth_compiler} beschrieben ist. Auf einige beachtenswerte Aspekte
wird im folgenden eingegangen.

\paragraph{Eingabe.} Da die Spezifikation von Unicode als Eingabe ausgeht, arbeitet der Scanner entsprechend auf der Basis von Unicode-kodierten Zeichen.
Der Byte-Strom der Eingabe wird also in einem Schritt noch vor dem Scanner in einen "`Unicode-Strom"' umkodiert\footnote{Verwendet wird dazu die Bibliothek ICU,
\url{http://site.icu-project.org/}}.

\paragraph{Schlüsselwörter.} Erkennt der Scanner einen Bezeichner, wird auch geprüft, ob es sich um ein Schlüsselwort handelt. Ist dies der Fall
wird im Token eine dem Schlüsselwort eindeutig zugeordnete ID gespeichert.

%Die erste Ausnahme
Eine Ausnahme allerdings bilden die Schlüsselwörter für Vektor- und Matrixtypen (Abschnitte~\ref{Vektortypen}, \ref{Matrixtypen}). Diese entsprechen
jeweils dem Muster $\mathit{typ}\mathrm{N}$ bzw. $\mathit{typ}\mathrm{N}\mathit{x}\mathrm{M}$ (mit $N \in 1 \dots 4, M \in 1 \dots 4$).
Da eine eigene ID für jeden Vektor- oder Matrix insgesamt 20 weitere IDs pro Basis-Typ nach sich ziehen würde -- wobei später noch jeder ID wiederum
die ursprünglichen Werte für $N$ und $M$ nochmals zugeordnet
werden müssten -- wird im generierten Token vermerkt, ob es sich um einen Vektor- oder Matrixtyp handelt.
Dazu überprüft der Scanner, ob ein Bezeichner den angegebenen Muster für Vektor- bzw. Matrixschlüsselwörtern entspricht.
Weiterhin werden bereits $N$ bzw. $M$ aus den Bezeichnern extrahiert und ebenfalls vermerkt.

Abbildung~\ref{fig:LexerToken} stellt die vom Scanner gesammelten Daten als Strukturdefinition dar.

\begin{figure}[h]
   \centering
  \lstinputlisting[language=C++]{snips/LexerToken.txt}
  \caption{Daten eines vom Scanner ausgegebenen Tokens}
  \label{fig:LexerToken}
\end{figure}

% Die zweite Ausnahme bilden Attributnamen~(\ref{Attribute}) inklusive Swizzles~(\ref{Vektorattribute}). Diese sind teilweise recht allgemein, und
% es erscheint wünschenswert, Bezeichner zuzulassen, die Attributnamen entsprechen -- z.B. ``length'', das auch ein Arrayattribut ist, und einbuchstabige
% Bezeichner wie ``x'', ``y'' etc., welche auch Vektorattribute (Swizzles) sind. Syntaktisch gibt es keine Mehrdeutigkeiten zwischen Attributen und
% anderen Bezeichnern -- ein Attribut kann \emph{nur} rechts eines \op{.} auftauchen, ein anderer Bezeichner dort nie.


Weiterhin schreibt die Spezifikation vor, dass zwei Bezeicher als identisch betrachtet werden, wenn sie kanonisch äquivalent im Sinne von Unicode sind.
Der Scanner speichert zu diesem Zweck alle Bezeichner in einer normalisierten Form. Diese ist vom Unicode-Standard vorgegeben:~\cite{unicode}, Annex \#15.

\section{Parser}

Der \emph{Parser} untersucht den vom Scanner gelieferten Strom von Tokens auf syntaktische Strukturen.
Es wird überprüft, ob der Token-Strom gültig im Sinne der in der Sprachspezifikation gegebenen Sprache ist --
sonst liegt ein \emph{Syntaxfehler} vor.

Während der Überprüfung werden auch syntaktische Elemente -- grundsätzlich Terminale wie Bezeichner oder numerische Werte -- extrahiert.
Diese werden bei der \emph{semantischen} Verarbeitung benötigt.

%- Lookahead: unendl.
%- Grammatik: kontextfrei, rechtsrekursiv

%\subsection{Eigenschaften der Grammatik}

%Die Grammatik ist kontextfrei. Die Regeln sind rechtsrekursiv.

\subsection{Aufbau des Parsers}

\newcommand\rulelink[1]{\glq\texttt{\detokenize{#1}}\grq~(\ref{#1})}

Der Parser ist nach der Methode des rekursiven Abstiegs (beschrieben in \cite{wirth_compiler}) handprogrammiert.
Der Aufbau spiegelt im Wesentlichen die Struktur der Regeln wieder -- viele haben ein direktes Gegenstück in einer Methode des Parsers.

\paragraph{Umgang mit Mehrdeutigkeiten:}
An einigen Stellen der Grammatik gibt es Mehrdeutigkeiten.
Werden beim Parsen eines \rulelink{programm_statements} die Tokens \glq\texttt{typ BEZEICHNER}\grq~(\ref{typ}, \ref{BEZEICHNER})  erkannt,
so kann es sich entweder um die Regel \rulelink{funktion_definition} oder um \rulelink{dekl_var} handeln.
Andere Fälle von Mehrdeutigkeiten sind \rulelink{dekl_var} oder \rulelink{kommando} in \rulelink{block} und
\rulelink{funktion_aufruf} oder \rulelink{BEZEICHNER} in \rulelink{asdr_basis}.

Solche Mehrdeutigkeiten lassen sich entweder in der Implementierung des Parsers oder durch Abändern der Grammatik lösen.

Bei der Parser-Lösung werden einfach weitere Tokens betrachtet. Im Falle eines  \rulelink{programm_statements}
wird auch das nächste Token nach \glq\texttt{typ}\grq{} und \glq\texttt{BEZEICHNER}\grq{} überprüft:
handelt es sich um \glq\texttt{(}\grq, ist die anzuwendende Regel \rulelink{funktion_definition};
handelt es sich um \glq\texttt{=}\grq, \glq\texttt{,}\grq{} oder \glq\texttt{;}\grq{} ist die anzuwendende Regel \rulelink{dekl_var};
andere Tokens sind ein Syntaxfehler. Eine Pseudo-Code-Version der Implementierung ist in Abbildung~\ref{fig:ParseProgramStatements}
aufgelistet.

In den Implementierungen der Regeln \rulelink{block} und \rulelink{asdr_basis} wurde analog verfahren.

Bei der Lösung von Mehrdeutigkeiten durch Abändern der Grammatik muss eine Regel erstellt werden,
die mit der mehrdeutigen Token-Sequenz beginnt. Dahinter werden als Alternativen neue Regeln angefügt,
die aus den "`Resttokens"' der ursprünglich mehrdeutigen Regeln bestehen müssen. % Hier ne Ref wäre vllt gut

Allerdings wird damit die Lesbarkeit der Grammatik eingeschränkt; nur für die Regel \rulelink{ausdruck} wurde dieser Ansatz verfolgt.
Für die anderen Regeln wurde das "`Vorausschauen"' von Tokens gewählt, da es in diesen Fällen einfach zu implementieren war
und die Grammatik besser lesbar bleibt.

\begin{figure}[!h]
   \centering
  \lstinputlisting[language=Java]{snips/ParseProgramStatements_pseudo.txt}
  \caption{Beispiel einer Parsing-Methode mit Auflösung von Mehrdeutigkeiten}
  \label{fig:ParseProgramStatements}
\end{figure}

\paragraph{Semantische Verarbeitung:}
% Die semantische Verarbeitung wird an ein Interface vom Typ \verb+SemanticHandler+ übergeben.
% Dieses Interface übernimmt die verschiedenen Aspekte der semantischen Verarbeitung, von der Verwaltung der
% Symboltabelle bis zu einer geeigneten internen Repräsentation von Ausdrücken.
Die semantische Verarbeitung wird von einer weiteren Komponente -- hier ``semantic handler'' genannt -- vorgenommen. 
Dieses Komponente übernimmt die verschiedenen Aspekte der semantischen Verarbeitung, von der Verwaltung der
Symboltabelle bis zu einer geeigneten internen Repräsentation von Ausdrücken. Die in der Komponente gespeicherten Informationen sind
in einem Rückkanal dem Parser zugänglich; so werden diese zum Beispiel benutzt um festzustellen, ob ein Bezeichner ein
Typ-Alias oder eine Funktion identifiziert.
Die Ausgabe des ``semantic handlers'' ist eine Zwischencoderepräsentation des Programms.

% \verb+SemanticHandler+ besitzt Methoden, um syntaktische Elemente -- wie Bezeichner und numerische Literale -- in Objekte 
% einzukapseln. Diese Objekte wiederum werden bei der Verarbeitung anderer syntaktischer Elemente
% zurück an das Interface übergeben. % Wenn Code-Schnipsel dann hier verweisen

% Beispiel: Bei einem Ausdruck \verb+a * 2+ werden von \verb+SemanticHandler+ zunächst Repräsentationen für
% \verb+a+ und \verb+2+ erfragt. Zurückgegeben werden Repräsentationen von "`Ausdrücken"'. Diese wiederum
% dienen als Argumente, um eine Repräsentation einer Multiplikation zu erhalten. Diese letzte Repräsentation kann
% dann überall dort verwendet werden, wo Ausdrücke erwartet werden: Zuweisungen, Funktionsparameter etc.

% Vom der \verb+SemanticHandler+-Implementierung zum Parser gibt es auch einen "`Rückkanal"'. Dies ist nötig, da bei einigen
% Konstrukten bekannt sein muss, ob ein Bezeichner eine Variable, eine Funktion oder einen Typ identifiziert:
% Das Ausdruck \verb+foo (1)+ ist, je nachdem ob \verb+foo+ eine Funktion, ein Typ-Alias oder eine Variable bezeichnet,
% entsprechend ein ein Funktionsaufruf, der Aufruf eines Typ-Konstruktors, oder ein ungültiger Ausdruck.

Verglichen mit dem "`klassischen"' Ansatz der semantischen Verarbeitung -- Parser erzeugt Abstract Syntax Tree (AST) als ersten Schritt,
semantische Analyse erzeugt Zwischencoderepräsentation im zweiten Schritt -- finden sich kleine Teile der semantischen
Analyse im Parser; die Erstellung eines ASTs wird übergangen, der ``semantic handler'' nimmt mit den vom
Parser übergebenen Informationen die restliche semantische Analyse vor und erzeugt sofort eine Zwischencoderepräsentation (beschrieben in Abschnitt~\ref{zcr}).

Die Erstellung eines AST wurde übergangen, da diese als unnötig angesehen wurde: eine direkte Ausgabe der Zwischencoderepräsentation
wurde als einfacher umzusetzen und für die weiteren Arbeitsschritte im Compiler als ausreichend angesehen. 
Insbesondere Optimierungen sind in der gewählten Zwischencoderepräsentation (ZCR) einfacher vorzunehmen als auf
einem AST. Auch werden in der ZCR wichtige semantische Informationen, wie Typen von Werten, Funktionssignaturen etc. gespeichert,
es tritt also kein Informationsverlust im Vergleich zu einem AST auf.

Weiterhin wurde die Implementierung so gestaltet, dass die Komponent des ``semantic handler'' relativ einfach austauschbar ist.
Sollte also notwendig werden, dass der Compiler einen AST des Programms erstellt, so wäre es prinzipiell möglich,
einen ``semantic handler'' zu schreiben der genau dies tut.

% Die Idee hinter dem \verb+SemanticHandler+ ist eine möglichst vollständige Trennung zwischen syntaktischer
% und semantischer Verarbeitung. Eine minimale Implementierung könnte intern eine
% AST-Repräsentation generieren (allerdings benötigt der Parser trotzdem auch einige semantische Informationen über
% Bezeichner).

% \begin{figure}[h]
%    \centering
%   \lstinputlisting[language=Java]{snips/ParseIf_pseudo.txt}
%   \caption{Zusammenspiel Parser und \texttt{SemanticHandler}: Parsen einer Verzweigung}
%   \label{fig:ParseIf}
% \end{figure}

\paragraph{Fehlerbehandlung:}
In der Implementierung wird die Fehlerbehandlung bei der syntaktischen wie auch semantischen Verarbeitung über \emph{Ausnahmen}
realisiert. Die Parser-Komponente selbst fängt dabei Ausnahmen ab, um zu gewährleisten, dass möglichst viel eines
Programms verarbeitet wird, um möglichst viele potentielle Fehler aufzudecken (wie in \cite{wirth_compiler} empfohlen):
tritt z.B. eine Ausnahme während der Verarbeitung eines Block-Kommandos auf, setzt der Parser die
Verarbeitung nach dem nächsten Semikolon -- also mit dem nächsten Kommando -- fort (sofern kein Ende
des Blockes festgestellt wird).
Die abgefangenen Ausnahmen werden jedoch nicht verworfen, sondern an ein Objekt zur Fehlerbehandlung
übergeben um eine Nachricht für den Benutzer darzustellen.

% \paragraph{Implementierung \texttt{SemanticHandler}:}
% In der vorgenommen Implementierung von \verb+SemanticHandler+ wird gleich eine Umsetzung in die Zwischencoderepräsentation vorgenommen
% (Beschreibung siehe Unten). Die Generierung eines ASTs als Zwischenschritt wurde als unnötig angesehen.
% Die Zwischencoderepräsentation erhält auch wichtige semantische Eigenschaften (wie Typinformationen) und
% die Verarbeitungsschritte "`Auftrennung"' und "`Optimierung"' lassen sich auf der Zwischencoderepräsentation besser vornehmen.

% Zuordnung Variable <-> akt. Register in Symboltabelle

\section{Zwischencoderepräsentation}
\label{zcr}

\input{ir_commands}

% Abstrakte(s) Beispiel(e): Quellcode + resultierende Zw.rep.

\subsection{Vorlagen der Zwischencoderepräsentation}

Als Vorlagen für die hier vorgestellte Zwischencoderepräsentation dienten das ``LLVM Instruction Set''~(\cite{LLVM:CGO04}),
SafeTSA~(\cite{SafeTSA}) und ``SIMPLE'' des McCAT Compiler-Projektes~(\cite{SIMPLE}).

% "Inspirationen": LLVM, Amme's SSA, GIMPLE/SIMPLE

%Das \emph{LLVM Instruction Set} (hier kurz ``LLVM'') 
\paragraph{LLVM}: LLVM ist ein \emph{Framework} für Compiler. Insbesondere will es ermöglichen, Optimierungen
eines Programms über dessen ganzen "`Lebenszyklus"' (inklusive Link- und Laufzeit) zu ermöglichen.

Das \emph{LLVM Instruction Set} ist der ausgegebene "`Objektcode"'. Das Programm wird -- ähnlich Maschinen-
oder Bytecode -- als eine Folge von einfachen Instruktionen auf Registern repräsentiert. 
Allerdings gibt es eine unbeschränkte Anzahl von typisierten Registern. Typumwandlungen sind immer explizit.
Die Instruktionen sind in SSA-Form.

% LLVM:
% - nicht gedacht als allg. Compiler-IR
% - keine Typsicherheit (nicht mehr als Maschinencode)
% - 
% - LLVM provides an inﬁnite set of typed virtual
% registers which can hold values of primitive types (Boolean,
% integer, ﬂoating point, and pointer). The virtual registers
% are in Static Single Assignment (SSA) form [15]. LLVM
% is a load/store architecture: programs transfer values be-
% tween registers and memory solely via load and store op-
% erations using typed pointers. The LLVM memory model is
% described in Section 2.3.
% - Opcodes: 3-Adress-Form
% - Ich->Mehr Opcodes als LLVM (unäre Op., Vektor-Op.)
% - Expliziter Kontrollflussgraph
% - abgeleitete Typen: Zeiger, Arrays, Structs, Funktionen
% - Typumwandlungen: explizit

% expliziter Kontrollfluss == keine GOTOs, sondern "Verweise" auf Blöcke/nächsten Schritt

\paragraph{SafeTSA:} Eine Art Objektcode, hauptsächlich zur Benutzung
als "`mobiler"' Code, d.h. zur Übertragung von Programmcode über Netzwerke wie das Internet.
Das Design von SafeTSA ist inhärent sicher. Bösartige Manipulationen von Programmen, die zu
problematischem Verhalten wie die Benutzung von undefinierten Werten oder Aliasing von Werten
eines anderen Typs führen, sind nicht möglich bzw. durch eine einfache Verifizierung feststellbar.

Die Instruktionen basieren auf der SSA-Form. Entsprechend gibt es eine beliebige Zahl von Registern.
Register sind in mehrere Sätze organisiert, ein Satz pro Typ. Instruktionen können nur auf einen
spezifischen Registersatz zugreifen. Verschiedene Instruktionsblöcke besitzen eigene Registersätze.

% SafeTSA:
% - erweiterte SSA
% - Zugriff auf Werte über Abstand in Dominatorbaum
% - Typtrennung: mehrere Registersätze; implizite Auswahl des Registersatzes
% - typisierter Konstantenpool
% - Registersätze per Basisblock
% - 

\paragraph{SIMPLE:} Als "`echte"' Compiler-Zwischencoderepräsentation für einen C-Compiler entwickelt
stellt sie Programme auf sehr hoher Ebene dar. Ausdrücke sind nicht in der SSA-Form, allerdings
"`vereinfacht"' auf zwei Operanden und einfache Strukturzugriffe. Symboltabelle und Typinformationen
sind erhalten. Typumwandlung, und andere in C implizite Verhalten, müssen explizit ausgedrückt werden.

% SIMPLE:
% - expliziter Kontrollfluss/zusammengesetzte Flusskontrollstatements
% - Typinformationen
% - klare Semantik (keine impliziten Verhalten wie autom. casts)
% - einfache Referenzen
% - einfache Statements

\paragraph{Zusammenfassung:}
Die gewählte Zwischencoderepräsentation ist größtenteils ein "`Querschnitt"' aus den obigen Repräsentationen
%(allerdings auch mit Aspekten aus keiner Vorlage, wie die Behandlung von Arrays).
(allerdings auch mit eigenständig entwickelten Aspekten, wie die Behandlung von Arrays).
Die meisten Eigenschaften
teilt die Zwischencoderepräsentation mit dem LLVM Instruction Set; chronologisch wurde dieses jedoch als letzte
Repräsentation betrachtet. Aus SafeTSA und SIMPLE stammen deshalb grundsätzliche Aspekte der Zwischencoderepräsentation 
-- einfache Statements, SSA-Form, separate Registersätze.

Anzumerken ist, dass die Shadingsprache keine zufälligen Speicherzugriffe oder Zeiger/Referenzen erlaubt.
Im Umfang ist sie teilweise beschränkt -- es gibt keine Strukturtypen --, besitzt aber als "`Eigenheit"' Vektortypen.
LLVM, SafeTSA und SIMPLE wurden für "`Maschinen"' entwickelt, die die Verwendung von Zeigern erlauben. Entsprechend
stellen sie Lösungen für Probleme, wie die Aliasing\footnote{Zugriff auf ein Datum über mehrere verschiedene Zeiger}-Analyse
oder typsichere Speicherzugriffe, bereit, die mit der hier spezifizierten Shadingsprache nicht vorkommen. Die genannten Repräsentationen sind hier nicht
mit ihren vollständigen Fähigkeiten in Hinsicht auf diese Aspekte beschrieben.

\subsection{Aufbau}

Bei der Gestaltung der \emph{Zwischencoderepräsentation} sollten folgende Rahmenbedingungen erfüllt werden:
\begin{itemize}
\item \emph{Eignung als Zwischenrepräsentation zwischen verschiedenen Arbeitsschritten des Compilers}.
Um die Komplexität des Compilers und den damit verbundenen Implementierungsaufwand klein zu halten
sollte \emph{ein} Format zur Zwischenrepräsentation für den compilerinternen Austausch verwendet werden.
(Andere Compiler verwenden verschiedene Formate zwischen Verarbeitungsschritten, siehe z.B.~\cite{SIMPLE}.)
\item Dies schliesst auch \emph{Eignung für Optimierungen} ein. Es sollten also genug Information enthalten sein,
um verschiedene Optimierungsalgorithmen umzusetzen. Idealerweise sollte die Zwischencoderepräsentation
diese Umsetzung von Optimierungen möglichst unterstützen und vereinfachen.
% \item Eignung als Ausgabe für Auftrenner?
\item Auch der \emph{Aufbau} sollte möglichst \emph{einfach} sein, damit Programme in der Zwischencoderepräsentation 
unkompliziert traversiert und manipuliert werden können.
\end{itemize}

Die Optimierbarkeit wird unterstützt, in dem der Zwischencoderepräsentation die \emph{``Single Static Assignment''-Form} (SSA, siehe~\cite{ssa1} und \cite{ssa2})
für Ausdrücke zugrunde liegt. Der gewünschte einfache Aufbau äußert sich darin, dass Befehle eines Programmes
in einer einfachen Reihung gespeichert werden -- ohne Sprungmarken oder ähnliches. Verzweigungen und Schleifen werden
durch "`komplexe"' Befehle realisiert (die intern wiederum Reihungen von Befehlen enthalten).

Das "`Grundelement"' der Zwischencoderepräsentation ist eine "`Sequenz"'. Eine Sequenz besteht aus "`Operationen"',
die auf "`Registern"' arbeiten. Register sind \emph{typisiert}, es gibt getrennte Registersätze, ein Satz für jeden verwendeten Typ. 
Der Aufbau einer Sequenz ist in Abbildung~\ref{fig:ir_sequence} schematisch dargestellt.

Die in Operationen gespeicherte Registeridentifikation verweist auf den zugehörigen Registersatz, Typinformationen bleiben also erhalten.
% Satz teil von Register-ID
%Jedes Register besitzt ausserdem einen Namen; dieser wird aber nur verwendet, um generierten Code lesbarer zu machen.

\begin{figure}[h]
   \centering
  \includegraphics{ir_sequence}
  \caption{Teile einer Sequenz}
  \label{fig:ir_sequence}
\end{figure}

Der wesentliche, von der SSA-Form entliehene, Aspekt ist, dass ein Register nur von \emph{einer} Operation der Sequenz beschrieben werden darf
(im Weiteren "`Register-Zuweisungs-Bedingung"' genannt).

Im Gegensatz zu einer "`reinen"' SSA-Form gibt es jedoch keine $\phi$-Operation. Stattdessen werden $\phi$-Operation bereits "`aufgelöst"'
gespeichert: soll z.B. bei einer Verzweigung eine Variable in einem Zweig verändert werden, so werden in beiden Zweigen Zuweisungen zum
entsprechenden Register generiert. Ein Zweig enthält die Zuweisung des neuen Wertes, der andere die Zuweisung des alten Wertes.

Anzumerken ist, dass dieses Auflösen nicht die oben gegebenen "`Register-Zuweisungs-Bedingung"' verletzt, da Verzweigungen und Schleifen
jeweils als \emph{eine} Operation in der Sequenz, in der sie verwendet werden, gelten.

Die Sichtbarkeit von Registern ist auf die Sequenz, in der sie deklariert wurden, beschränkt.
%Insbesondere können auf diese nicht implizit
%aus verschachtelten Blöcke (wie sie auch bei Bedingungen oder Schleifen vorkommen) zugegriffen werden. 
Insbesondere gibt es Sequenzoperationen, die andere Sequenzen einschachteln (Verzweigungen, Schleifen, Sequenzschachtelung).
Aus solch eingeschachtelten Blöcken kann \emph{nicht} implizit auf die Register aus dem umgebenden Block
zugegriffen werden.

Stattdessen werden zu eingeschachtelten Blöcken eine Zuordnung zwischen Registern aus dem umgebenden Block
("`extern"') und
Registern des eingeschachtelten Blockes ("`lokal"') gespeichert.
Wie genau die Abbildung von Werten von "`externen"' an "`lokale"' Register stattfindet ist ein Implementierungsdetail, dass dem Generator obliegt;
das Verhalten muss einem "`umleiten"' von Lese- oder Schreibzugriffen von den angegebenen lokalen auf die zugeordneten externen
Registern entsprechen.
%Wie genau die Übergabe von Werten von "`externen"' an "`lokale"' Register statfindet ist ein Implementierungsdetail, dass dem Generator obliegt;
%das Verhalten muss jedoch semantisch äquivalent zu einem Kopieren der externen Eingaberegister in lokale Register Anfang des Blockes
%und analog am Ende zu einem zurückkopieren von lokalen Registern in die externen Ausgaberegister sein.

Abbildung~\ref{fig:ir_seq_block_nest} zeigt eine Sequenz, in der die zweite Operation eine Sequenzschachtelung ist.
Der Sequenzoperation sind neben einem Verweis auf die auszuführende Sequenz auch Registerzuordnungen von
Registern der äusseren (einschachtelnden) zu Registern der inneren (eingeschachtelten) Sequenz.

\begin{figure}[h]
   \centering
  \includegraphics{ir_seq_block_nest}
  \caption{Schema einer Sequenzschachtelung}
  \label{fig:ir_seq_block_nest}
\end{figure}

\paragraph{Funktionen:}
Eine Funktion der Zwischencoderepräsentation besteht aus einem eindeutigem Bezeichner, einer Liste von Eingabeparametern,
einer Liste von Ausgabeparametern und einer Sequenz mit den eigentlichen Funktionsoperationen.
Ein eventueller Rückgabewert ist nur ein weiterer Ausgabeparameter.
Abbildung~\ref{fig:ir_function} ist eine schematische Abbildung einer Funktion.

%Jede Überladung einer Funktion wird in der Zwischencoderepräsentation durch einen eindeutigen Bezeichner identifiziert.
%Dieser wird aus dem ursprünglichen Bezeichner sowie einer aus den Parametertypen generierten "`Signatur"' konstruiert.
Bei überladenen Funktionen muss die auszuführende Variante der Funktion in der Zwischencoderepräsentation
explizit angegeben werden.
Aus diesem Grund wird in der Zwischencoderepräsentation jede Überladung einer Funktion durch einen eindeutigen Bezeichner identifiziert.

Parameter werden mit einem Mechanismus, der der Behandlung "`externer"' Register in einem eingeschachteltem
Block ähnelt, übergeben. Die Parameterlisten enthalten zu jedem Eingabeparameter ein lokales Register, in dem die
Sequenz den Wert des Parameters "`erwartet"'. Analog wird jedem Ausgabeparameter ein Register zugeordnet,
in dem bei Verlassen der Funktion der zurückzugebende Wert liegt.
(Die genaue Umsetzung dieses Verhaltens ist ein Implementierungsdetail, dass dem Generator obliegt.)

Ein Parameter, der gleichzeitig Ein- wie auch Ausgabeparameter ist, wird "`verdoppelt"', d.h. es wird daraus
ein nur-Eingabe- sowie auch ein nur-Ausgabe-Parameter generiert. Bei Funktionsaufrufen werden den beiden
Parametern auch entsprechend verschiedene Register zugeordnet.

\begin{figure}[h]
   \centering
  \includegraphics{ir_function}
  \caption{Schema einer Funktionsbeschreibung}
  {\small für eine Funktion deklariert mit \texttt{float lerp (float a, float b, float factor)}.}
  \label{fig:ir_function}
\end{figure}

\paragraph{Globale Variablen:}
Echte globale Variablen sind nicht vorgesehen. Sie werden nachgebildet, in dem in einer Funktion gelesene globale Variablen
auf spezielle, "`versteckte"' Eingabeparameter abgebildet werden. Geschriebene globale Variablen werden
auf spezielle Ausgabeparameter abgebildet. Nur in der Eintrittsfunktion werden globalen Variablen tatsächlich
"`eigene"' Register zugewiesen. Im Prinzip sind "`globale"' Variablen "`versteckte"' lokale Variablen in
der Eintrittsfunktion.

Damit müssen globale Variablen von Optimierungsschritten u.ä. nicht besonders berücksichtigt werden.
Insbesondere müssen keine "`Seiteneffekte"' von Funktionen ermittelt werden: manipuliert eine Funktion eine "`globale"' Variable,
so erhält sie in der Zwischencoderepräsentation einen weiteren Ausgabeparameter.
Betrachtet man den Aufruf dieser Funktion so wird nur eine weitere Variable beschrieben.

Optimierungsschritte wie Constant Propagation oder Dead Code Elimination. aber auch der Auftrennungs-Schritt werden vereinfacht,
da nur "`lokale"' Variablen berücksichtigt werden müssen; gleichzeitig werden als global deklarierte Variablen
von solchen Verarbeitungsschritten korrekt behandelt.

%Stattdessen werden zu eingeschachtelten Blöcken gespeichert, welche Register von dem Block gelesen oder
%beschrieben werden sollen

%Soll ein Register in einem eingeschachteltem Block gelesen oder beschrieben werden, 

\paragraph{Behandlung von Arrays:}
Arrays werden als "`ein"' Wert behandelt -- eine Zuweisungsoperation kopiert immer ein ganzes Array.
Das Lesen einzelner Elemente geschieht mit Hilfe der Operation "`Extraktion eines Arrayelements"' ($\mathtt{getelem}$).

Zum Schreiben eines Elements gibt es die Operation "`Änderung eines Arrayelements"' ($\mathtt{setelem}$):
%diese kopiert alle Elemente eines Arrays in das Zielarray \emph{außer} das Element eines gegebenen Indexes;
%im Zielarray wird dort der zu schreibende Wert abgelegt.
diese kopiert alle Elemente, bis auf das zu ändernde Element, eines Arrays in das Zielarray;
dort wird am gegebenen Index der zu schreibende Wert abgelegt.
Dieser Ansatz wurde gewählt, weil er sehr gut in das "`SSA-Prinzip"' passt.
Bei der direkten Umsetzung eines Zugriffs auf Array-Elemente (Ausdrücke wie eine Zuweisung "`$a[i] = x$"') ist es schwierig, sicherzustellen, dass
jedes Element von $a$ wie verlangt nur einmal beschrieben wird (insbesondere bei Schleifen); es
müsste für jedes Array-Element individuell "`verfolgt"' werden, ob es beschrieben wurde.
Ein solches Verfolgen wird weiterhin schwieriger, sobald die Array-Größe nicht bekannt ist
-- die spezifizierte Sprache sieht dies vor. Das betrachten eines Arrays als "`einen"' Wert macht es hingegen einfach,
die Bedingung "`nur eine Zuweisung"' einzuhalten und zu überprüfen.
% Andere Alternativen? Wie in LLVM, SafeTSA? Wer hat sich noch über Arrays Gedanken gemacht?

Für manche Optimierungen ist es trotzdem von Vorteil, die einzelnen Elemente eines Arrays zu verfolgen -- sind diese
z.B. Konstanten können die Werte an einer Konstantenfaltung teilnehmen. Solche Möglichkeiten der Optimierungen
bleiben bestehen: sind Größe und Elementwerte eines Arrays bekannt, kann ein Optimierer diese wie individuelle
Register durch die Arrayoperationen hindurch verfolgen, oder sogar ein Array auf individuelle Register "`aufteilen"'.

\subsection{Sequenz-Operationen}

Dieser Abschnitt zählt alle möglichen Operationen in einer Sequenz auf. Eine Operation greift für die Eingabe auf kein, ein oder mehrere
\emph{Quellregister} zu. Hat die Operation ein Ergebnis, wird dieses in ein \emph{Zielregister} geschrieben. 

Für jede Operation wird ein einfaches Beispielprogramm gegeben; diesem wird der generierte Zwischencode gegenüber gestellt.

%Unter vielen Operationen ist das Verhalten in Pseudo-Code angegeben. Dabei steht $d$ für das Zielregister einer Operation.
%Die Quellregister werden durch $s$, $t$, \dots bezeichnet. 

\newpage
\subsubsection{Einfache Operationen}

\newcommand\SeqOpSample[2]{
  %\begin{figure}[!h]
  \renewcommand{\baselinestretch}{1.0}\normalsize
  \emph{Beispiel und Zwischencode:}\\
  \makebox[\textwidth]{
    \centering
    \begin{minipage}{7cm}\lstinputlisting{s1source/#1.s1}\end{minipage}
    \begin{minipage}{8cm}\include{s1latex/#1}\end{minipage}
    %\caption{#2.}
    \label{fig:ir_example_#1}
  %\end{figure}
  }
  \renewcommand{\baselinestretch}{1.50}\normalsize
}
\newcommand\SeqOpSampleStacked[2]{
  %\begin{figure}[!h]
  \vspace*{1em}
  \emph{Beispiel und Zwischencode:}
  \vspace*{-1em}
  \renewcommand{\baselinestretch}{1.0}\normalsize
  %\makebox[\textwidth]{
    \begin{center}
    \begin{minipage}{7cm}\lstinputlisting{s1source/#1.s1}\end{minipage}
    \begin{minipage}{\textwidth}\include{s1latex/#1}\end{minipage}
    %\caption{#2.}
    \label{fig:ir_example_#1}
    \end{center}
    \vspace*{-1em}
  %\end{figure}
  %}
  \renewcommand{\baselinestretch}{1.50}\normalsize
}

\paragraph{Zuweisungsoperation:} Kopiert Inhalt eines Registers in ein anderes.
%\\\hspace*{1cm}$d \gets s$

\SeqOpSample{assign}{Zuweisungsoperation}


\paragraph{Konstantenoperation:} Diese weist dem Zielregister eine Boolesche, Integer- (vorzeichenlos oder vorzeichenbehaftet) oder
Fließkommakonstante zu.

%\\\hspace*{1cm}$d \gets \mathrm{Konstante}$
\SeqOpSample{const}{Konstantenoperation}


\paragraph{Typumwandlungsoperation:} Liest das Eingaberegister, wandelt dessen Wert in den Ziel-Typ und schreibt den umgewandelten Wert in das Zielregister.
Kann zwischen Integer- (vorzeichenlos oder vorzeichenbehaftet) und Fließkommawerten umwandeln.

%\\\hspace*{1cm}$d \gets s\ \mathrm{als}\ \mathrm{"`Ziel-Typ``}$
\SeqOpSample{cast}{Typumwandlungsoperation}


% Eventuell Tabelle (Operation|Verknüpfung|Eing-Typ|Ausg-Typ) statt Prosa?
\paragraph{Arithmetische Operation:} Die Inhalte zweier Eingaberegister 
werden durch eine arithmetische Operation verknüpft und das Ergebnis in das Zielregister geschrieben.
Die Eingaberegister und das Zielregister müssen vom gleichen Typ sein -- Integer- (vorzeichenlos oder vorzeichenbehaftet) und Fließkommawerte.

%\\\hspace*{1cm}$d \gets s + t$
%\\\hspace*{1cm}$d \gets s - t$
%\\\hspace*{1cm}$d \gets s * t$
%\\\hspace*{1cm}$d \gets s / t$
\SeqOpSample{arith}{Arithmetikoperationen}


\paragraph{Vergleichsoperation:} Die Inhalte zweier Eingaberegister 
werden miteinander verglichen (gleich, ungleich, größer, größer gleich, kleiner oder kleiner gleich) und das Ergebnis in das Zielregister geschrieben.
Die Eingaberegister müssen vom gleichen Typ sein -- Integer- (vorzeichenlos oder vorzeichenbehaftet) und Fließkommawerte.
Das Zielregister muss vom Typ Boolean sein.

%\\\hspace*{1cm}$d \gets s = t$
%\\\hspace*{1cm}$d \gets s < t$
%\\\hspace*{1cm}$\phantom{d \gets}\vdots$
\SeqOpSample{compare}{Vergleichsoperationen}


\paragraph{Logische Operation:} Die Inhalte zweier Eingaberegister werden durch logisch UND oder logisch ODER verknüpft und das Ergebnis in das Zielregister geschrieben.
Die Eingaberegister und das Zielregister müssen vom Typ Boolean sein.

%\\\hspace*{1cm}$d \gets s \land t$
%\\\hspace*{1cm}$d \gets s \lor t$
\SeqOpSample{logic}{Logische Operationen}


\paragraph{Unäre Operation:} Unäre Operationen sind Negation, logisches NICHT und bitweise Invertierung.

Negation negiert den Wert des Eingaberegisters und schreibt das Ergebnis in das Zielregister.
Die Eingabe- und das Zielregister müssen vom gleichen Typ sein -- Integer- (vorzeichenlos oder vorzeichenbehaftet) und Fließkommawerte.\\
Logisches NICHT invertiert den Wert des Eingaberegisters und schreibt das Ergebnis in das Zielregister.
Die Eingabe- und das Zielregister müssen vom gleichen Typ Boolean sein.\\
Bitweise Invertiertung wird auf das Eingaberegister angewendet und schreibt das Ergebnis in das Zielregister.
Die Eingabe- und das Zielregister müssen von einem Integer-Typ (vorzeichenlos oder vorzeichenbehaftet) sein.

%\\\hspace*{1cm}$d \gets \neg s$
%\\\hspace*{1cm}$d \gets -s$
%\\\hspace*{1cm}$\phantom{d \gets}\vdots$
\SeqOpSample{unary}{Unäre Operationen}


\subsubsection{Vektor- und Matrix-Operationen}

\paragraph{Vektor-Erstellung:} Nimmt als Eingabe ein bis vier Register, je nach der Komponentenanzahl des Zielregisters. Die Eingaberegister müssen alle
den Basistyp des Zielregisters besitzen. Sie werden der Reihe nach den Vektorkomponenten im Zielregister zugeordnet.
%\\\hspace*{1cm}$d \gets (s)$
%\\\hspace*{1cm}$d \gets (s, t)$
%\\\hspace*{1cm}$\phantom{d \gets}\vdots$

\SeqOpSample{makevec}{Vektor-Erstellung}


\paragraph{Extraktion einer Vektorkomponente:} Nimmt neben einem Eingaberegister auch eine Integer-Konstante $N$ im Bereich $0 \dots 3$ entgegen.
Das Eingaberegister muss von einem Vektortyp sein. Das Zielregister muss vom Basistyp des Vektors sein.
Aus dem Eingabevektor wird die Komponente Nummer $N$ extrahiert und in das Zielregister geschrieben.
%\\\hspace*{1cm}$d \gets s_N$

\SeqOpSample{vecextract}{Extraktion einer Vektorkomponente}


\paragraph{Matrix-Erstellung:} Nimmt als Eingabe ein bis sechzehn Register, je nach den Dimensionen des Zielregisters. Die Eingaberegister müssen alle
den Basistyp des Zielregisters besitzen. Sie werden der Reihe nach den Elementen im Zielregister zugeordnet: zuerst das Element der ersten Spalte in der ersten Zeile,
als nächstes das Element der zweiten Spalte in der ersten Zeile, usw.
%\\\hspace*{1cm}$d \gets \left(s\right)$
%\\\hspace*{1cm}$d \gets \left(\begin{array}{cc}s&t\\u&v\end{array}\right)$
%\\\hspace*{1cm}$\phantom{d \gets}\vdots$

\SeqOpSampleStacked{makematrix}{Matrix-Erstellung}

\subsubsection{Array-Operationen}

\paragraph{Array-Erstellung:} Nimmt als Eingabe eine variable Anzahl von Registern, die Anzahl der Eingaberegister bestimmt die Länge des Arrays.
Die Eingaberegister müssen alle den Basistyp des Zielregisters besitzen. Sie werden der Reihe nach den Array-Elementen im Zielregister zugeordnet.
%\\\hspace*{1cm}$d \gets (s, t, \dots)$

\SeqOpSampleStacked{makearray}{Array-Erstellung}


\paragraph{Extraktion eines Arrayelements:} Verwendet zwei Eingaberegister: ein Arrayregister sowie als Index ein Register mit einem vorzeichenlosen Integer.
Aus dem Array wird das Element mit dem gegebenen Index extrahiert und in das Zielregister geschrieben.
Das Zielregister muss den Basistyp des Array-Registers besitzen.
%\\\hspace*{1cm}$d \gets s[t]$

\SeqOpSampleStacked{arrayextract}{Extraktion eines Arrayelements}


\paragraph{Änderung eines Arrayelements:} Verwendet drei Eingaberegister: neben einem Arrayregister und dem Indexregister (vorzeichenloser Integer)
weiterhin ein Register vom Basistyps des Arrays (der "`neue Wert"').
Aus dem Eingabearray werden alle Elemente \emph{außer} das Element des gegebenen Indexes in das Zielarray kopiert;
dort wird stattdessen der "`neue Wert"' abgelegt. Das Zielregister muss den Typ des Arrayregisters besitzen.
%\\\hspace*{1cm}$d \gets (x | x = s[i]\ \mathrm{f"ur\ alle}\ i \neq t, u\ \mathrm{sonst})$

In Pseudocode ausgedrückt:
\begin{lstlisting}
// Eingaben: Array, Index, NeuerWert
// Ausgabe: Zielarray
for element = 0 to Array.length-1
{
  if (element == Index)
    ZielArray[element] = NeuerWert;
  else
    ZielArray[element] = Array[element];
}
\end{lstlisting}

\SeqOpSampleStacked{arraychange}{Änderung eines Arrayelements}


\paragraph{Arraylänge:} Nimmt im Eingaberegister ein Array entgegen. Schreibt in das Zielregister, welches vom Typ "`vorzeichenloser Integer"' sein muss,
die Anzahl der Elemente des Arrays.
%\\\hspace*{1cm}$d \gets |s|$

\SeqOpSampleStacked{arraylen}{Arraylänge}

\subsubsection{Komplexe Operationen}

\paragraph{Sequenzschachtelung:} Eine Operation, die auf eine weitere, eingeschachtelte Sequenz verweist, welche beim Ausführen der Operation abgearbeitet wird.
Neben dem Verweis auf eine Sequenz werden auch Listen von "`importierten"' und "`exportierten"' Namen zu der Operation gespeichert.
Jedem Namen ist weiterhin ein Register in der eingeschachtelten Sequenz zugeordnet.

Für den Zugriff auf Register der "`umgebenden"' Sequenz wird von dieser 
beim Einfügen der Operation eine Zuordnung von "`importierten"' und "`exportierten"' Namen der
eingeschachtelten Sequenz zu Registern der umgebenden Sequenz vorgenommen. 
%Diese Zuordnung wird benutzt, um vor der Abarbeitung der eingeschachtelten Sequenz Registerwerte von der umgebenden in die eingeschachtelte Sequenz zu kopieren.
%Nach der Abarbeitung erfolgt ein Kopieren in die umgekehrte Richtung.

Eine Sequenzschachtelung gilt als \emph{eine} Operation in der umgebenden Sequenz. Solange die Zuordnung von "`exportierten"' Namen der
eingeschaltelten Sequenz zu Registern der umgebenden Sequenz korrekt ist (es wird kein Register verwendet, das bereits beschrieben wurde), bleibt die Register-Zuweisungs-Bedingung erfüllt.

\SeqOpSampleStacked{nest_seq}{Sequenzschachtelung (Rahmen symbolisiert eingeschachtelte Sequenz)}

\paragraph{Verzweigung:} Eine auf der Sequenzschachtelung basierende Operation. Eingaben sind zwei Sequenzen (eine ``if''- und eine ``else''-Sequenz) sowie ein Register vom
Typ Boolean mit dem Wert der Bedingung. Ist dieser "`wahr"', wird die ``if''-Sequenz ausgeführt, sonst die ``else''-Sequenzen. Es müssen immer beide Sequenzen
gegeben werden, Sequenzen können aber leer sein.
%Soll ein Register in einer Verzweigung beschrieben werden, so muss dies immer in \emph{beiden} Blöcken geschehen, da ansonsten je nach Ausführungspfad ein
%Register undefinierte Wert

%Ein Register kann in beiden Blöcken beschrieben werden (z.B. wenn im Quellcode eine Variable von einer Bedingung abhängig unterschiedliche Werte zugewiesen wurden).
%Eine Verzweigung gilt als \emph{eine} Operation in der umgebenden Sequenz. D.h. auch wenn ein Register in beiden Blöcken beschrieben wird, wird es,
%von der umgebenden Sequenz aus gesehen, bloß von einer Operation beschrieben (eben der Verzweigung). Damit bleibt die Register-Zuweisungs-Bedingung erfüllt.
Ein beschriebenes "`exportiertes"' Register muss in beiden Untersequenzen beschrieben werden: würde in einer Verzweigung
in nur einer Sequenz ein Register beschrieben werden, würde bei Ausführung des "`anderen"' Pfades entweder zur Laufzeit das Register einen undefinierten Wert besitzen, oder
es müsste anderweitig überschrieben werden, was die Register-Zuweisungs-Bedingung verletzt. Um diese Probleme zu vermeiden wird verlangt,
dass in der "`anderen"' Sequenz eine Zuweisung (typischerweise vom "`alten"' Wert der dem Register entsprechenden Variable) vorgenommen werden muss.

Da eine Verzweigung als \emph{eine} Operation in der umgebenden Sequenz gilt, wird ein Register, auch wenn es in beiden Blöcken beschrieben wird, 
von der umgebenden Sequenz aus gesehen bloß von einer Operation beschrieben (eben der Verzweigung). Damit bleibt die Register-Zuweisungs-Bedingung erfüllt.

%\\\hspace*{1cm}$\mathrm{if}\ s\ \mathrm{then}\ \mathit{Block}\ \mathrm{else}\ \mathit{Block}$

%Um die SSA-Bedingungen zu erfüllen, aber

Abbildung~\ref{fig:ir_seq_branch} zeigt schematisch eine Verzweigungsoperation in einer Sequenz.
Zuerst wird der Bedingungswert \texttt{Z} berechnet. Die Verzweigungsoperation selbst enthält dazu noch
Verweise auf die ``if''- und ``else''-Sequenzen, zu denen es jeweils Zuordnungen von "`importierten"' und "`exportierten"' 
Namen der umgebenden Sequenz zu Registern der verwiesenen Sequenz gibt.

\begin{figure}[h]
   \centering
  \includegraphics{ir_seq_branch}
  \caption{Schema einer Verzweigungsoperation.}
  \small\includegraphics[height=10pt]{ir_seq_torquoise_arrow} symbolisiert die Registerzuordnungen aus Abb.~\ref{fig:ir_seq_block_nest}.
  \label{fig:ir_seq_branch}
\end{figure}

\SeqOpSampleStacked{branch}{Verzweigung}

\paragraph{While-Schleife:} Eine auf der Sequenzschachtelung basierende Operation. Eingaben sind eine Sequenz sowie zwei Register vom
Typ Boolean, jeweils mit einem Wert der Bedingung: das erste Register enthält die Bedingung \emph{vor} der ersten Ausführung der Sequenz,
das zweite Register die Bedingung \emph{nach} einer Ausführung der Sequenz.

Werte, die sich von Schleifendurchlauf zu Schleifendurchlauf ändern, werden ähnlich behandelt: es muss jedem solchen Wert ein lokales
Register im Schleifenkörper zugeordnet werden. Die Schleifenoperation selber erhält eine Abbildung von einem Paar "`externer"' Register
(Wert vor der ersten Ausführung sowie Wert nach einer Ausführung) zu den lokalen Registern als weitere Eingabe.
Durch diese Verwendung von Paaren von Eingaben ist es möglich, Werte in einem Schleifendurchlauf zu beschreiben
und im nächsten Durchlauf wieder als Eingabe für eine Operation zu verwenden: bei ein Quellcode wie 
\texttt{int i = 0; while (...) \{ i = i + 1; \}} müssten, ohne Registerpaare, bei \texttt{i = i + 1} entweder Eingabe-\texttt{i}
wie auch Ergebnis-\texttt{i} auf das gleiche Register umgesetzt werden -- welches entsprend mehrfach zugewiesen wird -- oder aber verschiedene Register, wobei
Eingabe-\texttt{i} immer den anfänglichen Wert \texttt{0} besitzen würde. Registerpaare erlauben es, dass im ersten Durchlauf
der anfängliche Wert \texttt{0} für Eingabe-\texttt{i} verwendet wird, in anschliessenden Durchläufen aber der Wert des Ergebnis-\texttt{i}
des letzten Durchlaufs.

%Durch die Verwendung eines
%Paares von Eingaben wird die Verwendung der $\phi$-Funktion vermieden.

Ein Register kann also in mehreren Schleifendurchläufen beschrieben werden.
Da aber eine Schleife als \emph{eine} Operation in der umgebenden Sequenz gilt, wird auch ein mehrmals beschriebenes Register,
von der umgebenden Sequenz aus gesehen, bloß von einer Operation beschrieben (eben der Schleife).
Damit bleibt die Register-Zuweisungs-Bedingung erfüllt.

Es gibt keine spezielle Operation für \texttt{for}-Schleifen, diese werden auf \texttt{while}-Schleifen abgebildet.
%\\\hspace*{1cm}$\mathrm{while}\ s\ \mathrm{do}\ \mathit{Block}$

\SeqOpSampleStacked{while}{Schleife}

\subsubsection{Funktions-Operationen}

\paragraph{Funktionsaufruf:} Diese Operation nimmt einen Funktionsbezeichner, eine Liste Eingabe-Register und eine Liste Ausgabe-Register
entgegen.
% Rückgabewert?
Die Eingaberegister werden der Position nach auf die Funktionsparameter abgebildet.

Der "`Bezeichner"' ist eine prinzipiell beliebig wählbare Zeichenkette, die die Funktion bezeichnet. Dem Code-Generator muss
vorher eine Funktionsbeschreibung übergeben worden sein, die durch den Bezeichner identifiziert werden kann.
%\\\hspace*{1cm}$d \gets \mathrm{Funktion}\ (s, \dots)$
%\\\hspace*{1cm}$\mathrm{Funktion}\ (s, \dots)$

\emph{Beispiel siehe nächster Absatz.}


\paragraph{Funktionsrücksprung:} Damit wird die Funktion verlassen. Es wird eine Liste von Registern entgegen genommen. Diese
werden, der Position nach, den Ausgabeparametern der Funktion zugewiesen.
%\\\hspace*{1cm}$\mathrm{return}\ s$
%\\\hspace*{1cm}$\mathrm{return}$

\SeqOpSampleStacked{funccall}{Funktionsaufruf und -rücksprung}


\paragraph{Vordefinierte Funktion:} Diese Operation sammelt den Zugriff auf vordefinierte Funktionen (siehe~\ref{builtins})
und arbeitet analog zu Funktionsaufrufen. Es wird eine Konstante, welche die Funktion identifiziert, eine Liste Eingabe-Register 
und ein Zielregister für den Rückgabewert entgegen genommen. Die Eingaberegister werden wieder der Position nach auf die Funktionsparameter abgebildet.
%\\\hspace*{1cm}$d \gets \mathrm{pow}(s, t)$
%\\\hspace*{1cm}$d \gets s \cdot t$
%\\\hspace*{1cm}$\phantom{d \gets}\vdots$

\SeqOpSampleStacked{funcbuiltin}{Vordefinierte Funktion}


%$\phi$-Funktion: diese konkrete Zwischencoderepräsentation eines compilierten Programmes enthält nicht die bei SSAs wesentliche $\phi$-Funktion.

% \subsection{Textdarstellung}

% Die folgende Tabelle listet auf, wie die verschiedenen Sequenzoperationen in den Beispielen als Text dargestellt werden.
% Bei den Parametern steht $d$ für das Zielregister einer Operation, $s$, $t$ bezeichnen die Quellregister.

% \begin{longtable}{ l l p{4cm} }
% Zuweisung & \begin{array}[t]{ll}\sOassign{d}{s}\\\sOassign{d}{\mathrm{Konstante}}\end{array}\\
% \hline
% Typumwandlung & \begin{array}[t]{ll}\sOcast{float}{d}{s}\\\sOcast{int}{d}{s}\\\sOcast{uint}{d}{s}\end{array}\\
% \hline
% Arithmetische Operationen & \begin{array}[t]{ll}\sOadd{d}{s}{t}\\\sOsub{d}{s}{t}\\\sOmul{d}{s}{t}\\\sOdiv{d}{s}{t}\\\sOmod{d}{s}{t}\end{array}\\
% \hline
% Vergleichsoperation & \begin{array}[t]{ll}\sOcmpeq{d}{s}{t}\\\sOcmpne{d}{s}{t}\\\sOcmplt{d}{s}{t}\\\sOcmple{d}{s}{t}\\\sOcmpgt{d}{s}{t}\\\sOcmpge{d}{s}{t}\end{array}\\
% \hline
% Logische Operation & \begin{array}[t]{ll}\sOand{d}{s}{t}\\\sOor{d}{s}{t}\end{array}\\
% \hline
% Unäre Operation & \begin{array}[t]{ll}\sOinv{d}{s}\\\sOneg{d}{s}\\\sOnot{d}{s}\end{array}\\
% \hline
% Vektor-Erstellung & \begin{array}[t]{ll}\sOmakevec{d}{\dots}\end{array} & Zahl der Quellregister variiert\\
% Extraktion einer Vektorkomponente & \begin{array}[t]{ll}\sOvecextract{d}{s}{\mathrm{n}}\end{array} & $n$ ist konstante Komponentennummer\\
% \hline
% Matrix-Erstellung & \begin{array}[t]{ll}\sOmakematrix{d}{\dots}\end{array} & Zahl der Quellregister variiert\\
% \hline
% Array-Erstellung & \begin{array}[t]{ll}\sOmakearray{d}{\dots}\end{array} & Zahl der Quellregister variiert\\
% Extraktion eines Arrayelements & \begin{array}[t]{ll}\sOgetelem{d}{s}{i}\end{array} & $i$: zu extrahierender Index\\
% Änderung eines Arrayelements & \begin{array}[t]{ll}\sOsetelem{d}{s}{i}{t}\end{array} & $t$: neuer Elementwert\\
% Arraylänge & \begin{array}[t]{ll}\sOarraylen{d}{s}\end{array}\\
% \hline
% Sequenzschachtelung & \begin{array}[t]{ll}\sOnestseq{Sequenz}\end{array}\\
% \hline
% Verzweigung & \begin{array}[t]{ll}\sObranch{c}{if-Sequenz}{else-Sequenz}\end{array} & $c$: Bedingungsregister\\
% \hline
% While-Schleife & \begin{array}[t]{ll}\sOwhile{c_0}{c_n}{Sequenz}\end{array} & $c_0, c_n$: Bedingungsregister erster Durchlauf/weitere Durchläufe\\
% \hline
% Funktionsaufruf & \begin{array}[t]{ll}\sOcall{\mathrm{Funktion}}{\dots}\\\sOcallret{d}{\mathrm{Funktion}}{\dots}\end{array} & Zahl der Quell- und Zielregister variiert\\
% \hline
% Funktionsrücksprung & \begin{array}[t]{ll}\sOreturnvoid\\\sOreturn{s}\end{array}\\
% \hline
%% Vordefinierte Funktion
% Skalarprodukt & \begin{array}[t]{ll}\sObuiltindot{d}{s}{t}\end{array}\\
% Vektorprodukt & \begin{array}[t]{ll}\sObuiltincross{d}{s}{t}\end{array}\\
% Matrixmultiplikation & \begin{array}[t]{ll}\sObuiltinmul{d}{s}{t}\end{array}\\
% Normalisierung & \begin{array}[t]{ll}\sObuiltinnormalize{d}{s}\end{array}\\
% Euklidische Länge & \begin{array}[t]{ll}\sObuiltinlength{d}{s}\end{array}\\
% Minimum & \begin{array}[t]{ll}\sObuiltinmin{d}{s}{t}\end{array}\\
% Maximum & \begin{array}[t]{ll}\sObuiltinmax{d}{s}{t}\end{array}\\
% Potenz & \begin{array}[t]{ll}\sObuiltinpow{d}{s}{t}\end{array}\\
% Textur auslesen & \begin{array}[t]{ll}\sObuiltintexOneD{d}{s}{t}\\\sObuiltintexTwoD{d}{s}{t}\\\sObuiltintexThreeD{d}{s}{t}\\\sObuiltintexCUBE{d}{s}{t}\\\end{array}\\
% \end{longtable}

\subsection{Beispiel}

Abbildung~\ref{fig:ir_sample_src} zeigt ein einfaches Programm in der Sprache, Abbildung~\ref{fig:ir_sample_gen} die generierte Zwischencoderepräsentation.

\begin{figure}[h]
   \centering
  \lstinputlisting{s1source/sample_minimal.s1}
  \caption{Quelltext eines Programms.}
  \label{fig:ir_sample_src}
\end{figure}
\begin{figure}[h]
   \centering
  \input{s1latex/sample_minimal.tex}
  \caption{Zu~\ref{fig:ir_sample_src} generierte Zwischencoderepräsentation.}
  \label{fig:ir_sample_gen}
\end{figure}

\section{Auftrennung}
\label{Auftrennung}

% High-Level Arbeitsweise
Der "`\emph{Splitter}"' trennt ein als Zwischencoderepräsentation vorliegendes Programm in ein \emph{Vertex-} und ein \emph{Fragmentprogramm} auf.
Die Entscheidung wird für individuelle Sequenzoperationen getroffen. Jeder Operation lässt sich eine \emph{Berechnungsfrequenz} (siehe unten),
in der diese Operation ausgeführt wird, zuordnen. Diese bestimmt, in welche Programme eine Operation ausgegeben wird.

\subsection{Definition Berechnungsfrequenz}
\label{Berechnungsfrequenz}

Aus den Beobachtungen in Abschnitt~\ref{berechnungsfrequenz_locker} lässt sich formulieren:
Die \emph{Berechnungsfrequenz eines Ausdrucks} beschreibt, wie oft sich der Wert des gegebenen Ausdrucks, auf alle Ausführungen eines
Programmes gesehen, ändert.

Die kleinstmögliche Frequenz besitzen statische Konstanten.

Die höchstmögliche Frequenz besitzen Ausdrücke, die bei jeder Auswertung einen anderen Wert liefern.
\emph{(Beispiel: Werte aus einer externen Datenquelle.)}

\subsection{Berechnungsfrequenzen bei Shading}

Bei Shadingsprachen sind folgende speziellen Berechnungsfrequenzen vorhanden:
\begin{itemize}
\item \emph{Mesh-Frequenz}: Ausdruck ist konstant während der Darstellung eines Dreiecksnetzes, aber nicht zwischen
verschiedenen Dreiecksnetzen oder Darstellungsläufen. %\emph{(Beispiel: Position in Weltkoordinaten.)}
\item \emph{Vertex-Frequenz}: Ausdruck ändert sich von Vertex zu Vertex. %\emph{(Beispiel: Texturkoordinaten.)}
\item \emph{Fragment-Frequenz}: Ausdruck ändert sich von Fragment zu Fragment. %\emph{(Beispiel: Aus Textur gelesener Wert.)}
\end{itemize}

Als Besonderheit kommt hinzu, dass aus Daten mit \emph{Vertex-Frequenz} durch lineare Interpolation Daten mit
\emph{Fragment-Frequenz} gewonnen werden. %\emph({Beispiel: für Auslesen einer Textur verwendete Koordinaten)}
%Dies führt dazu, dass Ausdrücke, die nach den folgenden Regeln
%eigentlich Fragment-Frequenz besitzen müssten, Vertex-Frequenz besitzen, unter der Bedingung, dass
%das Ergebnis einer linearen Interpolation des Gesamtausdrucks äquivalent zum Ergebnis bei linearer
%Interpolation aller Teilausdrücke (mit jeweils immer gleicher Gewichtung) ist.
Dies erlaubt, gewisse Ausdrücke per Vertex statt per Fragment auszuführen. Details zu diesem Aspekt finden sich in
Abschnitt~\ref{Interpolierbarkeit}.

\subsection{Formulierte Frequenz}
\label{formulierte_frequenz}

Zwar soll die Berechnungsfrequenz von Operationen soweit möglich automatisch bestimmt werden, trotzdem muss eine Frequenz
gewählt werden, in der alle Operationen vorerst formuliert werden.

Betrachtet man eine "`niedrige"' Frequenz wie die Vertex-Frequenz, so erkennt man, dass sich damit Berechnungen einer höheren
Frequenz (also Fragmente) schlecht darstellen lassen. Betrachtet man allerdings Berechnungen mit Fragment-Frequenz, so lassen sich
unter Umständen Berechnungen niedrigerer Frequenz ableiten.
Shaderprogramme sollten also grundsätzlich in "`Fragment-Frequenz"' formuliert werden.

\subsection{Bestimmung der Berechnungsfrequenz}

\paragraph{Variablen:} Variablen besitzen eine zugeordnete Berechnungsfrequenz, die angibt wie oft sich der enthaltene Wert ändert.
Diese Frequenz entspricht der Frequenz des zuletzt zugewiesenen Ausdrucks (oder undefiniert wenn noch keine Zuweisung stattfand).

\paragraph{Arrays:} %Ist die Größe eines Arrays statisch bekannt kann jedes Element als einzelne Variable gesehen werden
%(und entsprechend jedem Element eine eigene Berechnungsfrequenz zugeordnet werden).
%Ist die Größe eines Arrays nicht statisch bekannt, so muss für alle Elemente die höchste, irgendeinem Element möglicherweise zugewiesene
%Frequenz angenommen werden -- 
Wird auf Elemente eines Arrays nur mit statisch bekannten Indizes zugegriffen kann jedes Element als einzelne Variable gesehen werden
(und entsprechend jedem Element eine eigene Berechnungsfrequenz zugeordnet werden).
Da beim Zugriff mit nicht statisch bekannten Indizes jedoch nicht bestimmt werden kann, welche Berechnungsfrequenz ein
Element hat (da ja auch nicht bekannt ist, auf welche Elemente genau zugegriffen wird), so muss für alle Elemente die höchste, irgendeinem Element möglicherweise
zugewiesene Frequenz angenommen werden.

%\paragraph{Ausdrücke:} Die Berechnungsfrequenz eines Wertes eines Ausdrucks ergibt sich aus der kleinsten gemeinsamen Frequenz
%der in dem Ausdruck enthaltenen Teilausdrücke \emph{nach} möglicher Anwendung von Umformungen zur Vereinfachung/Optimierung --
%sofern keine \emph{Spezialregeln} greifen (siehe Unten).
\paragraph{Ausdrücke:} Die Berechnungsfrequenz eines Wertes eines Ausdrucks hängt von der grössten gemeinsamen Frequenz
der in dem Ausdruck enthaltenen Teilausdrücke sowie der verwendeten Verknüpfung ab.
Die Abschnitte~\ref{splitter_Berechnungsfrequenzen} und~\ref{Interpolierbarkeit} beschreiben wie die Berechnungsfrequenz eines Ausdrucks bestimmt werden kann.

%\subsection{Spezialregeln für Berechnungsfrequenzen von Ausdrücken}

%\paragraph{Manuelle Bestimmung:}
%Bei einigen Ausdrücken kann eine Frequenz nicht automatisch abgeleitet werden, insbesondere bei Eingabeparametern aus der
%Umgebung. 
\paragraph{Programmeingaben:}
Bei Eingabeparametern aus der Umgebung kann eine Frequenz nicht automatisch abgeleitet werden.
Es wird davon ausgegangen, dass die umgebende Anwendung dem Compiler mitteilt, mit welcher Frequenz ein Eingabeparameter
geändert wird.\\

% Die Beschaffenheit der Daten beim Shading erlaubt
% weitere
%einige
% Spezialfälle:
% \paragraph{Lineare Operationen:} Vertexattribute werden über die Fragmente eines Dreiecks linear interpoliert; deswegen ist es
% erlaubt, lineare Operationen auf Vertex-Frequenz zu vollziehen, wenn alle Operatoren mit Vertex-Frequenz oder darunter
% berechnet wurden.

% \paragraph{Spezielle Eigenschaften:} "`Spezialwissen"' über mögliche Werte kann benutzt werden, um die Frequenz eines
% Ausdrucks zu bestimmen, insbesondere wenn diese niedriger als die normalerweise bestimme Frequenz wäre.
% \begin{itemize}
% \item \emph{Einheitsvektoren:} Einheitsvektoren werden oft in Shadingprogrammen benutzt. Einheitsvektoren können aber 
% nicht linear interpoliert werden, da dies einen Verlust der Einheitslänge zur Folge haben kann. Trotzdem kann es effizienter
% sein, einen Einheitsvektor mit Vertex-Frequenz zu berechnen, über die Fragmente linear zu interpolieren und per Fragment
% zu normalisieren, als den Vektor vollständig mit Fragment-Frequenz zu berechnen.
% \end{itemize}

\subsection{Berechnungsfrequenzen in der Aufspaltung}
\label{splitter_Berechnungsfrequenzen}
% Welche Frequenzen?

Für die Aufspaltung relevante Frequenzen sind die Mesh-, % TODO Vergl. Nomenklatur mit Erklärung Freq.; "Freq." besser nicht überladen mit "Verarbeitungsschritt"
% "Uniform" blöd
Vertex- und Fragmentfrequenz.

Per-Mesh-Eingaben sind Eingaben, die sich nicht während aufeinanderfolgenden Ausführungen eines Programmes
ändern, und können daher als \emph{konstant} angesehen werden. Deren Werte stammen aus der umgebenden Anwendung.

Per-Vertex-Eingaben sind den verschiedenen Vertices zugeordnete Eingaben. % TODO Verw. auf Vertexdaten
Auch diese sind Anwendungsdaten.

Per-Fragment-Eingaben sind die interpolierten Ausgaben des Vertexprogramms (siehe Abschnitt~\ref{schnittstelle} unten). 
Insbesondere besitzt Grafikhardware keinen Mechanismus, der der Anwendung erlauben würden, direkt per-Fragment-Eingaben
vorzugeben.

"`Echte"' Konstanten werden vom Splitter auch als "`per Mesh"' betrachtet.

Für jedes Register wird verfolgt, für welche Frequenzen es vorliegt, im Wesentlichen also in welchem Teilprogramm es berechnet werden muss.
Dabei kann ein Register in mehreren Frequenzen verfügbar sein, wenn es im Vertex-Programm berechnet wurde, aber später 
zur Übertragung an das Fragmentprogramm markiert wird (Abschnitt~\ref{schnittstelle}).

%: mit \emph{Vertexfrequenz} (per Vertex) berechnete Operationen werden dem Vertexprogramm zugeordnet.
%Analog werden mit \emph{Fragmentfrequenz} (per Fragment) berechnete Operationen dem Fragmentprogramm. Die Bestimmung der Berechnungsfrequenz hängt von der Operation selbst
%und von den Frequenzen, mit denen die Operanden berechnet wurden, ab. 

Die Frequenzen, in denen ein Register vorliegt, beeinflusst, in welcher Frequenz Operationen ausgeführt werden,
die das Register als Operand verwenden: Eine Operation muss mindestens in derjenigen Frequenz ausgeführt werden, welche dem Maximum der Operanden-Frequenzen
entspricht (eine Operation seltener auszuführen, als sich die Operanden ändern könnten, ist offensichtlich nicht sinnvoll).
So muss z.B. eine Addition von zwei Werten per Fragment ausgeführt werden, wenn einer der Summanden per Fragment berechnet wurde.
% DIes ist darin begründet, dass Werte nur vom Vertex- zum Fragmentprogramm, aber nicht zurück, übertragen werden können. ... \ref{}

Vorraussetzung für die Ausführung einer Berechnung per Vertex ist damit, dass beide Eingaben per Vertex vorliegen.
(Darüber hinaus muss die Operation das Kriterium der \emph{Interpolierbarkeit}, beschrieben in Abschnitt~\ref{Interpolierbarkeit}), erfüllen).

\subsubsection{Ausgegebene Programme}
Der Splitter kategorisiert auch Operationen und Werte als "`per Mesh"', generiert jedoch \emph{kein} separates Programm.
Stattdessen werden per-Mesh-Operationen sowohl vom Vertex- als auch vom Fragmentprogramm ausgeführt. Zwei Annahmen
liegen diesem Zugrunde: zuerst, dass nur relativ einfache Operationen allein mit per Mesh vorliegenden Werten vorgenommen werden, es also kein
Nachteil durch eine mehrfache Ausführung in Vertex- und Fragmentprogramm entsteht. Die zweite Annahme ist,
dass durch weitere Optimierungsschritte wie Dead Code Elimination einige per-Mesh-Operationen entfernt werden.

% Eingaben: Uniform oder per Vertex; Fragmentfreq. nur Eingaben von VP

\subsection{Schnittstelle Vertex-/Fragmentprogramm}
\label{schnittstelle}

Da ein Teil der Operationen des ursprünglichen Programms dem Vertexprogramm zugeordnet wird, ein anderer Teil aber dem
Fragmentprogramm, müssen Ergebnisse des einen Programms zum anderen übertragen werden.
Dabei ist zu beachten, dass nur Werte vom Vertex- zum Fragmentprogramm übertragen werden können; % @@@ Eher nicht hier
eine Übertragung in die andere Richtung ist nicht möglich.

Stellt der Splitter die Notwendigkeit des Übertragens für einen Wert fest, wird das Register, welches den Wert enthält, aufgezeichnet.
Diese Liste der zu übertragenden Werte ("`Schnittstelle"' in Abbildung~\ref{fig:structure}) wird später dem Codegenerator übergeben.
Dieser kümmert sich um die "`technischen"' Details wie die Zuordnung von für die Übertragung notwendigen Ressourcen und % @@@ Ress. -> Interpolatoren. Verw
entsprechende Abbildung in der Zieldarstellung.

\subsection{Interpolierbarkeit}
\label{Interpolierbarkeit}
% Kriterium: Interpolation

Programme der Shadingsprache sind grundsätzlich so formuliert, als würden Operationen per Fragment ausgeführt (siehe Abschnitt~\ref{formulierte_frequenz}).
Das vom Splitter zu lösende Problem ist damit die Bestimmung von Operationen, die per Vertex ausgeführt werden können.
Das Hauptkriterium diese Entscheidung ist die \emph{Interpolierbarkeit} einer Operation.

\newcommand\lerp{\mathrm{lerp}}
Vom Vertexprogramm ausgegebene Werte werden, bevor sie wieder dem Fragmentprogramm als Eingabe dienen, \emph{linear interpoliert} (siehe Abschnitt~\ref{rasterung}):
% TODO: Verw. auf Erklärung/Interpolatoren
Eine lineare Interpolation -- "`$\lerp$"' -- zwischen zwei Werten $a$ und $b$ mit Faktor $f$ ($0 \le f \le 1$) wird durch $\lerp(a, b, f) = a \cdot (1-f) + b \cdot f$ berechnet.
Soll ein Wert $x$ vom Vertex- and das Fragmentprogramm übergeben werden, so gibt das Vertexprogramm per Vertex verschiedene Werte aus - $x_1, x_2$ usw.
Das Fragmentprogramm erhält als Eingabe das Ergebnis einer implizierten, bei der Rasterung berechneten Interpolation $\lerp(x_1, x_2, f)$ (wobei $f$ von der Grafikhardware berechnet wird
und per Fragment variiert)\footnote{Tatsächlich muss bei der Rasterung von Dreiecken zwischen drei Werten interpoliert werden. Dieser Abschnitt betrachtet konkret
bloss Interpolation zwischen zwei Werten, die Ergebnisse gelten aber auch bei Interpolation zwischen drei Werten.}.

Eine per Fragment ausgeführte Rechenoperation $g(x)$, mit einem aus Ausgaben des Vertexprogramms interpoliertem $x$ -- also $x = \lerp(x_1, x_2, f)$ --
kann auch per Fragment ausgeführt werden, wenn eine Interpolation des Ergebnisses der per Vertex berechneten Rechenoperation zum gleichen Endergebnis führt:
es muss $g(\lerp(x_1, x_2, f)) = \lerp (g(x_1), g(x_2), f)$ gelten. Augenscheinlich muss $g$ eine lineare Funktion sein.

Für binäre Rechenoperationen lautet die Bedingung $\lerp (g (x_1, y_1), g (x_2, y_2), f) = g (\lerp (x_1, x_2, f), \lerp (y_1, y_2, f))$.
Rechenoperationen mit mehr Operanden müssen nicht betrachtet werden, da die Shadingsprache höchstens
binäre Rechenoperationen vorsieht bzw. "`komplexere"' Rechenoperationen auf binäre Operationen heruntergebrochen werden
können (siehe auch~\ref{split_builtins}). % Zweistelliges Äquivalent für "lineare Funktion"?

Da Rechenoperationen auf Vektoren komponentweise ausgeführt werden,  ist die "`Interpolierbarkeit"' ohne weiteres auch auf Vektoroperationen anwendbar.

Die geforderte Linearität von $g(x)$ führt dazu, dass bloss Operationen auf \texttt{float}-Werten problemlos interpolierbar sind.
Integer-Werte sind nicht interpolierbar, da bei deren Interpolation nicht-Integer-Werte als Zwischenergebnisse entstehen können.
Diese müssen (zwangsweise) gerundet\footnote{Oder Nachkommastelle abgeschnitten usw.} werden -- diese Rundung
ist aber keine stetige Funktion.

Zu Beachten ist, dass Interpolierbarkeit nur Relevanz hat, wenn entschieden wird, ob eine Operation, bei der mindestens ein Operand
nur per Vertex (oder höher) vorliegt, auch per Vertex ausgeführt werden kann.
Operationen allein auf Konstanten oder (praktisch konstanten) per-Mesh-Eingaben sind immer auch per Vertex ausführbar - das Ergebnis
einer solchen Operation kann nicht zwischen den Berechnungen für verschieden Vertices variieren. Insbesondere können damit
auch Operation auf Integer-Werten, oder Operationen, die nachfolgend als "`nicht interpolierbar"' klassifiziert werden,
per Vertex ausgeführt werden.

% Konkreter: Ausgabe VP: x_1, x_2, ...
% Eingabe FP: lerp (x_1, x_2, f) - implizit

%Allerdings kann eine Operation auf Vertex-Frequenz "`abgesenkt"' werden, wenn eine lineare Interpolation
%des Ergebnisses der Operation äquivalent zu der Operation mit linear interpoliertem Operanden ist
%($\lerp (g (x_1, y_1), g (x_2, y_2), f) = g (\lerp (x_1, x_2, f), \lerp (y_1, y_2, f))$).
% Andere Operandenzahlen betrachten
% Beispiel?

% Stichwort: Linearkombination?
\subsubsection{Einfache Operationen}

\paragraph{Arithmetische Operationen:} Die Summe oder Differenz von zwei linearen Funktionen
ist wieder eine lineare Funktion, Addition und Subtraktion sind also uneingeschränkt interpolierbar.
% @@@ Beweisen? Zumindest erläutern.

Multiplikation und Division sind interpolierbar, wenn mindestens ein Operand höchstens per Mesh gegeben ist.
Sind beide Operanden per Vertex gegeben, so ist eine Multiplikation oder Division keine lineare,
sondern eine \emph{quadratische} Funktion, und damit nicht interpolierbar. Per Mesh gegebene Operanden können aber praktisch als
konstant betrachtet werden, die Multiplikation oder Division mit einem per Mesh gegebenen
Operanden ist also eine lineare Funktion und damit interpolierbar.

Die Modulo-Operation ist unstetig und daher nicht interpolierbar.

\paragraph{Logische Ausdrücke, Vergleichsoperationen:} Diese Operationen sind ebenfalls unstetig und somit nicht interpolierbar.

\paragraph{Unäre Ausdrücke:} Negation ist offensichtlich interpolierbar.

Logisches NICHT ist, wie die anderen logischen Ausdrücke, nicht interpolierbar.

Bitweises invertieren ist nur für Integer-Werte sinnvoll und damit nicht interpolierbar.

\paragraph{Eingebaute Funktionen:} \label{split_builtins}
Skalarprodukt, Vektorprodukt und Matrixmultiplikation lassen sich alle mit arithmetischen Basisoperationen darstellen.
Da in diesen Darstellungen jeweils auch die Multiplikation enthalten ist, ergeben sich die oben genannten Beschränkungen:
diese Operationen sind nur interpolierbar, wenn mindesten ein Operand per Mesh gegeben ist.

Potenzierung ist im Allgemeinen keine stetige Funktion und damit nicht interpolierbar.

Die Berechnung von "`Normalisierung"' und "`Euklidische Länge"' erfordert das Ziehen einer Wurzel bzw. Potenzieren mit $\frac{1}{2}$.
Damit sind diese Funktionen ebenfalls nicht interpolierbar.

Minimum und Maximum sind im Allgemeinen keine stetigen Funktion und damit nicht interpolierbar.

Die Texturfunktionen sind prinzipbedingt nicht interpolierbar.

\subsubsection{Flusskontrolle}

Neben mathematischen Ausdrücken kann ein aufzuspaltendes Programm auch Operationen der Flusskontrolle enthalten,
die ebenso auf mehrere Ausgabeprogramme aufgespaltet werden müssen.

Grundsätzlich richten sich die Ausführungsfrequenzen von den Ablaufsteuerungsoperationen nach den Frequenzen der 
"`eingebetteten"' Operationen. Im Gegensatz zu "`einfachen"' Operationen wird eine Ablaufsteuerungsoperationen meist
in mehrere oder alle Ausgabeprogramme übernommen, allerdings mit anderen "`eingebetteten"' Operationen.

\paragraph{Sequenzschachtelung:} Eine Sequenzschachtelungsoperation wird prinzipiell zu allen generierten Teilprogrammen hinzugefügt,
allerdings mit unterschiedlichen Sequenzen. Diese sind selbst das Ergebnis einer Aufspaltung der ursprünglichen Sequenz.

\paragraph{Verzweigung:} Eine Verzweigung besteht konzeptionell aus zwei eingeschachtelten Sequenzen (für die jeweiligen Verzweigungsblöcke)
und einem bool'scher Bedingungswert, nach dessen Wert abhängig verzweigt wird.

Die beiden eingeschachtelten Verzweigungssequenzen werden selbst aufgespalten.

Der bool'scher Bedingungswert kann entweder per Mesh oder per Fragment vorliegen: per Mesh, wenn er eine per-Mesh-Eingabe ist bzw. allein aus
per-Mesh-Eingaben berechnet wurde. Per Fragment, wenn er aus Werten anderer Frequenzen berechnet wurde.
Aufgrund der Nicht-Interpolierbarkeit von Vergleichs- und Logikoperationen kann ein Bedingungswert nicht per Vertex vorliegen.

Selbst wenn der Bedingungswert nur per Fragment vorliegt, kann die Verzweigungsoperation nicht allein per Fragment ausgeführt werden:
die Aufspaltung der Verzweigungsblöcke kann auch in per Mesh bzw. per Vertex auszuführende Sequenzen resultieren. Diese müssen als "`normale"'
eingeschachtelte Sequenzen, d.h. ohne Verzweigung, zum Vertexprogramm hinzugefügt werden. Im Vertexprogramm werden also immer
die Vertexteile beider Verzweigungsblöcke ausgeführt. Zwischenergebnisse müssen an das Fragmentprogramm übertragen und dort ausgewählt werden.

Von den Verzweigungsblöcken beschriebene Register sind immer nur in der selben Frequenz wie das Register des Bedingungswerts verfügbar:
Selbst wenn beide Verzweigungen bloss per-Vertex-Operationen ausführen, sind durch die Auswahl nach einer per-Fragment-Bedingung
die berechneten Wert nur per Fragment verfügbar.

\paragraph{Schleife:} Eine Schleifenoperation besteht aus einer eingeschachtelten Sequenz (dem Schleifenrumpf) sowie
einem bool'scher Bedingungswert, der Schleifenbedingung.

Wie bei der Verzweigung kann der bool'scher Bedingungswert nur entweder per Mesh oder per Fragment vorliegen.

Bei der Bestimmung, in welcher Frequenz einzelne Operanden im Schleifenrumpf vorliegen,
ergibt sich das Problem, dass die Frequenzen, in denen ein Register vorliegt, von der Anzahl der Schleifendurchläufe
abhängt: z.B. kann eine Multiplikation eines Registers mit einem per Vertex vorliegendem Wert im ersten Durchlauf
eine interpolierbare Operation sein, im zweiten Durchlauf aber nicht mehr, wenn dem Register ein bloss per Vertex
verfügbarem Ergebnis aus dem vorherigen Durchlauf zugewiesen wurde.
Um eine "`stabile"' Verfügbarkeit von Registern, die von vorherigen Schleifendurchläufen abhängen, zu ermitteln,
werden zwei Schleifendurchläufe\footnote{Zwei Durchläufe sind ausreichend, da die Verfügbarkeit eines Registers
nach höchstens zwei Schritten bei der höchsten Frequenz liegt -- von Mesh auf Vertex bzw. von Vertex auf Fragment.}
simuliert und die damit bestimmten Verfügbarkeiten für das Aufspalten des Schleifenrumpfes verwendet.

Teile des Rumpfes können per Mesh oder per Vertex ausgeführt werden, wenn die Operationen nicht von vorhergegangenen Schleifendurchläufen
abhängen. Ein per-Mesh- oder per-Vertex-Ausführen von Operationen, die eine solche Abhängigkeit besitzen, wäre problematisch: es müsste bekannt sein, wieviele Werte vom
Mesh- bzw. Vertex-Teil zum Fragment-Teil übertragen werden sollen. Dies hängt von der Anzahl der Schleifendurchläufe ab,
welche im Allgemeinen nicht zur Kompilierzeit bestimmt werden kann.
Ausführen von "`echten"' Schleifen ist also nur komplett per Mesh oder per Fragment möglich.
%Schleifenoperationen können also nur komplett per Mesh oder per Fragment ausgeführt werden.

\paragraph{Funktionsaufruf:} Der Rumpf einer Funktion ist eine Sequenz, kann also prinzipiell in einen per-Vertex- und einen per-Fragment-Teil aufgespalten werden.
Das Hauptproblem besteht dabei darin, dass die Frequenzen der Funktionsparameter je nach Aufruf variieren können.

Dies wird gelöst, in dem für eine Funktion bei der Aufspaltung mehrere Varianten generiert werden: bei einem Funktionsaufruf
wird die Funktion aufgespalten, mit den jeweiligen Verfügbarkeiten der übergebenen aktuellen Parameter. Wird die gleiche Funktion
nochmals aufgerufen, aber mit einer anderen "`Signatur"' von Verfügbarkeiten, so wird die Funktion in neue Varianten aufgespalten usw.

Die Verfügbarkeiten von Ausgabeparametern hängen von den Verfügbarkeiten der Eingabeparameter ab, können aber nach dem Aufspalten
einer Variation bestimmt werden.

Das Übertragen von Werten vom per-Vertex- zum per-Fragment-Teil einer Funktionsvariation geschieht über generierte Ausgabe- bzw.
Eingabeparameter; die eigentliche Übertragung geschieht schlussendlich in der Eintrittsfunktion.

%Rekursionen müssen besonders behandelt werden:
Für Rekursionen ergibt sich folgendes Problem:
um die korrekten Verfügbarkeiten der Ausgabeparameter zu bestimmen
muss eine Funktion zunächst aufgespalten werden. Im Falle einer Rekursion wird möglicherweise aber genau die angetroffene
Variante gerade selbst aufgespalten -- die Verfügbarkeiten sind also noch nicht bekannt, der Versuch einer Aufspaltung der
angetroffenen Variante würde über kurz oder lang zum exakt selben Problem führen.

Dieses Problem wird vermieden, in dem rekursive Funktionen besonders behandelt werden: im Wesentlichen wird angenommen,
dass bei einem festgestelltem rekursiven Aufruf die Ausgabeparameter nur per Fragment verfügbar sind.
Mit dieser konservativen Annahme kann der Rumpf einer rekursiven Funktion aufgespalten werden.

% Behandlung von: arithm. Ausdr., Logik, Vergl, Unäre Ausdr., Verzweigungen, Schleifen, Funktionen

% Array-Operationen: evtl. nur per Fragment? (bei dyn. Arrays)

% 'Trivial': Zuweisung, Konstante, Typumwandlung, Vektor-Erstellung/-Extraktion, [Array-Erstellung/-Extraktion/-Änderung/-Länge,?]
% 

\subsubsection{Array-Operationen}

Array-Operationen sind nur interpolierbar, wenn die Länge des Arrays \emph{statisch konstant}
(und nicht per Mesh) bekannt ist und bei der Array-Extraktion bzw. \mbox{-Än}\-de\-rung der verwendete Index höchstens per Mesh
verfügbar ist.

\subsubsection{Andere Operationen}

Zuweisungen, Konstantenoperationen, Typumwandlung, die Erstellung eines Vektors sowie
die Extraktion einer Komponente können trivialerweise mit derjenigen Frequenz berechnet werden, die der höchsten Frequenz
aller Eingaben entspricht.

\subsection{Beispiel}

Ein einfaches Beispiel soll die Ausgabe des Auftrenners demonstrieren.

\subsubsection{Eingabeprogramm}

Als Eingabe dient das einfache Shading-Programm aus Abbildung~\ref{fig:simple_s1}.
Es basiert auf dem Beispiel in Abbildung~\ref{fig:simple_cg} -- dessen Vertex- und Fragment-Teil wurden hier zusammengeführt.

Das Programm berechnet eine Beleuchtungsintensität für eine Lichtquelle mit konstanter Richtung des Lichteinfalls (also eine Lichtquelle im
Unendlichen) und gegebener Farbe. Diese Beleuchtungsintensität mit der ``ambient''-Farbe (eine Annäherung von "`Streulicht"')
zu einer Gesamtintensität addiert. Diese wird dann mit einer aus einer Textur ausgelesenen Oberflächenfarbe moduliert.

In der Abbildung wurde (manuell) markiert, in welchen Frequenzen die Eingabeparameter vorliegen,
sowie die Frequenz, in der die einzelnen Ausdrücke ausgeführt werden müssten.

% Beispiele
\begin{figure}[ht]
  \input{simple_s1}
  \caption{Ein Programm in der Shading-Sprache.}
  \centering
  \small Operationen und Werte sind von der Berechnungsfrequenz abhängig markiert (\freqPerMesh{Mesh}, \freqPerVert{Vertex}, \freqPerFrag{Fragment})
  \label{fig:simple_s1}
\end{figure}

\subsubsection{Auftrennung}

Die für die Ausdrücke anzuwendenen Aufspaltungsregeln sind:

\paragraph{\texttt{outPosition}}: \texttt{Position} liegt per Vertex vor, der Gesamtausdruck muss daher mindestens per Vertex
berechnet werden. \texttt{ModelViewProj} liegt per Mesh vor, die Matrixmultiplikation ist interpolierbar,
der Gesamtausdruck kann daher auch höchstens per Vertex berechnet werden.

\paragraph{\texttt{ambient}}: Konstante, liegt daher per Mesh vor.

\paragraph{\texttt{diffuse}}: Das Skalarprodukt zwischen \texttt{LightDirObj} und \texttt{Normal} muss, da \texttt{Normal} per Vertex vorliegt,
mindestens per Vertex berechnet werden. \texttt{LightDirObj} liegt per Mesh vor, das Skalarprodukt ist also interpolierbar,
kann daher auch höchstens per Vertex berechnet werden.

Ebenso ist die Multiplikation von \texttt{LightColor} und dem Skalarprodukt interpolierbar, der Gesamtausdruck kann also per Vertex
berechnet werden.

\paragraph{\texttt{litColor}}: Da \texttt{diffuse} per Vertex vorliegt,\texttt{ambient} per Mesh, und weiterhin
Additionen uneingeschränkt interpolierbar sind, kann der Gesamtausdruck per Vertex berechnet werden.

\paragraph{\texttt{outColor}}: Das Erstellen eines \texttt{float4}-Vektors aus \texttt{litColor} wirkt sich nicht 
auf die Berechnungsfrequenz aus, der neue \texttt{float4}-Vektor liegt also per Vertex vor.

Das Auslesen der Textur mit \texttt{tex2D} kann nur per Fragment erfolgen. Damit muss auch die Multiplikation des Texturwertes mit
dem \texttt{float4}-Vektor per Fragment erfolgen.

\subsubsection{Ausgabe}

Abbildung~\ref{fig:simple_s1_split} enthält das Ergebnis nach Aufspaltung in Zwischencoderepräsentation.
(Vor oder nach der Aufspaltung wurden keine Optimierungen angewendet.)

%Die erste Hälfte stellt das Vertexprogramm dar. Direkt Ergebnisse der Aufspaltung sind:
Die Aufspaltung wirkt sich auf alle Aspekte der Programme aus:
\begin{itemize}
\item \emph{Eingabeparameter:} Im Vertexprogramm sind alle Eingabeparameter des Originalprogramms erhalten,
auch \texttt{Texture}, welches nur im Fragmentprogramm ausgelesen wird.

Bei den Eingabeparametern des Fragmentprogramms fehlen die per Vertex vorliegenden Eingaben -- diese werden
stattdessen vom Vertexprogramm weitergegeben ("`Übertragene Register"'). Allerdings gibt es auch
hier "`unnötige"' Eingaben, wie \texttt{ModelViewProj}. 

\item \emph{Ausgabeparameter:} Dies sind die vom jeweiligen Verarbeitungsschritt zu berechnenden Ausgaben --
die projizierte Vertex-Position im Falle des Vertexprogramms bzw. die finale Fragmentfarbe im Falle des
Fragmentprogramms.

\item \emph{Übertragene Register:} Die "`Schnittstelle"' zwischen Vertex- und Fragmentprogramm.
Dabei enthält $\sOreg{m\_TexCoord\_B0}$ den Wert des Eingabeparameters \texttt{TexCoord}, der per Vertex vorliegt,
aber nur im Fragmentprogramm verwendet wird. $\sOreg{i\_tmp12}$ das Ergebnis der Beleuchtungsberechnung
-- der rechte Faktor in der abschliessenden Multiplikation nach \texttt{outColor} --
welches im Fragmentprogramm mit der ausgelesenen Texturfarbe multipliziert werden soll.

Der Aufspalter hat diese Register zur Übertragung ausgewählt, da deren Werte nur per Vertex vorliegen,
aber im Fragmentprogramm verwendet werden.

\item \emph{Operationen:} Der Splitter hat die per Vertex und per Fragment zu berechnenden Operationen
genau so aufgeteilt, wie es nach der manuellen Klassifizierung im Eingabeprogramm zu erwarten war.
Die per Mesh zu berechnenden Operationen wurde, wie in Abschnitt~\ref{splitter_Berechnungsfrequenzen}
beschrieben, sowohl in das Vertex- wie auch das Fragmentprogramm ausgegeben. In diesem Fall ist dies
nur die Zuweisungen von $\sOreg{v\_ambient}$ und $\sOreg{i\_tmp11}$. Diese Werte werden im Fragment-Programm nicht verwendet,
die Operationen selbst bleiben aber in diesem Fall wegen nicht vorgenommener Optimierungen dort erhalten.

\end{itemize}

\begin{figure}[h!t]
  \centering
  \input{simple_s1_split}
  \caption{Programm aus \ref{fig:simple_s1} nach der Aufspaltung.}
  %\small Operationen und Werte sind von der Berechnungsfrequenz abhängig markiert (\freqPerMesh{Mesh}, \freqPerVert{Vertex}, \freqPerFrag{Fragment})
  \label{fig:simple_s1_split}
\end{figure}

Abbildung~\ref{fig:simple_s1_images} visualisiert die Anteile der Berechnungen der verschiedenen Berechnungsfrequenzen
an der finalen Fragmentfarbe. Dafür wurde mit Hilfe des Compilers das Eingabeprogramm in ein Vertex- und Fragmentprogramm
in der Shadingsprache Cg übersetzt. Diese wurden für die Visualisierung der per-Mesh- bzw. per-Vertex-Anteile leicht bearbeitet
um eben diese Anteile auszugeben. Die Bilder selbst wurden mit Hilfe eines kurzen, selbstgeschriebenen Programms erstellt,
dass ein texturiertes 3D-Dreiecksmodel unter Verwendung der Shadingprogramme darstellt.

Das erste Bild zeigt den per-Mesh-Anteil (\texttt{ambient}) und zeigt dementsprechend eine durchgängige Färbung.

Im zweiten Bild zeigt wurde der per-Vertex-Anteil (\texttt{litColor}) hinzugenommen. Es ist deutlich erkennbar,
dass die Farbe über das Modell stark variiert und damit eine Beleuchtung aus der rechten oberen Richtung suggeriert.
Allerdings sind auch Facettierungen von der per-Vertex-Berechnung erkennbar (am deutlichsten auf dem Ausguss oder dem Henkel).

Im dritten Bild wurde schliesslich auch der per-Fragment-Anteil hinzugenommen. Die Farbveränderung aus der "`Beleuchtung"'
ist noch klar erkennbar, aber das Auslesen einer Oberflächenfarbe aus einer Textur fügt weitere visuelle Details hinzu
und reduziert die Sichtbarkeit der Facettierungen.

\begin{figure}[h]
  \centering
  \includegraphics[width=8cm]{simple_s1_mesh}\\
  \includegraphics[width=8cm]{simple_s1_vert}\\
  \includegraphics[width=8cm]{simple_s1_frag}
  \caption{Programm aus \ref{fig:simple_s1}}
  \small 1. nur per-Mesh-Anteil der Fragment-Farbe\\
  2. mit zusätzlich per-Vertex-Anteil\\
  3. vollständige Fragment-Farbe\\
  \label{fig:simple_s1_images}
\end{figure}

% Force figures to appear before section
\clearpage
\section{Optimierer}

\newcommand\OptSample[2]{
  \begin{figure}[!h]
    \centering
    \begin{minipage}{8cm}\lstinputlisting{s1source/opt_ex/#1.s1}\end{minipage}
    \begin{minipage}{10cm}\include{s1latex/opt_ex/#1_unopt}\end{minipage}
    \vspace{0.3em}
    \begin{minipage}{10cm}\include{s1latex/opt_ex/#1_opt}\end{minipage}
    \caption{#2.}
    \label{fig:ir_optex_#1}
  \end{figure}
}
\newcommand\OptSampleStacked[2]{
  \begin{figure}[!h]
    \centering
    \begin{minipage}{8cm}\lstinputlisting{s1source/opt_ex/#1.s1}\end{minipage}
    \begin{minipage}{10cm}\include{s1latex/opt_ex/#1_unopt}\end{minipage}\\
    \vspace{0.3em}
    \begin{minipage}{10cm}\include{s1latex/opt_ex/#1_opt}\end{minipage}
    \caption{#2.}
    \label{fig:ir_optex_#1}
  \end{figure}
}

Die Aufgabe eines \emph{Optimierers} ist es, ein gegebenes Programm so umzuschreiben, dass es zur Laufzeit
schnellstmöglich ausgeführt wird. Im Allgemeinen erstrecken sich mögliche Optimierungen von Vereinfachungen,
wie ein Entfernen von unbenötigten Operationen und ein Berechnen von Ausdrücken zur Kompilierzeit,
bis hin zu komplexen Umsortierungen oder Zusammenfassung von Operationen, z.B. um ``multiply-add''-Operation
besser auszunutzen.

Ein Optimierer, der Redundanzen u.ä. entfernt, erlaubt als Nebeneffekt auch, dass die vorhergehenden Arbeitsschritte
eines Compilers -- im vorliegenden Compiler insbesondere der Splitter --
nicht selbst optimalen Zwischencode erzeugen müssen. Die Implementierungen jener Arbeitsschritte kann damit
einfacher gehalten werden.

\subsection{Aufbau}

% Ein-, Ausgabe: Programme

Der Optimierer im vorliegenden Compiler nimmt als Eingabe ein komplettes Programm entgegen
und liefert als Ausgabe entsprechend auch ein komplettes Programm.

Das Arbeiten auf ganzen Programmen erlaubt es prinzipiell, funktionsübergreifende Optimierungen
vorzunehmen, von einem entfernen unbenötigter Funktionen über Inlining bis zu einem entfernen
einzelner, nicht benötigter Funktionsparameter.

Allerdings beschränken sich die implementierten, unten beschriebenen Optimierungen auf Sequenzen
von Operationen; diese Sequenzoptimierungen werden auf alle Funktionen eines Programms unabhängig
voneinander angewendet.

% mehrere Stufen
Die einzelnen Sequenzenoptimierungen werden nacheinander angewendet. Bei Bedarf kann eine
Optimierung mehrmals angewendet werden -- z.B. kann das ``Constant Folding'' einen Ausführungszweig
einer Verzweigung auswählen; in diesem Fall wird ein erneutes ``Block Inlining'' veranlasst,
um die dadurch eingefügte Sequenzschachtelungsoperation zu vereinfachen.
% bei Bedarf mehrere Durchgänge -> z.B. erneutes BI when CF einen Branch o.ä. "geinlined" hat

\subsection{Block Inlining}

% 'entfernt' Block-Seqop.
Das \emph{Block Inlining} ersetzt alle Sequenzschachtelungsoperationen einer Sequenz durch
die in der eingeschachtelten Sequenz enthaltenen Operationen. Dabei werden die von den
Operationen verwendeten bzw. veränderten Register angepasst: Register, die einem importiertem
oder exportiertem Namen zugeordnet sind, werden durch ihre Gegenstücke in der umgebenden
Sequenz ersetzt. Andere Register werden umbenannt um Kollisionen zu vermeiden.

% v.a. "Hilfsschritt" für andere Opt.
Die vom Block Inlining vorgenommen Änderungen an einer Sequenz haben keine Auswirkungen auf das
Laufzeitverhalten des Programms. Dieser Optimierungsschritt dient vor allem als "`Hilfsschritt"',
um die Implementierungen anderer Optimierungsschritte zu vereinfachen: einerseits können
Sequenzschachtelungsoperationen als "`nicht vorhanden"' angenommen werden, andererseits kann
ein Inlining von Blöcken -- z.B. wegen der statischen Auswahl eines Verzweigungsblockes --
einfach vorgenommen werden, da die nötige "`Hauptarbeit"' später vom Block-Inlining-Schritt
vorgenommen wird.

Abbildung~\ref{fig:ir_optex_bi} vergleicht ein einfaches Programm vor und nach der Anwendung von Block Inlining.

\OptSampleStacked{bi}{Block Inlining: Quellcode, Zwischencoderepräsentation unoptimiert und optimiert}

\subsection{Constant Folding}

% Berechnung von konstanten Ausdrücken
% (Cast, Arithmetische, Logische, Unäre, Vergleichsop., Builtins, Arraylänge, Array getelem)
% Entfernung von Branches/Schleifen mit konst. Bedingung
\emph{Constant Folding} berechnet das Ergebnis einer Sequenzoperation zur Kompilierzeit
wenn alle Eingabeoperanden zur Kompilierzeit bekannte Konstanten sind. Berücksichtigt
werden Zuweisungs-, Cast-, arithmetische, logische, unäre und Vergleichsoperationen, alle eingebauten
Funktionen (mit Ausnahme von Texturfunktionen) sowie die Operationen "`Arraylänge"' und
"`Extraktion eines Arrayelements"'.
Weiterhin werden Verzweigungsoperationen, deren Bedingung ein konstanter Wert ist,
durch eine Schachtelung der entsprechenden Sequenz ersetzt (die andere Sequenz wird verworfen).
Auch Schleifenoperationen, deren Schleifenbedingung den konstanten Wert "`falsch"' besitzt,
werden verworfen.

% Fkt.weise: speichert für jedes Reg., ob konst., und wenn ja, dessen Wert;
% Op. auf Konstanten zur Kompilierzeit berechnet
In der Implementierung des Constant Folding wird eine Zuordnung zwischen Registern und konstanten
Werten verwendet; ist einem Register kein solcher Wert zugeordnet besitzt es keinen bekannten
konstanten Wert. Eine solche Zuordnung wird erstellt, wenn eine Operationen ein konstantes
Ergebnis hat. Dies sind zuvorderst Konstantenoperationen.
Bei Operationen, die einer der oben genannten Arten entsprechen, wird überprüft, ob alle Operanden
konstante Werte sind. Ist dies der Fall wird das Ergebnis der Operation vom Compiler berechnet
und die Operation durch eine einfache Konstantenoperation ersetzt.

% Zukunft: Funktionen mit rein konstanten Argumenten

Abbildung~\ref{fig:ir_optex_cf} vergleicht ein einfaches Programm vor und nach der Anwendung von Constant Folding.
Anzumerken ist, dass die Addition vom Compiler ausgerechnet und durch eine Konstantenoperation ersetzt
wird; die Konstantenoperationen der Quelloperanden bleiben jedoch erhalten - deren Entfernung ist
die Aufgabe der Dead Code Elimination, welche aber in diesem Beispiel nicht durchgeführt wurde.

\OptSampleStacked{cf}{Constant Folding: Quellcode, Zwischencoderepräsentation unoptimiert und optimiert}

\subsection{Dead Code Elimination}

\emph{Dead Code Elimination} entfernt unnötige Sequenzoperationen; eine Operation ist "`unnötig"',
wenn keines der von ihr geschriebenen Register jemals benutzt wird.

% entfernt Op., deren Ergebnis nie benutzt wird

In der Implementierung werden die Operationen einer Sequenz \emph{von hinten} betrachtet.
Es wird eine Menge von "`ausgelesenen"' Registern gespeichert. Bei jeder Operation wird
zunächst überprüft, ob wenigstens eins der Ausgaberegister ein solches "`ausgelesenes"'
Register ist. Ist dies nicht der Fall, wird die Operation verworfen. Andernfalls wird
die Operation beibehalten und alle ihre Eingaberegister als "`ausgelesen"' markiert.

Die Menge der "`ausgelesenen"' Register benötigt eine "`Saat"' von Registern, die als
immer ausgelesen angenommen werden (sonst würden alle Operationen einer Sequenz verworfen
werden). Dies sind immer die Ausgabeparameter der Funktion, die die Sequenz enthält.
Für Sequenzen, die z.B. in Verzweigungen eingeschachtelt sind, dient die Menge der
ausgelesenen Register der umgebenden Sequenz als Saat.

% Fkt.weise: iteriert Operationen rückwärts
% speichert zu jedem Reg., ob gelesen
% verwirft Op., deren Zielregister nie gelesen wurde
% verwirft Blöcke, bei denen kein "exportiertes" Register gelesen wurde
% verwirft Fkt.aufrufe, bei denen kein Ausgabereg. gelesen wurde
% benötigt "Saat-Register" (Ausgabeparameter)

Abbildung~\ref{fig:ir_optex_dce} vergleicht ein einfaches Programm vor und nach der Anwendung von Dead Code Elimination.
Dargestellt sind die Zwischencoderepräsentationen nach der Aufspaltung des Programms.
In den unoptimierten Programmen werden beide Ausgabeparameter sowohl in Vertex- als auch Fragmentprogramm
beschrieben, obwohl jeweils nur einer tatsächlich verwendet wird. Aus den optimierten Programmen wurde die jeweils unnötige
Zuweisung entfernt.

\OptSampleStacked{dce}{Dead Code Elimination: Quellcode, Zwischencoderepräsentation unoptimiert und optimiert;
Zwischencoderepräsentation nach Aufspaltung in Vertex- und Fragmentprogramme}

\clearpage
\section{Code-Generator}

Der \emph{Code-Generator} übersetzt ein in der Zwischencoderepräsentation vorliegendes Programm in eine \emph{Zieldarstellung}.
Diese "`Darstellung"' kann wieder eine Hochsprache sein, prinzipiell kann ein Code-Generator aber auch Assembler-Quelltext oder eine
Binärcodierung ausgeben.

\subsection{Eingaben und Aufgaben}

Der \emph{Code-Generator} erhält als Eingabe eine Liste von Funktionsbeschreibungen.
Eine Funktionsbeschreibung besteht aus dem eindeutigen Bezeichner, einer Liste von Parametern (getrennt nach Ein- und Ausgabeparametern)
und einer Sequenz mit den eigentlichen Operationen. Eine Funktion aus der Liste ist als "`Eintrittsfunktion"' markiert.

\begin{figure}[h]
   \centering
  \includegraphics{ir_program}
  \caption{Zusammensetzung eines Programms in der Zwischencoderepräsentation}
  \label{fig:ir_program}
\end{figure}

\newpage
Die Aufgaben des Code-Generators bestehen aus:
\begin{itemize}
\item Nötige Umformungen für die Zieldarstellung -- z.B. Schleifen ausrollen oder ``inlining'' von Funktionen.
\item Übertragung der Funktionsbeschreibungen in eine entsprechende Deklaration in der Zieldarstellung.
\item Übersetzung der Sequenzoperationen in die Zieldarstellung. 
\item Dabei Ressourcenallokation, wenn nötig (z.B. begrenzte Registerzahl in der Zieldarstellung).
\item Generierung von "`Schnittstellen-Anweisungen"' wie z.B. bei der Übergabe von Parametern an Funktionen
oder die Behandlung von Werten "`vor dem ersten Durchlauf, nach dem ersten Durchlauf"' wie sie bei Schleifen
auftreten.
\end{itemize}

\subsection{Generator für Cg}

\renewcommand{\baselinestretch}{1.40}\normalsize
In der vorliegenden Implementierung wurde als Zieldarstellung die Sprache Cg~(\cite{cgpaper}, \cite{cg_home}) gewählt.

Cg als Hochsprache kennt selbst Konstrukte wie Funktionen und Schleifen. Umformungen durch den Codegenerator
sind also nicht nötig.

Jede Funktion wird also direkt auf eine Cg-Funktion abgebildet.

Jedem Register der Zwischencoderepräsentation wird eine Variable zugeordnet -- eine Re\-gis\-ter\-al\-lo\-ka\-tion ist unnötig, diese wird später vom Cg-Compiler selbst vorgenommen.
"`Einfache"' Sequenzoperation (arithmetische Operationen u.ä.) lassen sich auf einen einzelnen Cg-Befehl übertragen. 
Weiterhin werden die meisten eingebauten Funktionen und Attribute direkt von Cg unterstützt (Ausnahme ist das Matrix-Attribut \texttt{inverted}).

Kompliziertere Operationen -- Verzweigungen, Schleifen, Funktionsaufrufe -- resultieren in mehreren Statements, obwohl es sich bei dem
zusätzlichen "`Aufwand"' meist nur um Zuweisungen zwischen Variablen handelt, wie z.B. die Auswahl des Bedingungsregisters basierend zwischen
den Wert vor und nach dem ersten Schleifendurchlauf.

Die spezifizierte Sprache unterstützt Zeichenketten aus Unicode-Buchstaben und -Ziffern als Bezeichner;
Cg nur eine Untermenge von ASCII. Für die Ausgabe als Cg-Code werden Bezeichner in eine Darstellung in der akzeptieren
Zeichenmenge umgewandelt\footnote{Als Kodierung wurde Punycode~(\cite{rfc3492}) gewählt da dies die aus ASCII bestehenden Teile eines Bezeichners
gut lesbar lässt.}.

% Original-Schnipsel und Generator-Output
\renewcommand{\baselinestretch}{1.50}\normalsize

\newpage
\section{Zusammenfassung}

Grundsätzlich folgt der Aufbau des Compilers der Standardarchitektur; die Abweichnung ist der Verarbeitungsschritt der "`Auftrennung"' in mehrere
Programme.

Die Auftrennung nutzt dabei Eigenschaften von Grafikhardware aus, deren Aufbau auf den Ablauf des Echtzeit-3D-Renderings abgestimmt ist.
Speziell werden Operationen in der Vertex- statt Fragmentverarbeitung ausgeführt, sofern das Ergebnis zur ursprünglichen Operation mathematisch äquivalent ist
(unter Berücksichtigung der von der Grafikhardware vorgenommen Interpolation von Ausgaben der Vertexverarbeitung).

Auch hervorzuheben ist die verwendete Zwischencoderepräsentation, die als Übergabeformat zwischen allen Verarbeitungsschritten von der
semantischen Analyse bis zur Codegenerierung dient. Weiterhin ist sie darauf ausgerichtet, die Implementierung von Optimierungsschritten
möglichst zu vereinfachen.

\chapter{Ausblick}

% AST: nützlich, wenn FEs für anderen Sprachen, oder komplexer (Strukturen)
% Manuelles spezifizieren von per-Vertex Ops // keyword 'interpolate'

Die übersetzte Sprache ist eine zwar vergleichsweise einfache, aber trotzdem praktisch nutzbare
Shadingsprache, die es erlaubt, Shadingprogramme zu schreiben, ohne den Hardwareaufbau aus verschiedenen Funktionseinheiten
berücksichtigen zu müssen.

Der in Abschnitt~\ref{Auftrennung} beschriebene Auftrenner arbeitet konservativ in dem Sinne, dass eine Operation nur in das Ausgabe-Vertex-Programm
"`verschoben"' wird wenn das Ergebnis mathematisch äquivalent zu einer Berechnung im Ausgabe-Fragment-Programm wäre.
Praktisch sollen aber manchmal bewusst Operationen durch eine per-Vertex-Berechnung approximiert werden (aus Geschwindigkeitsgründen
bei komplexen oder oftmals verwendeten Programmen). Die Sprache sollte deswegen noch um ein Schlüsselwort o.ä. erweitert werden
welches ein manuelles Bestimmen der Berechnungseinheit für eine Operation erlaubt.

Die anderen Shadingsprachen wie Cg, GLSL usw. noch weitere "`Komfortfunktionen"' für oft verwendete
Berechnungen (z.B. für die lineare Interpolation von Werten oder Vektoren), die zwar prinzipiell mit den vorhandenen Operationen
oder eingebauten Funktionen nachgebildet werden können; ein zur Verfügung stellen als eingebaute Funktion wäre jedoch komfortabler.

Die in vielen Programmiersprachen vorhandenen Verbundtypen wäre eine sinnvolle Erweiterung 
um das Erstellen von komplexeren Programmen zu vereinfachen. Auch praktisch nützlich wären die von anderen Shadingsprachen meist bereitgestellten
Typen mit unterschiedlichen Genauigkeiten (wie ``half'' oder ``double precision''-Fließkommazahlen). Diese lassen den Programmierer, je nach Anforderungen,
zwischen Genauigkeit und Berechnungsgeschwindigkeit abwägen. 

Denkbar ist es auch, den Compiler so zu erweitern, dass Programme aus "`üblichen"' Shadingsprachen mit getrennten Vertex- und Fragmentprogrammen
-- wie Cg -- akzeptiert werden. Die Ausgabe des Compilers wären ein funktional äquivalente Vertex- und Fragment-Programme,
allerdings potentiell mit einer besseren Verteilung von Operationen auf Verarbeitungseinheiten.

Bei der Implementierung besteht noch Verbesserungspotential im Aufspalter. 
Vor allem rekursive Funktionen werden nur im Fragment-Programm ausgeführt - dies stellt zwar ein korrektes
Ergebnis sicher, ist aber nicht in allen Fällen die optimale Lösung.

%Der Compiler selbst nimmt in der vorliegenden Implementierung noch keine Optimierungsschritte vor. In Anbetracht der bewussten Ausrichtung
%der Zwischencoderepräsentation auf möglichst einfache Optimierungen sowie die bei der Implementierung gemachten Annahmen (z.B. im Aufspalter) über das
%Vorhandensein von Optimierungsschritten wäre es der nächste sinnvolle Schritte, diese Optimierungsschritte tatsächlich umzusetzen.

Zur weiteren praktischen Verwendung des Compilers ist eine Integration in eine "'3D-Engine"' (also Bibliothek für 3D-Visualisierungen), wie es einige
unter Open-Source-Lizenzen gibt, anstrebenswert.

\cleardoublepage
\appendix

\printglossaries

\bibliography{thesis_de}
\addcontentsline{toc}{chapter}{Literatur}

\end{document}
